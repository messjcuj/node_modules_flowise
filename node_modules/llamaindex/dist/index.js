Object.defineProperty(exports, '__esModule', { value: true });

var jsTiktoken = require('js-tiktoken');
var node_crypto = require('node:crypto');
var Anthropic$1 = require('@anthropic-ai/sdk');
var _ = require('lodash');
var OpenAI$1 = require('openai');
var portkeyAi = require('portkey-ai');
var Replicate = require('replicate');
var path = require('node:path');
var node_os = require('node:os');
var path$1 = require('path');
var astraDbTs = require('@datastax/astra-db-ts');
var chromadb = require('chromadb');
var mongodb = require('mongodb');
var pg = require('pg');
var pgvector = require('pgvector/pg');
var pinecone = require('@pinecone-database/pinecone');
var node_assert = require('node:assert');
var rake = require('rake-modified');
var assemblyai = require('assemblyai');
var Papa = require('papaparse');
var mammoth = require('mammoth');
var notionMdCrawler = require('notion-md-crawler');

function _interopDefault (e) { return e && e.__esModule ? e : { default: e }; }

function _interopNamespace(e) {
  if (e && e.__esModule) return e;
  var n = Object.create(null);
  if (e) {
    Object.keys(e).forEach(function (k) {
      if (k !== 'default') {
        var d = Object.getOwnPropertyDescriptor(e, k);
        Object.defineProperty(n, k, d.get ? d : {
          enumerable: true,
          get: function () { return e[k]; }
        });
      }
    });
  }
  n.default = e;
  return n;
}

var Anthropic__default = /*#__PURE__*/_interopDefault(Anthropic$1);
var ___namespace = /*#__PURE__*/_interopNamespace(_);
var OpenAI__default = /*#__PURE__*/_interopDefault(OpenAI$1);
var Replicate__default = /*#__PURE__*/_interopDefault(Replicate);
var path__default = /*#__PURE__*/_interopDefault(path);
var path__default$1 = /*#__PURE__*/_interopDefault(path$1);
var pg__default = /*#__PURE__*/_interopDefault(pg);
var pgvector__default = /*#__PURE__*/_interopDefault(pgvector);
var rake__default = /*#__PURE__*/_interopDefault(rake);
var Papa__default = /*#__PURE__*/_interopDefault(Papa);
var mammoth__default = /*#__PURE__*/_interopDefault(mammoth);

exports.Tokenizers = void 0;
(function(Tokenizers) {
    Tokenizers["CL100K_BASE"] = "cl100k_base";
})(exports.Tokenizers || (exports.Tokenizers = {}));
/**
 * Helper class singleton
 */ class GlobalsHelper {
    initDefaultTokenizer() {
        const encoding = jsTiktoken.encodingForModel("text-embedding-ada-002"); // cl100k_base
        this.defaultTokenizer = {
            encode: (text)=>{
                return new Uint32Array(encoding.encode(text));
            },
            decode: (tokens)=>{
                const numberArray = Array.from(tokens);
                const text = encoding.decode(numberArray);
                const uint8Array = new TextEncoder().encode(text);
                return new TextDecoder().decode(uint8Array);
            }
        };
    }
    tokenizer(encoding) {
        if (encoding && encoding !== "cl100k_base") {
            throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
        }
        if (!this.defaultTokenizer) {
            this.initDefaultTokenizer();
        }
        return this.defaultTokenizer.encode.bind(this.defaultTokenizer);
    }
    tokenizerDecoder(encoding) {
        if (encoding && encoding !== "cl100k_base") {
            throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
        }
        if (!this.defaultTokenizer) {
            this.initDefaultTokenizer();
        }
        return this.defaultTokenizer.decode.bind(this.defaultTokenizer);
    }
    createEvent({ parentEvent, type, tags }) {
        return {
            id: node_crypto.randomUUID(),
            type,
            // inherit parent tags if tags not set
            tags: tags || (parentEvent == null ? void 0 : parentEvent.tags),
            parentId: parentEvent == null ? void 0 : parentEvent.id
        };
    }
    constructor(){
        this.defaultTokenizer = null;
    }
}
const globalsHelper = new GlobalsHelper();

class AnthropicSession {
    constructor(options = {}){
        if (!options.apiKey) {
            if (typeof process !== undefined) {
                options.apiKey = process.env.ANTHROPIC_API_KEY;
            }
        }
        if (!options.apiKey) {
            throw new Error("Set Anthropic Key in ANTHROPIC_API_KEY env variable"); // Overriding Anthropic package's error message
        }
        this.anthropic = new Anthropic__default.default(options);
    }
}
// I'm not 100% sure this is necessary vs. just starting a new session
// every time we make a call. They say they try to reuse connections
// so in theory this is more efficient, but we should test it in the future.
let defaultAnthropicSession = [];
/**
 * Get a session for the Anthropic API. If one already exists with the same options,
 * it will be returned. Otherwise, a new session will be created.
 * @param options
 * @returns
 */ function getAnthropicSession(options = {}) {
    var _defaultAnthropicSession_find;
    let session = (_defaultAnthropicSession_find = defaultAnthropicSession.find((session)=>{
        return ___namespace.default.isEqual(session.options, options);
    })) == null ? void 0 : _defaultAnthropicSession_find.session;
    if (!session) {
        session = new AnthropicSession(options);
        defaultAnthropicSession.push({
            session,
            options
        });
    }
    return session;
}
const ANTHROPIC_HUMAN_PROMPT = Anthropic$1.HUMAN_PROMPT;
const ANTHROPIC_AI_PROMPT = Anthropic$1.AI_PROMPT;

// NOTE we're not supporting the legacy models as they're not available for new deployments
// https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/legacy-models
// If you have a need for them, please open an issue on GitHub
const ALL_AZURE_OPENAI_CHAT_MODELS = {
    "gpt-35-turbo": {
        contextWindow: 4096,
        openAIModel: "gpt-3.5-turbo"
    },
    "gpt-35-turbo-16k": {
        contextWindow: 16384,
        openAIModel: "gpt-3.5-turbo-16k"
    },
    "gpt-4": {
        contextWindow: 8192,
        openAIModel: "gpt-4"
    },
    "gpt-4-32k": {
        contextWindow: 32768,
        openAIModel: "gpt-4-32k"
    }
};
const ALL_AZURE_OPENAI_EMBEDDING_MODELS = {
    "text-embedding-ada-002": {
        dimensions: 1536,
        openAIModel: "text-embedding-ada-002",
        maxTokens: 8191
    }
};
const DEFAULT_API_VERSION = "2023-05-15";
//^ NOTE: this will change over time, if you want to pin it, use a specific version
function getAzureConfigFromEnv(init) {
    var _init_apiKey, _ref, _ref1, _init_endpoint, _ref2, _ref3, _init_apiVersion, _ref4, _ref5, _ref6, _init_deploymentName, _ref7, _ref8;
    return {
        apiKey: (_ref1 = (_ref = (_init_apiKey = init == null ? void 0 : init.apiKey) != null ? _init_apiKey : process.env.AZURE_OPENAI_KEY) != null ? _ref : // From Azure docs
        process.env.OPENAI_API_KEY) != null ? _ref1 : // Python compatible
        process.env.AZURE_OPENAI_API_KEY,
        endpoint: (_ref3 = (_ref2 = (_init_endpoint = init == null ? void 0 : init.endpoint) != null ? _init_endpoint : process.env.AZURE_OPENAI_ENDPOINT) != null ? _ref2 : // From Azure docs
        process.env.OPENAI_API_BASE) != null ? _ref3 : // Python compatible
        process.env.AZURE_OPENAI_API_INSTANCE_NAME,
        apiVersion: (_ref6 = (_ref5 = (_ref4 = (_init_apiVersion = init == null ? void 0 : init.apiVersion) != null ? _init_apiVersion : process.env.AZURE_OPENAI_API_VERSION) != null ? _ref4 : // From Azure docs
        process.env.OPENAI_API_VERSION) != null ? _ref5 : // Python compatible
        process.env.AZURE_OPENAI_API_VERSION) != null ? _ref6 : // LCJS compatible
        DEFAULT_API_VERSION,
        deploymentName: (_ref8 = (_ref7 = (_init_deploymentName = init == null ? void 0 : init.deploymentName) != null ? _init_deploymentName : process.env.AZURE_OPENAI_DEPLOYMENT) != null ? _ref7 : // From Azure docs
        process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME) != null ? _ref8 : // LCJS compatible
        init == null ? void 0 : init.model
    };
}
function getAzureBaseUrl(config) {
    return `${config.endpoint}/openai/deployments/${config.deploymentName}`;
}
function getAzureModel(openAIModel) {
    for (const [key, value] of Object.entries(ALL_AZURE_OPENAI_EMBEDDING_MODELS)){
        if (value.openAIModel === openAIModel) {
            return key;
        }
    }
    for (const [key, value] of Object.entries(ALL_AZURE_OPENAI_CHAT_MODELS)){
        if (value.openAIModel === openAIModel) {
            return key;
        }
    }
    throw new Error(`Unknown model: ${openAIModel}`);
}
function shouldUseAzure() {
    return process.env.AZURE_OPENAI_ENDPOINT || process.env.AZURE_OPENAI_API_INSTANCE_NAME || process.env.OPENAI_API_TYPE === "azure";
}

function _async_generator$4(gen) {
    var front, back;
    function send(key, arg) {
        return new Promise(function(resolve, reject) {
            var request = {
                key: key,
                arg: arg,
                resolve: resolve,
                reject: reject,
                next: null
            };
            if (back) {
                back = back.next = request;
            } else {
                front = back = request;
                resume(key, arg);
            }
        });
    }
    function resume(key, arg) {
        try {
            var result = gen[key](arg);
            var value = result.value;
            var wrappedAwait = value instanceof _await_value$4;
            Promise.resolve(wrappedAwait ? value.wrapped : value).then(function(arg) {
                if (wrappedAwait) {
                    resume("next", arg);
                    return;
                }
                settle(result.done ? "return" : "normal", arg);
            }, function(err) {
                resume("throw", err);
            });
        } catch (err) {
            settle("throw", err);
        }
    }
    function settle(type, value) {
        switch(type){
            case "return":
                front.resolve({
                    value: value,
                    done: true
                });
                break;
            case "throw":
                front.reject(value);
                break;
            default:
                front.resolve({
                    value: value,
                    done: false
                });
                break;
        }
        front = front.next;
        if (front) {
            resume(front.key, front.arg);
        } else {
            back = null;
        }
    }
    this._invoke = send;
    if (typeof gen.return !== "function") {
        this.return = undefined;
    }
}
if (typeof Symbol === "function" && Symbol.asyncIterator) {
    _async_generator$4.prototype[Symbol.asyncIterator] = function() {
        return this;
    };
}
_async_generator$4.prototype.next = function(arg) {
    return this._invoke("next", arg);
};
_async_generator$4.prototype.throw = function(arg) {
    return this._invoke("throw", arg);
};
_async_generator$4.prototype.return = function(arg) {
    return this._invoke("return", arg);
};
function _async_iterator$6(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$6(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$6(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$6 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$6.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$6(s);
}
function _await_async_generator$4(value) {
    return new _await_value$4(value);
}
function _await_value$4(value) {
    this.wrapped = value;
}
function _wrap_async_generator$4(fn) {
    return function() {
        return new _async_generator$4(fn.apply(this, arguments));
    };
}
function streamConverter(stream, converter) {
    return _streamConverter.apply(this, arguments);
}
function _streamConverter() {
    _streamConverter = _wrap_async_generator$4(function*(stream, converter) {
        {
            var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
            try {
                for(var _iterator = _async_iterator$6(stream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$4(_iterator.next())).done; _iteratorAbruptCompletion = false){
                    let _value = _step.value;
                    const data = _value;
                    yield converter(data);
                }
            } catch (err) {
                _didIteratorError = true;
                _iteratorError = err;
            } finally{
                try {
                    if (_iteratorAbruptCompletion && _iterator.return != null) {
                        yield _iterator.return();
                    }
                } finally{
                    if (_didIteratorError) {
                        throw _iteratorError;
                    }
                }
            }
        }
    });
    return _streamConverter.apply(this, arguments);
}
function streamReducer(params) {
    return _streamReducer.apply(this, arguments);
}
function _streamReducer() {
    _streamReducer = _wrap_async_generator$4(function*(params) {
        let value = params.initialValue;
        {
            var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
            try {
                for(var _iterator = _async_iterator$6(params.stream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$4(_iterator.next())).done; _iteratorAbruptCompletion = false){
                    let _value = _step.value;
                    const data = _value;
                    value = params.reducer(value, data);
                    yield data;
                }
            } catch (err) {
                _didIteratorError = true;
                _iteratorError = err;
            } finally{
                try {
                    if (_iteratorAbruptCompletion && _iterator.return != null) {
                        yield _iterator.return();
                    }
                } finally{
                    if (_didIteratorError) {
                        throw _iteratorError;
                    }
                }
            }
        }
        if (params.finished) {
            params.finished(value);
        }
    });
    return _streamReducer.apply(this, arguments);
}
/**
 * Extracts just the text from a multi-modal message or the message itself if it's just text.
 *
 * @param message The message to extract text from.
 * @returns The extracted text
 */ function extractText(message) {
    if (Array.isArray(message)) {
        // message is of type MessageContentDetail[] - retrieve just the text parts and concatenate them
        // so we can pass them to the context generator
        return message.filter((c)=>c.type === "text").map((c)=>c.text).join("\n\n");
    }
    return message;
}

function asyncGeneratorStep$P(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$P(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$P(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$P(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class BaseLLM {
    complete(params) {
        var _this = this;
        return _async_to_generator$P(function*() {
            const { prompt, parentEvent, stream } = params;
            if (stream) {
                const stream = yield _this.chat({
                    messages: [
                        {
                            content: prompt,
                            role: "user"
                        }
                    ],
                    parentEvent,
                    stream: true
                });
                return streamConverter(stream, (chunk)=>{
                    return {
                        text: chunk.delta
                    };
                });
            }
            const chatResponse = yield _this.chat({
                messages: [
                    {
                        content: prompt,
                        role: "user"
                    }
                ],
                parentEvent
            });
            return {
                text: chatResponse.message.content
            };
        })();
    }
}

function _extends$b() {
    _extends$b = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$b.apply(this, arguments);
}
class AzureOpenAI extends OpenAI__default.default {
    authHeaders() {
        return {
            "api-key": this.apiKey
        };
    }
}
class OpenAISession {
    constructor(options = {}){
        if (!options.apiKey) {
            if (typeof process !== undefined) {
                options.apiKey = process.env.OPENAI_API_KEY;
            }
        }
        if (!options.apiKey) {
            throw new Error("Set OpenAI Key in OPENAI_API_KEY env variable"); // Overriding OpenAI package's error message
        }
        if (options.azure) {
            this.openai = new AzureOpenAI(options);
        } else {
            this.openai = new OpenAI__default.default(_extends$b({}, options));
        }
    }
}
// I'm not 100% sure this is necessary vs. just starting a new session
// every time we make a call. They say they try to reuse connections
// so in theory this is more efficient, but we should test it in the future.
let defaultOpenAISession = [];
/**
 * Get a session for the OpenAI API. If one already exists with the same options,
 * it will be returned. Otherwise, a new session will be created.
 * @param options
 * @returns
 */ function getOpenAISession(options = {}) {
    var _defaultOpenAISession_find;
    let session = (_defaultOpenAISession_find = defaultOpenAISession.find((session)=>{
        return ___namespace.default.isEqual(session.options, options);
    })) == null ? void 0 : _defaultOpenAISession_find.session;
    if (!session) {
        session = new OpenAISession(options);
        defaultOpenAISession.push({
            session,
            options
        });
    }
    return session;
}

const readEnv = (env, default_val)=>{
    if (typeof process !== "undefined") {
        var _process_env;
        var _process_env_env;
        return (_process_env_env = (_process_env = process.env) == null ? void 0 : _process_env[env]) != null ? _process_env_env : default_val;
    }
    return default_val;
};
class PortkeySession {
    constructor(options = {}){
        if (!options.apiKey) {
            options.apiKey = readEnv("PORTKEY_API_KEY");
        }
        if (!options.baseURL) {
            options.baseURL = readEnv("PORTKEY_BASE_URL", "https://api.portkey.ai");
        }
        this.portkey = new portkeyAi.Portkey({});
        this.portkey.llms = [
            {}
        ];
        if (!options.apiKey) {
            throw new Error("Set Portkey ApiKey in PORTKEY_API_KEY env variable");
        }
        this.portkey = new portkeyAi.Portkey(options);
    }
}
let defaultPortkeySession = [];
/**
 * Get a session for the Portkey API. If one already exists with the same options,
 * it will be returned. Otherwise, a new session will be created.
 * @param options
 * @returns
 */ function getPortkeySession(options = {}) {
    var _defaultPortkeySession_find;
    let session = (_defaultPortkeySession_find = defaultPortkeySession.find((session)=>{
        return ___namespace.default.isEqual(session.options, options);
    })) == null ? void 0 : _defaultPortkeySession_find.session;
    if (!session) {
        session = new PortkeySession(options);
        defaultPortkeySession.push({
            session,
            options
        });
    }
    return session;
}

class ReplicateSession {
    constructor(replicateKey = null){
        this.replicateKey = null;
        if (replicateKey) {
            this.replicateKey = replicateKey;
        } else if (process.env.REPLICATE_API_TOKEN) {
            this.replicateKey = process.env.REPLICATE_API_TOKEN;
        } else {
            throw new Error("Set Replicate token in REPLICATE_API_TOKEN env variable");
        }
        this.replicate = new Replicate__default.default({
            auth: this.replicateKey
        });
    }
}

function _async_generator$3(gen) {
    var front, back;
    function send(key, arg) {
        return new Promise(function(resolve, reject) {
            var request = {
                key: key,
                arg: arg,
                resolve: resolve,
                reject: reject,
                next: null
            };
            if (back) {
                back = back.next = request;
            } else {
                front = back = request;
                resume(key, arg);
            }
        });
    }
    function resume(key, arg) {
        try {
            var result = gen[key](arg);
            var value = result.value;
            var wrappedAwait = value instanceof _await_value$3;
            Promise.resolve(wrappedAwait ? value.wrapped : value).then(function(arg) {
                if (wrappedAwait) {
                    resume("next", arg);
                    return;
                }
                settle(result.done ? "return" : "normal", arg);
            }, function(err) {
                resume("throw", err);
            });
        } catch (err) {
            settle("throw", err);
        }
    }
    function settle(type, value) {
        switch(type){
            case "return":
                front.resolve({
                    value: value,
                    done: true
                });
                break;
            case "throw":
                front.reject(value);
                break;
            default:
                front.resolve({
                    value: value,
                    done: false
                });
                break;
        }
        front = front.next;
        if (front) {
            resume(front.key, front.arg);
        } else {
            back = null;
        }
    }
    this._invoke = send;
    if (typeof gen.return !== "function") {
        this.return = undefined;
    }
}
if (typeof Symbol === "function" && Symbol.asyncIterator) {
    _async_generator$3.prototype[Symbol.asyncIterator] = function() {
        return this;
    };
}
_async_generator$3.prototype.next = function(arg) {
    return this._invoke("next", arg);
};
_async_generator$3.prototype.throw = function(arg) {
    return this._invoke("throw", arg);
};
_async_generator$3.prototype.return = function(arg) {
    return this._invoke("return", arg);
};
function _async_iterator$5(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$5(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$5(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$5 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$5.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$5(s);
}
function asyncGeneratorStep$O(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$O(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$O(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$O(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _await_async_generator$3(value) {
    return new _await_value$3(value);
}
function _await_value$3(value) {
    this.wrapped = value;
}
function _extends$a() {
    _extends$a = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$a.apply(this, arguments);
}
function _wrap_async_generator$3(fn) {
    return function() {
        return new _async_generator$3(fn.apply(this, arguments));
    };
}
const GPT4_MODELS = {
    "gpt-4": {
        contextWindow: 8192
    },
    "gpt-4-32k": {
        contextWindow: 32768
    },
    "gpt-4-1106-preview": {
        contextWindow: 128000
    },
    "gpt-4-vision-preview": {
        contextWindow: 8192
    }
};
const GPT35_MODELS = {
    "gpt-3.5-turbo": {
        contextWindow: 4096
    },
    "gpt-3.5-turbo-16k": {
        contextWindow: 16384
    },
    "gpt-3.5-turbo-1106": {
        contextWindow: 16384
    }
};
/**
 * We currently support GPT-3.5 and GPT-4 models
 */ const ALL_AVAILABLE_OPENAI_MODELS = _extends$a({}, GPT4_MODELS, GPT35_MODELS);
/**
 * OpenAI LLM implementation
 */ class OpenAI extends BaseLLM {
    get metadata() {
        var _ALL_AVAILABLE_OPENAI_MODELS_this_model;
        var _ALL_AVAILABLE_OPENAI_MODELS_this_model_contextWindow;
        const contextWindow = (_ALL_AVAILABLE_OPENAI_MODELS_this_model_contextWindow = (_ALL_AVAILABLE_OPENAI_MODELS_this_model = ALL_AVAILABLE_OPENAI_MODELS[this.model]) == null ? void 0 : _ALL_AVAILABLE_OPENAI_MODELS_this_model.contextWindow) != null ? _ALL_AVAILABLE_OPENAI_MODELS_this_model_contextWindow : 1024;
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: this.maxTokens,
            contextWindow,
            tokenizer: exports.Tokenizers.CL100K_BASE
        };
    }
    tokens(messages) {
        // for latest OpenAI models, see https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb
        const tokenizer = globalsHelper.tokenizer(this.metadata.tokenizer);
        const tokensPerMessage = 3;
        let numTokens = 0;
        for (const message of messages){
            numTokens += tokensPerMessage;
            for (const value of Object.values(message)){
                numTokens += tokenizer(value).length;
            }
        }
        numTokens += 3; // every reply is primed with <|im_start|>assistant<|im_sep|>
        return numTokens;
    }
    mapMessageType(messageType) {
        switch(messageType){
            case "user":
                return "user";
            case "assistant":
                return "assistant";
            case "system":
                return "system";
            case "function":
                return "function";
            default:
                return "user";
        }
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$O(function*() {
            var _response_choices__message;
            const { messages, parentEvent, stream } = params;
            const baseRequestParams = _extends$a({
                model: _this.model,
                temperature: _this.temperature,
                max_tokens: _this.maxTokens,
                messages: messages.map((message)=>({
                        role: _this.mapMessageType(message.role),
                        content: message.content
                    })),
                top_p: _this.topP
            }, _this.additionalChatOptions);
            // Streaming
            if (stream) {
                return _this.streamChat(params);
            }
            // Non-streaming
            const response = yield _this.session.openai.chat.completions.create(_extends$a({}, baseRequestParams, {
                stream: false
            }));
            var _response_choices__message_content;
            const content = (_response_choices__message_content = (_response_choices__message = response.choices[0].message) == null ? void 0 : _response_choices__message.content) != null ? _response_choices__message_content : "";
            return {
                message: {
                    content,
                    role: response.choices[0].message.role
                }
            };
        })();
    }
    streamChat({ messages, parentEvent }) {
        var _this = this;
        return _wrap_async_generator$3(function*() {
            var _this_callbackManager;
            const baseRequestParams = _extends$a({
                model: _this.model,
                temperature: _this.temperature,
                max_tokens: _this.maxTokens,
                messages: messages.map((message)=>({
                        role: _this.mapMessageType(message.role),
                        content: message.content
                    })),
                top_p: _this.topP
            }, _this.additionalChatOptions);
            //Now let's wrap our stream in a callback
            const onLLMStream = ((_this_callbackManager = _this.callbackManager) == null ? void 0 : _this_callbackManager.onLLMStream) ? _this.callbackManager.onLLMStream : ()=>{};
            const chunk_stream = yield _await_async_generator$3(_this.session.openai.chat.completions.create(_extends$a({}, baseRequestParams, {
                stream: true
            })));
            const event = parentEvent ? parentEvent : {
                id: "unspecified",
                type: "llmPredict"
            };
            // TODO: add callback to streamConverter and use streamConverter here
            //Indices
            var idx_counter = 0;
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$5(chunk_stream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$3(_iterator.next())).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const part = _value;
                        if (!part.choices.length) continue;
                        //Increment
                        part.choices[0].index = idx_counter;
                        const is_done = part.choices[0].finish_reason === "stop" ? true : false;
                        //onLLMStream Callback
                        const stream_callback = {
                            event: event,
                            index: idx_counter,
                            isDone: is_done,
                            token: part
                        };
                        onLLMStream(stream_callback);
                        idx_counter++;
                        var _part_choices__delta_content;
                        yield {
                            delta: (_part_choices__delta_content = part.choices[0].delta.content) != null ? _part_choices__delta_content : ""
                        };
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            return;
        })();
    }
    constructor(init){
        super();
        // OpenAI session params
        this.apiKey = undefined;
        var _init_model;
        this.model = (_init_model = init == null ? void 0 : init.model) != null ? _init_model : "gpt-3.5-turbo";
        var _init_temperature;
        this.temperature = (_init_temperature = init == null ? void 0 : init.temperature) != null ? _init_temperature : 0.1;
        var _init_topP;
        this.topP = (_init_topP = init == null ? void 0 : init.topP) != null ? _init_topP : 1;
        var _init_maxTokens;
        this.maxTokens = (_init_maxTokens = init == null ? void 0 : init.maxTokens) != null ? _init_maxTokens : undefined;
        var _init_maxRetries;
        this.maxRetries = (_init_maxRetries = init == null ? void 0 : init.maxRetries) != null ? _init_maxRetries : 10;
        var _init_timeout;
        this.timeout = (_init_timeout = init == null ? void 0 : init.timeout) != null ? _init_timeout : 60 * 1000; // Default is 60 seconds
        this.additionalChatOptions = init == null ? void 0 : init.additionalChatOptions;
        this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
        if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
            const azureConfig = getAzureConfigFromEnv(_extends$a({}, init == null ? void 0 : init.azure, {
                model: getAzureModel(this.model)
            }));
            if (!azureConfig.apiKey) {
                throw new Error("Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable.");
            }
            this.apiKey = azureConfig.apiKey;
            var _init_session;
            this.session = (_init_session = init == null ? void 0 : init.session) != null ? _init_session : getOpenAISession(_extends$a({
                azure: true,
                apiKey: this.apiKey,
                baseURL: getAzureBaseUrl(azureConfig),
                maxRetries: this.maxRetries,
                timeout: this.timeout,
                defaultQuery: {
                    "api-version": azureConfig.apiVersion
                }
            }, this.additionalSessionOptions));
        } else {
            var _init_apiKey;
            this.apiKey = (_init_apiKey = init == null ? void 0 : init.apiKey) != null ? _init_apiKey : undefined;
            var _init_session1;
            this.session = (_init_session1 = init == null ? void 0 : init.session) != null ? _init_session1 : getOpenAISession(_extends$a({
                apiKey: this.apiKey,
                maxRetries: this.maxRetries,
                timeout: this.timeout
            }, this.additionalSessionOptions));
        }
        this.callbackManager = init == null ? void 0 : init.callbackManager;
    }
}
const ALL_AVAILABLE_LLAMADEUCE_MODELS = {
    "Llama-2-70b-chat-old": {
        contextWindow: 4096,
        replicateApi: "replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48"
    },
    "Llama-2-70b-chat-4bit": {
        contextWindow: 4096,
        replicateApi: "meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3"
    },
    "Llama-2-13b-chat-old": {
        contextWindow: 4096,
        replicateApi: "a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5"
    },
    //^ Last known good 13b non-quantized model. In future versions they add the SYS and INST tags themselves
    "Llama-2-13b-chat-4bit": {
        contextWindow: 4096,
        replicateApi: "meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d"
    },
    "Llama-2-7b-chat-old": {
        contextWindow: 4096,
        replicateApi: "a16z-infra/llama7b-v2-chat:4f0a4744c7295c024a1de15e1a63c880d3da035fa1f49bfd344fe076074c8eea"
    },
    "Llama-2-7b-chat-4bit": {
        contextWindow: 4096,
        replicateApi: "meta/llama-2-7b-chat:13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0"
    }
};
exports.DeuceChatStrategy = void 0;
(function(DeuceChatStrategy) {
    DeuceChatStrategy["A16Z"] = "a16z";
    DeuceChatStrategy["META"] = "meta";
    DeuceChatStrategy["METAWBOS"] = "metawbos";
    //^ This is not exactly right because SentencePiece puts the BOS and EOS token IDs in after tokenization
    // Unfortunately any string only API won't support these properly.
    DeuceChatStrategy["REPLICATE4BIT"] = "replicate4bit";
    //^ To satisfy Replicate's 4 bit models' requirements where they also insert some INST tags
    DeuceChatStrategy["REPLICATE4BITWNEWLINES"] = "replicate4bitwnewlines";
})(exports.DeuceChatStrategy || (exports.DeuceChatStrategy = {}));
/**
 * Llama2 LLM implementation
 */ class LlamaDeuce extends BaseLLM {
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    get metadata() {
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: this.maxTokens,
            contextWindow: ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow,
            tokenizer: undefined
        };
    }
    mapMessagesToPrompt(messages) {
        if (this.chatStrategy === "a16z") {
            return this.mapMessagesToPromptA16Z(messages);
        } else if (this.chatStrategy === "meta") {
            return this.mapMessagesToPromptMeta(messages);
        } else if (this.chatStrategy === "metawbos") {
            return this.mapMessagesToPromptMeta(messages, {
                withBos: true
            });
        } else if (this.chatStrategy === "replicate4bit") {
            return this.mapMessagesToPromptMeta(messages, {
                replicate4Bit: true,
                withNewlines: true
            });
        } else if (this.chatStrategy === "replicate4bitwnewlines") {
            return this.mapMessagesToPromptMeta(messages, {
                replicate4Bit: true,
                withNewlines: true
            });
        } else {
            return this.mapMessagesToPromptMeta(messages);
        }
    }
    mapMessagesToPromptA16Z(messages) {
        return {
            prompt: messages.reduce((acc, message)=>{
                return (acc && `${acc}\n\n`) + `${this.mapMessageTypeA16Z(message.role)}${message.content}`;
            }, "") + "\n\nAssistant:",
            //^ Here we're differing from A16Z by omitting the space. Generally spaces at the end of prompts decrease performance due to tokenization
            systemPrompt: undefined
        };
    }
    mapMessageTypeA16Z(messageType) {
        switch(messageType){
            case "user":
                return "User: ";
            case "assistant":
                return "Assistant: ";
            case "system":
                return "";
            default:
                throw new Error("Unsupported LlamaDeuce message type");
        }
    }
    mapMessagesToPromptMeta(messages, opts) {
        const { withBos = false, replicate4Bit = false, withNewlines = false } = opts != null ? opts : {};
        const DEFAULT_SYSTEM_PROMPT = `You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.`;
        const B_SYS = "<<SYS>>\n";
        const E_SYS = "\n<</SYS>>\n\n";
        const B_INST = "[INST]";
        const E_INST = "[/INST]";
        const BOS = "<s>";
        const EOS = "</s>";
        if (messages.length === 0) {
            return {
                prompt: "",
                systemPrompt: undefined
            };
        }
        messages = [
            ...messages
        ]; // so we can use shift without mutating the original array
        let systemPrompt = undefined;
        if (messages[0].role === "system") {
            const systemMessage = messages.shift();
            if (replicate4Bit) {
                systemPrompt = systemMessage.content;
            } else {
                const systemStr = `${B_SYS}${systemMessage.content}${E_SYS}`;
                // TS Bug: https://github.com/microsoft/TypeScript/issues/9998
                // @ts-ignore
                if (messages[0].role !== "user") {
                    throw new Error("LlamaDeuce: if there is a system message, the second message must be a user message.");
                }
                const userContent = messages[0].content;
                messages[0].content = `${systemStr}${userContent}`;
            }
        } else {
            if (!replicate4Bit) {
                messages[0].content = `${B_SYS}${DEFAULT_SYSTEM_PROMPT}${E_SYS}${messages[0].content}`;
            }
        }
        return {
            prompt: messages.reduce((acc, message, index)=>{
                if (index % 2 === 0) {
                    return `${acc}${withBos ? BOS : ""}${B_INST} ${message.content.trim()} ${E_INST}` + (withNewlines ? "\n" : "");
                } else {
                    return `${acc} ${message.content.trim()}` + (withNewlines ? "\n" : " ") + (withBos ? EOS : ""); // Yes, the EOS comes after the space. This is not a mistake.
                }
            }, ""),
            systemPrompt
        };
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$O(function*() {
            const { messages, parentEvent, stream } = params;
            const api = ALL_AVAILABLE_LLAMADEUCE_MODELS[_this.model].replicateApi;
            const { prompt, systemPrompt } = _this.mapMessagesToPrompt(messages);
            const replicateOptions = {
                input: {
                    prompt,
                    system_prompt: systemPrompt,
                    temperature: _this.temperature,
                    top_p: _this.topP
                }
            };
            if (_this.model.endsWith("4bit")) {
                replicateOptions.input.max_new_tokens = _this.maxTokens;
            } else {
                replicateOptions.input.max_length = _this.maxTokens;
            }
            //TODO: Add streaming for this
            if (stream) {
                throw new Error("Streaming not supported for LlamaDeuce");
            }
            //Non-streaming
            const response = yield _this.replicateSession.replicate.run(api, replicateOptions);
            return {
                message: {
                    content: response.join("").trimStart(),
                    //^ We need to do this because Replicate returns a list of strings (for streaming functionality which is not exposed by the run function)
                    role: "assistant"
                }
            };
        })();
    }
    constructor(init){
        super();
        var _init_model;
        this.model = (_init_model = init == null ? void 0 : init.model) != null ? _init_model : "Llama-2-70b-chat-4bit";
        var _init_chatStrategy;
        this.chatStrategy = (_init_chatStrategy = init == null ? void 0 : init.chatStrategy) != null ? _init_chatStrategy : this.model.endsWith("4bit") ? "replicate4bitwnewlines" : "metawbos"; // With BOS and EOS seems to work best, although they all have problems past a certain point
        var _init_temperature;
        this.temperature = (_init_temperature = init == null ? void 0 : init.temperature) != null ? _init_temperature : 0.1; // minimum temperature is 0.01 for Replicate endpoint
        var _init_topP;
        this.topP = (_init_topP = init == null ? void 0 : init.topP) != null ? _init_topP : 1;
        var _init_maxTokens;
        this.maxTokens = (_init_maxTokens = init == null ? void 0 : init.maxTokens) != null ? _init_maxTokens : ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow; // For Replicate, the default is 500 tokens which is too low.
        var _init_replicateSession;
        this.replicateSession = (_init_replicateSession = init == null ? void 0 : init.replicateSession) != null ? _init_replicateSession : new ReplicateSession();
    }
}
const ALL_AVAILABLE_ANTHROPIC_MODELS = {
    // both models have 100k context window, see https://docs.anthropic.com/claude/reference/selecting-a-model
    "claude-2": {
        contextWindow: 200000
    },
    "claude-instant-1": {
        contextWindow: 100000
    }
};
/**
 * Anthropic LLM implementation
 */ class Anthropic extends BaseLLM {
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    get metadata() {
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: this.maxTokens,
            contextWindow: ALL_AVAILABLE_ANTHROPIC_MODELS[this.model].contextWindow,
            tokenizer: undefined
        };
    }
    mapMessagesToPrompt(messages) {
        return messages.reduce((acc, message)=>{
            return acc + `${message.role === "system" ? "" : message.role === "assistant" ? ANTHROPIC_AI_PROMPT + " " : ANTHROPIC_HUMAN_PROMPT + " "}${message.content.trim()}`;
        }, "") + ANTHROPIC_AI_PROMPT;
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$O(function*() {
            const { messages, parentEvent, stream } = params;
            //Streaming
            if (stream) {
                return _this.streamChat(messages, parentEvent);
            }
            var _this_maxTokens;
            //Non-streaming
            const response = yield _this.session.anthropic.completions.create({
                model: _this.model,
                prompt: _this.mapMessagesToPrompt(messages),
                max_tokens_to_sample: (_this_maxTokens = _this.maxTokens) != null ? _this_maxTokens : 100000,
                temperature: _this.temperature,
                top_p: _this.topP
            });
            return {
                message: {
                    content: response.completion.trimStart(),
                    role: "assistant"
                }
            };
        })();
    }
    streamChat(messages, parentEvent) {
        var _this = this;
        return _wrap_async_generator$3(function*() {
            var _this_maxTokens;
            // AsyncIterable<AnthropicStreamToken>
            const stream = yield _await_async_generator$3(_this.session.anthropic.completions.create({
                model: _this.model,
                prompt: _this.mapMessagesToPrompt(messages),
                max_tokens_to_sample: (_this_maxTokens = _this.maxTokens) != null ? _this_maxTokens : 100000,
                temperature: _this.temperature,
                top_p: _this.topP,
                stream: true
            }));
            var idx_counter = 0;
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$5(stream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$3(_iterator.next())).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const part = _value;
                        //TODO: LLM Stream Callback, pending re-work.
                        idx_counter++;
                        yield {
                            delta: part.completion
                        };
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            return;
        })();
    }
    constructor(init){
        super();
        // Anthropic session params
        this.apiKey = undefined;
        var _init_model;
        this.model = (_init_model = init == null ? void 0 : init.model) != null ? _init_model : "claude-2";
        var _init_temperature;
        this.temperature = (_init_temperature = init == null ? void 0 : init.temperature) != null ? _init_temperature : 0.1;
        var _init_topP;
        this.topP = (_init_topP = init == null ? void 0 : init.topP) != null ? _init_topP : 0.999; // Per Ben Mann
        var _init_maxTokens;
        this.maxTokens = (_init_maxTokens = init == null ? void 0 : init.maxTokens) != null ? _init_maxTokens : undefined;
        var _init_apiKey;
        this.apiKey = (_init_apiKey = init == null ? void 0 : init.apiKey) != null ? _init_apiKey : undefined;
        var _init_maxRetries;
        this.maxRetries = (_init_maxRetries = init == null ? void 0 : init.maxRetries) != null ? _init_maxRetries : 10;
        var _init_timeout;
        this.timeout = (_init_timeout = init == null ? void 0 : init.timeout) != null ? _init_timeout : 60 * 1000; // Default is 60 seconds
        var _init_session;
        this.session = (_init_session = init == null ? void 0 : init.session) != null ? _init_session : getAnthropicSession({
            apiKey: this.apiKey,
            maxRetries: this.maxRetries,
            timeout: this.timeout
        });
        this.callbackManager = init == null ? void 0 : init.callbackManager;
    }
}
class Portkey extends BaseLLM {
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    get metadata() {
        throw new Error("metadata not implemented for Portkey");
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$O(function*() {
            const { messages, parentEvent, stream, extraParams } = params;
            if (stream) {
                return _this.streamChat(messages, parentEvent, extraParams);
            } else {
                var _response_choices__message, _response_choices__message1;
                const bodyParams = extraParams || {};
                const response = yield _this.session.portkey.chatCompletions.create(_extends$a({
                    messages
                }, bodyParams));
                var _response_choices__message_content;
                const content = (_response_choices__message_content = (_response_choices__message = response.choices[0].message) == null ? void 0 : _response_choices__message.content) != null ? _response_choices__message_content : "";
                const role = ((_response_choices__message1 = response.choices[0].message) == null ? void 0 : _response_choices__message1.role) || "assistant";
                return {
                    message: {
                        content,
                        role: role
                    }
                };
            }
        })();
    }
    streamChat(messages, parentEvent, params) {
        var _this = this;
        return _wrap_async_generator$3(function*() {
            var _this_callbackManager;
            // Wrapping the stream in a callback.
            const onLLMStream = ((_this_callbackManager = _this.callbackManager) == null ? void 0 : _this_callbackManager.onLLMStream) ? _this.callbackManager.onLLMStream : ()=>{};
            const chunkStream = yield _await_async_generator$3(_this.session.portkey.chatCompletions.create(_extends$a({
                messages
            }, params, {
                stream: true
            })));
            const event = parentEvent ? parentEvent : {
                id: "unspecified",
                type: "llmPredict"
            };
            //Indices
            var idx_counter = 0;
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$5(chunkStream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$3(_iterator.next())).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const part = _value;
                        var _part_choices__delta;
                        //Increment
                        part.choices[0].index = idx_counter;
                        const is_done = part.choices[0].finish_reason === "stop" ? true : false;
                        //onLLMStream Callback
                        const stream_callback = {
                            event: event,
                            index: idx_counter,
                            isDone: is_done
                        };
                        onLLMStream(stream_callback);
                        idx_counter++;
                        var _part_choices__delta_content;
                        yield {
                            delta: (_part_choices__delta_content = (_part_choices__delta = part.choices[0].delta) == null ? void 0 : _part_choices__delta.content) != null ? _part_choices__delta_content : ""
                        };
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            return;
        })();
    }
    constructor(init){
        super();
        this.apiKey = undefined;
        this.baseURL = undefined;
        this.mode = undefined;
        this.llms = undefined;
        this.apiKey = init == null ? void 0 : init.apiKey;
        this.baseURL = init == null ? void 0 : init.baseURL;
        this.mode = init == null ? void 0 : init.mode;
        this.llms = init == null ? void 0 : init.llms;
        this.session = getPortkeySession({
            apiKey: this.apiKey,
            baseURL: this.baseURL,
            llms: this.llms,
            mode: this.mode
        });
        this.callbackManager = init == null ? void 0 : init.callbackManager;
    }
}

/*
DEFAULT_TEXT_QA_PROMPT_TMPL = (
    "Context information is below.\n"
    "---------------------\n"
    "{context_str}\n"
    "---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the query.\n"
    "Query: {query_str}\n"
    "Answer: "
)
*/ const defaultTextQaPrompt = ({ context = "", query = "" })=>{
    return `Context information is below.
---------------------
${context}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
const anthropicTextQaPrompt = ({ context = "", query = "" })=>{
    return `Context information:
<context>
${context}
</context>
Given the context information and not prior knowledge, answer the query.
Query: ${query}`;
};
/*
DEFAULT_SUMMARY_PROMPT_TMPL = (
    "Write a summary of the following. Try to use only the "
    "information provided. "
    "Try to include as many key details as possible.\n"
    "\n"
    "\n"
    "{context_str}\n"
    "\n"
    "\n"
    'SUMMARY:"""\n'
)
*/ const defaultSummaryPrompt = ({ context = "" })=>{
    return `Write a summary of the following. Try to use only the information provided. Try to include as many key details as possible.


${context}


SUMMARY:"""
`;
};
/*
DEFAULT_REFINE_PROMPT_TMPL = (
    "The original query is as follows: {query_str}\n"
    "We have provided an existing answer: {existing_answer}\n"
    "We have the opportunity to refine the existing answer "
    "(only if needed) with some more context below.\n"
    "------------\n"
    "{context_msg}\n"
    "------------\n"
    "Given the new context, refine the original answer to better "
    "answer the query. "
    "If the context isn't useful, return the original answer.\n"
    "Refined Answer: "
)
*/ const defaultRefinePrompt = ({ query = "", existingAnswer = "", context = "" })=>{
    return `The original query is as follows: ${query}
We have provided an existing answer: ${existingAnswer}
We have the opportunity to refine the existing answer (only if needed) with some more context below.
------------
${context}
------------
Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.
Refined Answer:`;
};
/*
DEFAULT_TREE_SUMMARIZE_TMPL = (
  "Context information from multiple sources is below.\n"
  "---------------------\n"
  "{context_str}\n"
  "---------------------\n"
  "Given the information from multiple sources and not prior knowledge, "
  "answer the query.\n"
  "Query: {query_str}\n"
  "Answer: "
)
*/ const defaultTreeSummarizePrompt = ({ context = "", query = "" })=>{
    return `Context information from multiple sources is below.
---------------------
${context}
---------------------
Given the information from multiple sources and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
const defaultChoiceSelectPrompt = ({ context = "", query = "" })=>{
    return `A list of documents is shown below. Each document has a number next to it along 
with a summary of the document. A question is also provided.
Respond with the numbers of the documents
you should consult to answer the question, in order of relevance, as well
as the relevance score. The relevance score is a number from 1-10 based on
how relevant you think the document is to the question.
Do not include any documents that are not relevant to the question.
Example format:
Document 1:
<summary of document 1>

Document 2:
<summary of document 2>

...

Document 10:\n<summary of document 10>

Question: <question>
Answer:
Doc: 9, Relevance: 7
Doc: 3, Relevance: 4
Doc: 7, Relevance: 3

Let's try this now:

${context}
Question: ${query}
Answer:`;
};
/*
PREFIX = """\
Given a user question, and a list of tools, output a list of relevant sub-questions \
that when composed can help answer the full user question:

"""


example_query_str = (
    "Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021"
)
example_tools = [
    ToolMetadata(
        name="uber_10k",
        description="Provides information about Uber financials for year 2021",
    ),
    ToolMetadata(
        name="lyft_10k",
        description="Provides information about Lyft financials for year 2021",
    ),
]
example_tools_str = build_tools_text(example_tools)
example_output = [
    SubQuestion(
        sub_question="What is the revenue growth of Uber", tool_name="uber_10k"
    ),
    SubQuestion(sub_question="What is the EBITDA of Uber", tool_name="uber_10k"),
    SubQuestion(
        sub_question="What is the revenue growth of Lyft", tool_name="lyft_10k"
    ),
    SubQuestion(sub_question="What is the EBITDA of Lyft", tool_name="lyft_10k"),
]
example_output_str = json.dumps([x.dict() for x in example_output], indent=4)

EXAMPLES = (
    """\
# Example 1
<Tools>
```json
{tools_str}
```

<User Question>
{query_str}


<Output>
```json
{output_str}
```

""".format(
        query_str=example_query_str,
        tools_str=example_tools_str,
        output_str=example_output_str,
    )
    .replace("{", "{{")
    .replace("}", "}}")
)

SUFFIX = """\
# Example 2
<Tools>
```json
{tools_str}
```

<User Question>
{query_str}

<Output>
"""

DEFAULT_SUB_QUESTION_PROMPT_TMPL = PREFIX + EXAMPLES + SUFFIX
*/ function buildToolsText(tools) {
    const toolsObj = tools.reduce((acc, tool)=>{
        acc[tool.name] = tool.description;
        return acc;
    }, {});
    return JSON.stringify(toolsObj, null, 4);
}
const exampleTools = [
    {
        name: "uber_10k",
        description: "Provides information about Uber financials for year 2021"
    },
    {
        name: "lyft_10k",
        description: "Provides information about Lyft financials for year 2021"
    }
];
const exampleQueryStr = `Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021`;
const exampleOutput = [
    {
        subQuestion: "What is the revenue growth of Uber",
        toolName: "uber_10k"
    },
    {
        subQuestion: "What is the EBITDA of Uber",
        toolName: "uber_10k"
    },
    {
        subQuestion: "What is the revenue growth of Lyft",
        toolName: "lyft_10k"
    },
    {
        subQuestion: "What is the EBITDA of Lyft",
        toolName: "lyft_10k"
    }
];
const defaultSubQuestionPrompt = ({ toolsStr = "", queryStr = "" })=>{
    return `Given a user question, and a list of tools, output a list of relevant sub-questions that when composed can help answer the full user question:

# Example 1
<Tools>
\`\`\`json
${buildToolsText(exampleTools)}
\`\`\`

<User Question>
${exampleQueryStr}

<Output>
\`\`\`json
${JSON.stringify(exampleOutput, null, 4)}
\`\`\`

# Example 2
<Tools>
\`\`\`json
${toolsStr}
\`\`\`

<User Question>
${queryStr}

<Output>
`;
};
// DEFAULT_TEMPLATE = """\
// Given a conversation (between Human and Assistant) and a follow up message from Human, \
// rewrite the message to be a standalone question that captures all relevant context \
// from the conversation.
// <Chat History>
// {chat_history}
// <Follow Up Message>
// {question}
// <Standalone question>
// """
const defaultCondenseQuestionPrompt = ({ chatHistory = "", question = "" })=>{
    return `Given a conversation (between Human and Assistant) and a follow up message from Human, rewrite the message to be a standalone question that captures all relevant context from the conversation.

<Chat History>
${chatHistory}

<Follow Up Message>
${question}

<Standalone question>
`;
};
function messagesToHistoryStr(messages) {
    return messages.reduce((acc, message)=>{
        acc += acc ? "\n" : "";
        if (message.role === "user") {
            acc += `Human: ${message.content}`;
        } else {
            acc += `Assistant: ${message.content}`;
        }
        return acc;
    }, "");
}
const defaultContextSystemPrompt = ({ context = "" })=>{
    return `Context information is below.
---------------------
${context}
---------------------`;
};
const defaultKeywordExtractPrompt = ({ context = "", maxKeywords = 10 })=>{
    return `
Some text is provided below. Given the text, extract up to ${maxKeywords} keywords from the text. Avoid stopwords.
---------------------
${context}
---------------------
Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'
`;
};
const defaultQueryKeywordExtractPrompt = ({ question = "", maxKeywords = 10 })=>{
    return `(
  "A question is provided below. Given the question, extract up to ${maxKeywords} "
  "keywords from the text. Focus on extracting the keywords that we can use "
  "to best lookup answers to the question. Avoid stopwords."
  "---------------------"
  "${question}"
  "---------------------"
  "Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'"
)`;
};

function asyncGeneratorStep$N(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$N(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$N(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$N(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * A ChatHistory is used to keep the state of back and forth chat messages
 */ class ChatHistory {
}
class SimpleChatHistory extends ChatHistory {
    addMessage(message) {
        this.messages.push(message);
    }
    requestMessages(transientMessages) {
        var _this = this;
        return _async_to_generator$N(function*() {
            return [
                ...transientMessages != null ? transientMessages : [],
                ..._this.messages
            ];
        })();
    }
    reset() {
        this.messages = [];
    }
    newMessages() {
        const newMessages = this.messages.slice(this.messagesBefore);
        this.messagesBefore = this.messages.length;
        return newMessages;
    }
    constructor(init){
        super();
        var _init_messages;
        this.messages = (_init_messages = init == null ? void 0 : init.messages) != null ? _init_messages : [];
        this.messagesBefore = this.messages.length;
    }
}
class SummaryChatHistory extends ChatHistory {
    summarize() {
        var _this = this;
        return _async_to_generator$N(function*() {
            // get the conversation messages to create summary
            const messagesToSummarize = _this.calcConversationMessages();
            let promptMessages;
            do {
                promptMessages = [
                    {
                        content: _this.summaryPrompt({
                            context: messagesToHistoryStr(messagesToSummarize)
                        }),
                        role: "user"
                    }
                ];
                // remove oldest message until the chat history is short enough for the context window
                messagesToSummarize.shift();
            }while (_this.llm.tokens(promptMessages) > _this.tokensToSummarize)
            const response = yield _this.llm.chat({
                messages: promptMessages
            });
            return {
                content: response.message.content,
                role: "memory"
            };
        })();
    }
    addMessage(message) {
        this.messages.push(message);
    }
    // Find last summary message
    getLastSummaryIndex() {
        const reversedMessages = this.messages.slice().reverse();
        const index = reversedMessages.findIndex((message)=>message.role === "memory");
        if (index === -1) {
            return null;
        }
        return this.messages.length - 1 - index;
    }
    getLastSummary() {
        const lastSummaryIndex = this.getLastSummaryIndex();
        return lastSummaryIndex ? this.messages[lastSummaryIndex] : null;
    }
    get systemMessages() {
        // get array of all system messages
        return this.messages.filter((message)=>message.role === "system");
    }
    get nonSystemMessages() {
        // get array of all non-system messages
        return this.messages.filter((message)=>message.role !== "system");
    }
    /**
   * Calculates the messages that describe the conversation so far.
   * If there's no memory, all non-system messages are used.
   * If there's a memory, uses all messages after the last summary message.
   */ calcConversationMessages(transformSummary) {
        const lastSummaryIndex = this.getLastSummaryIndex();
        if (!lastSummaryIndex) {
            // there's no memory, so just use all non-system messages
            return this.nonSystemMessages;
        } else {
            // there's a memory, so use all messages after the last summary message
            // and convert summary message so it can be send to the LLM
            const summaryMessage = transformSummary ? {
                content: `Summary of the conversation so far: ${this.messages[lastSummaryIndex].content}`,
                role: "system"
            } : this.messages[lastSummaryIndex];
            return [
                summaryMessage,
                ...this.messages.slice(lastSummaryIndex + 1)
            ];
        }
    }
    calcCurrentRequestMessages(transientMessages) {
        // TODO: check order: currently, we're sending:
        // system messages first, then transient messages and then the messages that describe the conversation so far
        return [
            ...this.systemMessages,
            ...transientMessages ? transientMessages : [],
            ...this.calcConversationMessages(true)
        ];
    }
    requestMessages(transientMessages) {
        var _this = this;
        return _async_to_generator$N(function*() {
            const requestMessages = _this.calcCurrentRequestMessages(transientMessages);
            // get tokens of current request messages and the transient messages
            const tokens = _this.llm.tokens(requestMessages);
            if (tokens > _this.tokensToSummarize) {
                // if there are too many tokens for the next request, call summarize
                const memoryMessage = yield _this.summarize();
                const lastMessage = _this.messages.at(-1);
                if (lastMessage && lastMessage.role === "user") {
                    // if last message is a user message, ensure that it's sent after the new memory message
                    _this.messages.pop();
                    _this.messages.push(memoryMessage);
                    _this.messages.push(lastMessage);
                } else {
                    // otherwise just add the memory message
                    _this.messages.push(memoryMessage);
                }
                // TODO: we still might have too many tokens
                // e.g. too large system messages or transient messages
                // how should we deal with that?
                return _this.calcCurrentRequestMessages(transientMessages);
            }
            return requestMessages;
        })();
    }
    reset() {
        this.messages = [];
    }
    newMessages() {
        const newMessages = this.messages.slice(this.messagesBefore);
        this.messagesBefore = this.messages.length;
        return newMessages;
    }
    constructor(init){
        super();
        var _init_messages;
        this.messages = (_init_messages = init == null ? void 0 : init.messages) != null ? _init_messages : [];
        this.messagesBefore = this.messages.length;
        var _init_summaryPrompt;
        this.summaryPrompt = (_init_summaryPrompt = init == null ? void 0 : init.summaryPrompt) != null ? _init_summaryPrompt : defaultSummaryPrompt;
        var _init_llm;
        this.llm = (_init_llm = init == null ? void 0 : init.llm) != null ? _init_llm : new OpenAI();
        if (!this.llm.metadata.maxTokens) {
            throw new Error("LLM maxTokens is not set. Needed so the summarizer ensures the context window size of the LLM.");
        }
        this.tokensToSummarize = this.llm.metadata.contextWindow - this.llm.metadata.maxTokens;
        if (this.tokensToSummarize < this.llm.metadata.contextWindow * 0.25) {
            throw new Error("The number of tokens that trigger the summarize process are less than 25% of the context window. Try lowering maxTokens or use a model with a larger context window.");
        }
    }
}
function getHistory(chatHistory) {
    if (chatHistory instanceof ChatHistory) {
        return chatHistory;
    }
    return new SimpleChatHistory({
        messages: chatHistory
    });
}

function _extends$9() {
    _extends$9 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$9.apply(this, arguments);
}
exports.NodeRelationship = void 0;
(function(NodeRelationship) {
    NodeRelationship["SOURCE"] = "SOURCE";
    NodeRelationship["PREVIOUS"] = "PREVIOUS";
    NodeRelationship["NEXT"] = "NEXT";
    NodeRelationship["PARENT"] = "PARENT";
    NodeRelationship["CHILD"] = "CHILD";
})(exports.NodeRelationship || (exports.NodeRelationship = {}));
exports.ObjectType = void 0;
(function(ObjectType) {
    ObjectType["TEXT"] = "TEXT";
    ObjectType["IMAGE"] = "IMAGE";
    ObjectType["INDEX"] = "INDEX";
    ObjectType["DOCUMENT"] = "DOCUMENT";
    ObjectType["IMAGE_DOCUMENT"] = "IMAGE_DOCUMENT";
})(exports.ObjectType || (exports.ObjectType = {}));
exports.MetadataMode = void 0;
(function(MetadataMode) {
    MetadataMode["ALL"] = "ALL";
    MetadataMode["EMBED"] = "EMBED";
    MetadataMode["LLM"] = "LLM";
    MetadataMode["NONE"] = "NONE";
})(exports.MetadataMode || (exports.MetadataMode = {}));
/**
 * Generic abstract class for retrievable nodes
 */ class BaseNode {
    get sourceNode() {
        const relationship = this.relationships["SOURCE"];
        if (Array.isArray(relationship)) {
            throw new Error("Source object must be a single RelatedNodeInfo object");
        }
        return relationship;
    }
    get prevNode() {
        const relationship = this.relationships["PREVIOUS"];
        if (Array.isArray(relationship)) {
            throw new Error("Previous object must be a single RelatedNodeInfo object");
        }
        return relationship;
    }
    get nextNode() {
        const relationship = this.relationships["NEXT"];
        if (Array.isArray(relationship)) {
            throw new Error("Next object must be a single RelatedNodeInfo object");
        }
        return relationship;
    }
    get parentNode() {
        const relationship = this.relationships["PARENT"];
        if (Array.isArray(relationship)) {
            throw new Error("Parent object must be a single RelatedNodeInfo object");
        }
        return relationship;
    }
    get childNodes() {
        const relationship = this.relationships["CHILD"];
        if (!Array.isArray(relationship)) {
            throw new Error("Child object must be a an array of RelatedNodeInfo objects");
        }
        return relationship;
    }
    getEmbedding() {
        if (this.embedding === undefined) {
            throw new Error("Embedding not set");
        }
        return this.embedding;
    }
    asRelatedNodeInfo() {
        return {
            nodeId: this.id_,
            metadata: this.metadata,
            hash: this.hash
        };
    }
    /**
   * Called by built in JSON.stringify (see https://javascript.info/json)
   * Properties are read-only as they are not deep-cloned (not necessary for stringification).
   * @see toMutableJSON - use to return a mutable JSON instead
   */ toJSON() {
        return _extends$9({}, this, {
            type: this.getType()
        });
    }
    clone() {
        return jsonToNode(this.toMutableJSON());
    }
    /**
   * Converts the object to a JSON representation.
   * Properties can be safely modified as a deep clone of the properties are created.
   * @return {Record<string, any>} - The JSON representation of the object.
   */ toMutableJSON() {
        return ___namespace.default.cloneDeep(this.toJSON());
    }
    constructor(init){
        /**
   * The unique ID of the Node/Document. The trailing underscore is here
   * to avoid collisions with the id keyword in Python.
   *
   * Set to a UUID by default.
   */ this.id_ = node_crypto.randomUUID();
        // Metadata fields
        this.metadata = {};
        this.excludedEmbedMetadataKeys = [];
        this.excludedLlmMetadataKeys = [];
        this.relationships = {};
        this.hash = "";
        Object.assign(this, init);
    }
}
/**
 * TextNode is the default node type for text. Most common node type in LlamaIndex.TS
 */ class TextNode extends BaseNode {
    /**
   * Generate a hash of the text node.
   * The ID is not part of the hash as it can change independent of content.
   * @returns
   */ generateHash() {
        const hashFunction = node_crypto.createHash("sha256");
        hashFunction.update(`type=${this.getType()}`);
        hashFunction.update(`startCharIdx=${this.startCharIdx} endCharIdx=${this.endCharIdx}`);
        hashFunction.update(this.getContent("ALL"));
        return hashFunction.digest("base64");
    }
    getType() {
        return "TEXT";
    }
    getContent(metadataMode = "NONE") {
        const metadataStr = this.getMetadataStr(metadataMode).trim();
        return `${metadataStr}\n\n${this.text}`.trim();
    }
    getMetadataStr(metadataMode) {
        if (metadataMode === "NONE") {
            return "";
        }
        const usableMetadataKeys = new Set(Object.keys(this.metadata).sort());
        if (metadataMode === "LLM") {
            for (const key of this.excludedLlmMetadataKeys){
                usableMetadataKeys.delete(key);
            }
        } else if (metadataMode === "EMBED") {
            for (const key of this.excludedEmbedMetadataKeys){
                usableMetadataKeys.delete(key);
            }
        }
        return [
            ...usableMetadataKeys
        ].map((key)=>`${key}: ${this.metadata[key]}`).join(this.metadataSeparator);
    }
    setContent(value) {
        this.text = value;
        this.hash = this.generateHash();
    }
    getNodeInfo() {
        return {
            start: this.startCharIdx,
            end: this.endCharIdx
        };
    }
    getText() {
        return this.getContent("NONE");
    }
    constructor(init){
        super(init);
        this.text = "";
        // textTemplate: NOTE write your own formatter if needed
        // metadataTemplate: NOTE write your own formatter if needed
        this.metadataSeparator = "\n";
        Object.assign(this, init);
        if (new.target === TextNode) {
            // Don't generate the hash repeatedly so only do it if this is
            // constructing the derived class
            this.hash = this.generateHash();
        }
    }
}
class IndexNode extends TextNode {
    getType() {
        return "INDEX";
    }
    constructor(init){
        super(init);
        this.indexId = "";
        Object.assign(this, init);
        if (new.target === IndexNode) {
            this.hash = this.generateHash();
        }
    }
}
/**
 * A document is just a special text node with a docId.
 */ class Document extends TextNode {
    getType() {
        return "DOCUMENT";
    }
    constructor(init){
        super(init);
        Object.assign(this, init);
        if (new.target === Document) {
            this.hash = this.generateHash();
        }
    }
}
function jsonToNode(json, type) {
    if (!json.type && !type) {
        throw new Error("Node type not found");
    }
    const nodeType = type || json.type;
    switch(nodeType){
        case "TEXT":
            return new TextNode(json);
        case "INDEX":
            return new IndexNode(json);
        case "DOCUMENT":
            return new Document(json);
        case "IMAGE_DOCUMENT":
            return new ImageDocument(json);
        default:
            throw new Error(`Invalid node type: ${nodeType}`);
    }
}
class ImageNode extends TextNode {
    getType() {
        return "IMAGE";
    }
    getUrl() {
        // id_ stores the relative path, convert it to the URL of the file
        const absPath = path__default.default.resolve(this.id_);
        return new URL(`file://${absPath}`);
    }
    constructor(init){
        super(init);
        this.image = init.image;
    }
}
class ImageDocument extends ImageNode {
    getType() {
        return "IMAGE_DOCUMENT";
    }
    constructor(init){
        super(init);
        if (new.target === ImageDocument) {
            this.hash = this.generateHash();
        }
    }
}
function splitNodesByType(nodes) {
    let imageNodes = [];
    let textNodes = [];
    for (let node of nodes){
        if (node instanceof ImageNode) {
            imageNodes.push(node);
        } else if (node instanceof TextNode) {
            textNodes.push(node);
        }
    }
    return {
        imageNodes,
        textNodes
    };
}

/**
 * Error class for output parsing. Due to the nature of LLMs, anytime we use LLM
 * to generate structured output, it's possible that it will hallucinate something
 * that doesn't match the expected output format. So make sure to catch these
 * errors in production.
 */ class OutputParserError extends Error {
    constructor(message, options = {}){
        // @ts-ignore
        super(message, options); // https://github.com/tc39/proposal-error-cause
        this.name = "OutputParserError";
        if (!this.cause) {
            // Need to check for those environments that have implemented the proposal
            this.cause = options.cause;
        }
        this.output = options.output;
        // This line is to maintain proper stack trace in V8
        // (https://v8.dev/docs/stack-trace-api)
        if (Error.captureStackTrace) {
            Error.captureStackTrace(this, OutputParserError);
        }
    }
}
/**
 *
 * @param text A markdown block with JSON
 * @returns parsed JSON object
 */ function parseJsonMarkdown(text) {
    text = text.trim();
    const left_square = text.indexOf("[");
    const left_brace = text.indexOf("{");
    var left;
    var right;
    if (left_square < left_brace && left_square != -1) {
        left = left_square;
        right = text.lastIndexOf("]");
    } else {
        left = left_brace;
        right = text.lastIndexOf("}");
    }
    const jsonText = text.substring(left, right + 1);
    try {
        //Single JSON object case
        if (left_square === -1) {
            return [
                JSON.parse(jsonText)
            ];
        }
        //Multiple JSON object case.
        return JSON.parse(jsonText);
    } catch (e) {
        throw new OutputParserError("Not a json markdown", {
            output: text
        });
    }
}
/**
 * SubQuestionOutputParser is used to parse the output of the SubQuestionGenerator.
 */ class SubQuestionOutputParser {
    parse(output) {
        const parsed = parseJsonMarkdown(output);
        // TODO add zod validation
        return {
            rawOutput: output,
            parsedOutput: parsed
        };
    }
    format(output) {
        return output;
    }
}

const DEFAULT_CONTEXT_WINDOW = 3900;
const DEFAULT_NUM_OUTPUTS = 256;
const DEFAULT_CHUNK_SIZE = 1024;
const DEFAULT_CHUNK_OVERLAP = 20;
const DEFAULT_CHUNK_OVERLAP_RATIO = 0.1;
const DEFAULT_SIMILARITY_TOP_K = 2;
// NOTE: for text-embedding-ada-002
const DEFAULT_EMBEDDING_DIM = 1536;
const DEFAULT_PADDING = 5;

class TextSplit {
    constructor(textChunk, numCharOverlap = undefined){
        this.textChunk = textChunk;
        this.numCharOverlap = numCharOverlap;
    }
}
const defaultregex = /[.?!][\])'"`’”]*(?:\s|$)/g;
const defaultSentenceTokenizer = (text)=>{
    const slist = [];
    const iter = text.matchAll(defaultregex);
    let lastIdx = 0;
    for (const match of iter){
        slist.push(text.slice(lastIdx, match.index + 1));
        lastIdx = match.index + 1;
    }
    slist.push(text.slice(lastIdx));
    return slist.filter((s)=>s.length > 0);
};
// Refs: https://github.com/fxsjy/jieba/issues/575#issuecomment-359637511
const resentencesp = /([﹒﹔﹖﹗．；。！？]["’”」』]{0,2}|：(?=["‘“「『]{1,2}|$))/;
/**
 * Tokenizes sentences. Suitable for Chinese, Japanese, and Korean. Use instead of `defaultSentenceTokenizer`.
 * @param text
 * @returns string[]
 */ function cjkSentenceTokenizer(sentence) {
    const slist = [];
    const parts = sentence.split(resentencesp);
    for(let i = 0; i < parts.length; i++){
        const part = parts[i];
        if (resentencesp.test(part) && slist.length > 0) {
            slist[slist.length - 1] += part;
        } else if (part) {
            slist.push(part);
        }
    }
    return slist.filter((s)=>s.length > 0);
}
const defaultParagraphSeparator = node_os.EOL + node_os.EOL + node_os.EOL;
// In theory there's also Mac style \r only, but it's pre-OSX and I don't think
// many documents will use it.
/**
 * SentenceSplitter is our default text splitter that supports splitting into sentences, paragraphs, or fixed length chunks with overlap.
 *
 * One of the advantages of SentenceSplitter is that even in the fixed length chunks it will try to keep sentences together.
 */ class SentenceSplitter {
    getEffectiveChunkSize(extraInfoStr) {
        // get "effective" chunk size by removing the metadata
        let effectiveChunkSize;
        if (extraInfoStr != undefined) {
            const numExtraTokens = this.tokenizer(`${extraInfoStr}\n\n`).length + 1;
            effectiveChunkSize = this.chunkSize - numExtraTokens;
            if (effectiveChunkSize <= 0) {
                throw new Error("Effective chunk size is non positive after considering extra_info");
            }
        } else {
            effectiveChunkSize = this.chunkSize;
        }
        return effectiveChunkSize;
    }
    getParagraphSplits(text, effectiveChunkSize) {
        // get paragraph splits
        let paragraphSplits = text.split(this.paragraphSeparator);
        let idx = 0;
        if (effectiveChunkSize == undefined) {
            return paragraphSplits;
        }
        // merge paragraphs that are too small
        while(idx < paragraphSplits.length){
            if (idx < paragraphSplits.length - 1 && paragraphSplits[idx].length < effectiveChunkSize) {
                paragraphSplits[idx] = [
                    paragraphSplits[idx],
                    paragraphSplits[idx + 1]
                ].join(this.paragraphSeparator);
                paragraphSplits.splice(idx + 1, 1);
            } else {
                idx += 1;
            }
        }
        return paragraphSplits;
    }
    getSentenceSplits(text, effectiveChunkSize) {
        let paragraphSplits = this.getParagraphSplits(text, effectiveChunkSize);
        // Next we split the text using the chunk tokenizer fn/
        let splits = [];
        for (const parText of paragraphSplits){
            const sentenceSplits = this.chunkingTokenizerFn(parText);
            if (!sentenceSplits) {
                continue;
            }
            for (const sentence_split of sentenceSplits){
                splits.push(sentence_split.trim());
            }
        }
        return splits;
    }
    /**
   * Splits sentences into chunks if necessary.
   *
   * This isn't great behavior because it can split down the middle of a
   * word or in non-English split down the middle of a Unicode codepoint
   * so the splitting is turned off by default. If you need it, please
   * set the splitLongSentences option to true.
   * @param sentenceSplits
   * @param effectiveChunkSize
   * @returns
   */ processSentenceSplits(sentenceSplits, effectiveChunkSize) {
        if (!this.splitLongSentences) {
            return sentenceSplits.map((split)=>({
                    text: split,
                    numTokens: this.tokenizer(split).length
                }));
        }
        let newSplits = [];
        for (const split of sentenceSplits){
            let splitTokens = this.tokenizer(split);
            const splitLen = splitTokens.length;
            if (splitLen <= effectiveChunkSize) {
                newSplits.push({
                    text: split,
                    numTokens: splitLen
                });
            } else {
                for(let i = 0; i < splitLen; i += effectiveChunkSize){
                    const cur_split = this.tokenizerDecoder(splitTokens.slice(i, i + effectiveChunkSize));
                    newSplits.push({
                        text: cur_split,
                        numTokens: effectiveChunkSize
                    });
                }
            }
        }
        return newSplits;
    }
    combineTextSplits(newSentenceSplits, effectiveChunkSize) {
        // go through sentence splits, combine to chunks that are within the chunk size
        // docs represents final list of text chunks
        let docs = [];
        // curChunkSentences represents the current list of sentence splits (that)
        // will be merged into a chunk
        let curChunkSentences = [];
        let curChunkTokens = 0;
        for(let i = 0; i < newSentenceSplits.length; i++){
            // if adding newSentenceSplits[i] to curDocBuffer would exceed effectiveChunkSize,
            // then we need to add the current curDocBuffer to docs
            if (curChunkTokens + newSentenceSplits[i].numTokens > effectiveChunkSize) {
                if (curChunkSentences.length > 0) {
                    // push curent doc list to docs
                    docs.push(new TextSplit(curChunkSentences.map((sentence)=>sentence.text).join(" ").trim()));
                }
                const lastChunkSentences = curChunkSentences;
                // reset docs list
                curChunkTokens = 0;
                curChunkSentences = [];
                // add the last sentences from the last chunk until we've hit the overlap
                // do it in reverse order
                for(let j = lastChunkSentences.length - 1; j >= 0; j--){
                    if (curChunkTokens + lastChunkSentences[j].numTokens > this.chunkOverlap) {
                        break;
                    }
                    curChunkSentences.unshift(lastChunkSentences[j]);
                    curChunkTokens += lastChunkSentences[j].numTokens + 1;
                }
            }
            curChunkSentences.push(newSentenceSplits[i]);
            curChunkTokens += newSentenceSplits[i].numTokens + 1;
        }
        docs.push(new TextSplit(curChunkSentences.map((sentence)=>sentence.text).join(" ").trim()));
        return docs;
    }
    splitTextWithOverlaps(text, extraInfoStr) {
        // Split incoming text and return chunks with overlap size.
        // Has a preference for complete sentences, phrases, and minimal overlap.
        // here is the typescript code (skip callback manager)
        if (text == "") {
            return [];
        }
        let effectiveChunkSize = this.getEffectiveChunkSize(extraInfoStr);
        let sentenceSplits = this.getSentenceSplits(text, effectiveChunkSize);
        // Check if any sentences exceed the chunk size. If they don't,
        // force split by tokenizer
        let newSentenceSplits = this.processSentenceSplits(sentenceSplits, effectiveChunkSize);
        // combine sentence splits into chunks of text that can then be returned
        let combinedTextSplits = this.combineTextSplits(newSentenceSplits, effectiveChunkSize);
        return combinedTextSplits;
    }
    splitText(text, extraInfoStr) {
        const text_splits = this.splitTextWithOverlaps(text);
        const chunks = text_splits.map((text_split)=>text_split.textChunk);
        return chunks;
    }
    constructor(options){
        const { chunkSize = DEFAULT_CHUNK_SIZE, chunkOverlap = DEFAULT_CHUNK_OVERLAP, tokenizer = null, tokenizerDecoder = null, paragraphSeparator = defaultParagraphSeparator, chunkingTokenizerFn, splitLongSentences = false } = options != null ? options : {};
        if (chunkOverlap > chunkSize) {
            throw new Error(`Got a larger chunk overlap (${chunkOverlap}) than chunk size (${chunkSize}), should be smaller.`);
        }
        this.chunkSize = chunkSize;
        this.chunkOverlap = chunkOverlap;
        // this._callback_manager = callback_manager || new CallbackManager([]);
        this.tokenizer = tokenizer != null ? tokenizer : globalsHelper.tokenizer();
        this.tokenizerDecoder = tokenizerDecoder != null ? tokenizerDecoder : globalsHelper.tokenizerDecoder();
        this.paragraphSeparator = paragraphSeparator;
        this.chunkingTokenizerFn = chunkingTokenizerFn != null ? chunkingTokenizerFn : defaultSentenceTokenizer;
        this.splitLongSentences = splitLongSentences;
    }
}

function getEmptyPromptTxt(prompt) {
    return prompt({});
}
/**
 * Get biggest empty prompt size from a list of prompts.
 * Used to calculate the maximum size of inputs to the LLM.
 * @param prompts
 * @returns
 */ function getBiggestPrompt(prompts) {
    const emptyPromptTexts = prompts.map(getEmptyPromptTxt);
    const emptyPromptLengths = emptyPromptTexts.map((text)=>text.length);
    const maxEmptyPromptLength = Math.max(...emptyPromptLengths);
    const maxEmptyPromptIndex = emptyPromptLengths.indexOf(maxEmptyPromptLength);
    return prompts[maxEmptyPromptIndex];
}
/**
 * A collection of helper functions for working with prompts.
 */ class PromptHelper {
    /**
   * Given a prompt, return the maximum size of the inputs to the prompt.
   * @param prompt
   * @returns
   */ getAvailableContextSize(prompt) {
        const emptyPromptText = getEmptyPromptTxt(prompt);
        const promptTokens = this.tokenizer(emptyPromptText);
        const numPromptTokens = promptTokens.length;
        return this.contextWindow - numPromptTokens - this.numOutput;
    }
    /**
   * Find the maximum size of each chunk given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */ getAvailableChunkSize(prompt, numChunks = 1, padding = 5) {
        const availableContextSize = this.getAvailableContextSize(prompt);
        const result = Math.floor(availableContextSize / numChunks) - padding;
        if (this.chunkSizeLimit) {
            return Math.min(this.chunkSizeLimit, result);
        } else {
            return result;
        }
    }
    /**
   * Creates a text splitter with the correct chunk sizes and overlaps given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */ getTextSplitterGivenPrompt(prompt, numChunks = 1, padding = DEFAULT_PADDING) {
        const chunkSize = this.getAvailableChunkSize(prompt, numChunks, padding);
        if (chunkSize === 0) {
            throw new Error("Got 0 as available chunk size");
        }
        const chunkOverlap = this.chunkOverlapRatio * chunkSize;
        const textSplitter = new SentenceSplitter({
            chunkSize,
            chunkOverlap
        });
        return textSplitter;
    }
    /**
   * Repack resplits the strings based on the optimal text splitter.
   * @param prompt
   * @param textChunks
   * @param padding
   * @returns
   */ repack(prompt, textChunks, padding = DEFAULT_PADDING) {
        const textSplitter = this.getTextSplitterGivenPrompt(prompt, 1, padding);
        const combinedStr = textChunks.join("\n\n");
        return textSplitter.splitText(combinedStr);
    }
    // eslint-disable-next-line max-params
    constructor(contextWindow = DEFAULT_CONTEXT_WINDOW, numOutput = DEFAULT_NUM_OUTPUTS, chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO, chunkSizeLimit, tokenizer, separator = " "){
        this.contextWindow = DEFAULT_CONTEXT_WINDOW;
        this.numOutput = DEFAULT_NUM_OUTPUTS;
        this.chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO;
        this.separator = " ";
        this.contextWindow = contextWindow;
        this.numOutput = numOutput;
        this.chunkOverlapRatio = chunkOverlapRatio;
        this.chunkSizeLimit = chunkSizeLimit;
        this.tokenizer = tokenizer || globalsHelper.tokenizer();
        this.separator = separator;
    }
}

function asyncGeneratorStep$M(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$M(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$M(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$M(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * LLMQuestionGenerator uses the LLM to generate new questions for the LLM using tools and a user query.
 */ class LLMQuestionGenerator {
    generate(tools, query) {
        var _this = this;
        return _async_to_generator$M(function*() {
            const toolsStr = buildToolsText(tools);
            const queryStr = query;
            const prediction = (yield _this.llm.complete({
                prompt: _this.prompt({
                    toolsStr,
                    queryStr
                })
            })).text;
            const structuredOutput = _this.outputParser.parse(prediction);
            return structuredOutput.parsedOutput;
        })();
    }
    constructor(init){
        var _init_llm;
        this.llm = (_init_llm = init == null ? void 0 : init.llm) != null ? _init_llm : new OpenAI();
        var _init_prompt;
        this.prompt = (_init_prompt = init == null ? void 0 : init.prompt) != null ? _init_prompt : defaultSubQuestionPrompt;
        var _init_outputParser;
        this.outputParser = (_init_outputParser = init == null ? void 0 : init.outputParser) != null ? _init_outputParser : new SubQuestionOutputParser();
    }
}

class CallbackManager {
    constructor(handlers){
        this.onLLMStream = handlers == null ? void 0 : handlers.onLLMStream;
        this.onRetrieve = handlers == null ? void 0 : handlers.onRetrieve;
    }
}

function _async_generator$2(gen) {
    var front, back;
    function send(key, arg) {
        return new Promise(function(resolve, reject) {
            var request = {
                key: key,
                arg: arg,
                resolve: resolve,
                reject: reject,
                next: null
            };
            if (back) {
                back = back.next = request;
            } else {
                front = back = request;
                resume(key, arg);
            }
        });
    }
    function resume(key, arg) {
        try {
            var result = gen[key](arg);
            var value = result.value;
            var wrappedAwait = value instanceof _await_value$2;
            Promise.resolve(wrappedAwait ? value.wrapped : value).then(function(arg) {
                if (wrappedAwait) {
                    resume("next", arg);
                    return;
                }
                settle(result.done ? "return" : "normal", arg);
            }, function(err) {
                resume("throw", err);
            });
        } catch (err) {
            settle("throw", err);
        }
    }
    function settle(type, value) {
        switch(type){
            case "return":
                front.resolve({
                    value: value,
                    done: true
                });
                break;
            case "throw":
                front.reject(value);
                break;
            default:
                front.resolve({
                    value: value,
                    done: false
                });
                break;
        }
        front = front.next;
        if (front) {
            resume(front.key, front.arg);
        } else {
            back = null;
        }
    }
    this._invoke = send;
    if (typeof gen.return !== "function") {
        this.return = undefined;
    }
}
if (typeof Symbol === "function" && Symbol.asyncIterator) {
    _async_generator$2.prototype[Symbol.asyncIterator] = function() {
        return this;
    };
}
_async_generator$2.prototype.next = function(arg) {
    return this._invoke("next", arg);
};
_async_generator$2.prototype.throw = function(arg) {
    return this._invoke("throw", arg);
};
_async_generator$2.prototype.return = function(arg) {
    return this._invoke("return", arg);
};
function _async_generator_delegate(inner, awaitWrap) {
    var iter = {}, waiting = false;
    function pump(key, value) {
        waiting = true;
        value = new Promise(function(resolve) {
            resolve(inner[key](value));
        });
        return {
            done: false,
            value: awaitWrap(value)
        };
    }
    if (typeof Symbol === "function" && Symbol.iterator) {
        iter[Symbol.iterator] = function() {
            return this;
        };
    }
    iter.next = function(value) {
        if (waiting) {
            waiting = false;
            return value;
        }
        return pump("next", value);
    };
    if (typeof inner.throw === "function") {
        iter.throw = function(value) {
            if (waiting) {
                waiting = false;
                throw value;
            }
            return pump("throw", value);
        };
    }
    if (typeof inner.return === "function") {
        iter.return = function(value) {
            return pump("return", value);
        };
    }
    return iter;
}
function _async_iterator$4(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$4(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$4(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$4 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$4.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$4(s);
}
function asyncGeneratorStep$L(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$L(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$L(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$L(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _await_async_generator$2(value) {
    return new _await_value$2(value);
}
function _await_value$2(value) {
    this.wrapped = value;
}
function _wrap_async_generator$2(fn) {
    return function() {
        return new _async_generator$2(fn.apply(this, arguments));
    };
}
/**
 * A filesystem implementation that stores files in memory.
 */ class InMemoryFileSystem {
    writeFile(path, content, options) {
        var _this = this;
        return _async_to_generator$L(function*() {
            _this.files[path] = ___namespace.default.cloneDeep(content);
        })();
    }
    readFile(path, options) {
        var _this = this;
        return _async_to_generator$L(function*() {
            if (!(path in _this.files)) {
                throw new Error(`File ${path} does not exist`);
            }
            return ___namespace.default.cloneDeep(_this.files[path]);
        })();
    }
    access(path) {
        var _this = this;
        return _async_to_generator$L(function*() {
            if (!(path in _this.files)) {
                throw new Error(`File ${path} does not exist`);
            }
        })();
    }
    mkdir(path, options) {
        var _this = this;
        return _async_to_generator$L(function*() {
            _this.files[path] = ___namespace.default.get(_this.files, path, null);
        })();
    }
    constructor(){
        this.files = {};
    }
}
function getNodeFS() {
    const fs = require("fs/promises");
    return fs;
}
let fs = null;
try {
    fs = getNodeFS();
} catch (e) {
    fs = new InMemoryFileSystem();
}
const DEFAULT_FS = fs;
// FS utility functions
/**
 * Checks if a file exists.
 * Analogous to the os.path.exists function from Python.
 * @param fs The filesystem to use.
 * @param path The path to the file to check.
 * @returns A promise that resolves to true if the file exists, false otherwise.
 */ function exists(fs, path) {
    return _exists.apply(this, arguments);
}
function _exists() {
    _exists = _async_to_generator$L(function*(fs, path) {
        try {
            yield fs.access(path);
            return true;
        } catch (e) {
            return false;
        }
    });
    return _exists.apply(this, arguments);
}
/**
 * Recursively traverses a directory and yields all the paths to the files in it.
 * @param fs The filesystem to use.
 * @param dirPath The path to the directory to traverse.
 */ function walk(fs, dirPath) {
    return _walk.apply(this, arguments);
}
function _walk() {
    _walk = _wrap_async_generator$2(function*(fs, dirPath) {
        if (fs instanceof InMemoryFileSystem) {
            throw new Error("The InMemoryFileSystem does not support directory traversal.");
        }
        const entries = yield _await_async_generator$2(fs.readdir(dirPath));
        for (const entry of entries){
            const fullPath = `${dirPath}/${entry}`;
            const stats = yield _await_async_generator$2(fs.stat(fullPath));
            if (stats.isDirectory()) {
                yield* _async_generator_delegate(_async_iterator$4(walk(fs, fullPath)), _await_async_generator$2);
            } else {
                yield fullPath;
            }
        }
    });
    return _walk.apply(this, arguments);
}

const DEFAULT_COLLECTION = "data";
const DEFAULT_PERSIST_DIR = "./storage";
const DEFAULT_INDEX_STORE_PERSIST_FILENAME = "index_store.json";
const DEFAULT_DOC_STORE_PERSIST_FILENAME = "doc_store.json";
const DEFAULT_VECTOR_STORE_PERSIST_FILENAME = "vector_store.json";
const DEFAULT_GRAPH_STORE_PERSIST_FILENAME = "graph_store.json";
const DEFAULT_NAMESPACE = "docstore";
const DEFAULT_IMAGE_VECTOR_NAMESPACE = "images";

class BaseKVStore {
}
class BaseInMemoryKVStore extends BaseKVStore {
    static fromPersistPath(persistPath) {
        throw new Error("Method not implemented.");
    }
}

function asyncGeneratorStep$K(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$K(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$K(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$K(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class SimpleKVStore extends BaseKVStore {
    put(key, val, collection = DEFAULT_COLLECTION) {
        var _this = this;
        return _async_to_generator$K(function*() {
            if (!(collection in _this.data)) {
                _this.data[collection] = {};
            }
            _this.data[collection][key] = ___namespace.default.clone(val); // Creating a shallow copy of the object
            if (_this.persistPath) {
                yield _this.persist(_this.persistPath, _this.fs);
            }
        })();
    }
    get(key, collection = DEFAULT_COLLECTION) {
        var _this = this;
        return _async_to_generator$K(function*() {
            let collectionData = _this.data[collection];
            if (___namespace.default.isNil(collectionData)) {
                return null;
            }
            if (!(key in collectionData)) {
                return null;
            }
            return ___namespace.default.clone(collectionData[key]); // Creating a shallow copy of the object
        })();
    }
    getAll(collection = DEFAULT_COLLECTION) {
        var _this = this;
        return _async_to_generator$K(function*() {
            return ___namespace.default.clone(_this.data[collection]); // Creating a shallow copy of the object
        })();
    }
    delete(key, collection = DEFAULT_COLLECTION) {
        var _this = this;
        return _async_to_generator$K(function*() {
            if (key in _this.data[collection]) {
                delete _this.data[collection][key];
                return true;
            }
            return false;
        })();
    }
    persist(persistPath, fs) {
        var _this = this;
        return _async_to_generator$K(function*() {
            fs = fs || DEFAULT_FS;
            // TODO: decide on a way to polyfill path
            let dirPath = path__default$1.default.dirname(persistPath);
            if (!(yield exists(fs, dirPath))) {
                yield fs.mkdir(dirPath);
            }
            yield fs.writeFile(persistPath, JSON.stringify(_this.data));
        })();
    }
    static fromPersistPath(persistPath, fs) {
        return _async_to_generator$K(function*() {
            fs = fs || DEFAULT_FS;
            let dirPath = path__default$1.default.dirname(persistPath);
            if (!(yield exists(fs, dirPath))) {
                yield fs.mkdir(dirPath);
            }
            let data = {};
            try {
                let fileData = yield fs.readFile(persistPath);
                data = JSON.parse(fileData.toString());
            } catch (e) {
                console.error(`No valid data found at path: ${persistPath} starting new store.`);
            }
            const store = new SimpleKVStore(data);
            store.persistPath = persistPath;
            store.fs = fs;
            return store;
        })();
    }
    toDict() {
        return this.data;
    }
    static fromDict(saveDict) {
        return new SimpleKVStore(saveDict);
    }
    constructor(data){
        super();
        this.data = data || {};
    }
}

function asyncGeneratorStep$J(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$J(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$J(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$J(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const defaultPersistPath$1 = `${DEFAULT_PERSIST_DIR}/${DEFAULT_DOC_STORE_PERSIST_FILENAME}`;
class BaseDocumentStore {
    // Save/load
    persist(persistPath = defaultPersistPath$1, fs) {
    // Persist the docstore to a file.
    }
    // Nodes
    getNodes(nodeIds, raiseError = true) {
        return Promise.all(nodeIds.map((nodeId)=>this.getNode(nodeId, raiseError)));
    }
    getNode(nodeId, raiseError = true) {
        var _this = this;
        return _async_to_generator$J(function*() {
            let doc = yield _this.getDocument(nodeId, raiseError);
            if (!(doc instanceof BaseNode)) {
                throw new Error(`Document ${nodeId} is not a Node.`);
            }
            return doc;
        })();
    }
    getNodeDict(nodeIdDict) {
        var _this = this;
        return _async_to_generator$J(function*() {
            let result = {};
            for(let index in nodeIdDict){
                result[index] = yield _this.getNode(nodeIdDict[index]);
            }
            return result;
        })();
    }
}

const TYPE_KEY = "__type__";
const DATA_KEY = "__data__";
function docToJson(doc) {
    return {
        [DATA_KEY]: JSON.stringify(doc),
        [TYPE_KEY]: doc.getType()
    };
}
function jsonToDoc(docDict) {
    let docType = docDict[TYPE_KEY];
    let dataDict = JSON.parse(docDict[DATA_KEY]);
    let doc;
    if (docType === exports.ObjectType.DOCUMENT) {
        doc = new Document({
            text: dataDict.text,
            id_: dataDict.id_,
            embedding: dataDict.embedding,
            hash: dataDict.hash,
            metadata: dataDict.metadata
        });
    } else if (docType === exports.ObjectType.TEXT) {
        doc = new TextNode({
            text: dataDict.text,
            id_: dataDict.id_,
            hash: dataDict.hash,
            metadata: dataDict.metadata
        });
    } else {
        throw new Error(`Unknown doc type: ${docType}`);
    }
    return doc;
}

function asyncGeneratorStep$I(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$I(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$I(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$I(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class KVDocumentStore extends BaseDocumentStore {
    docs() {
        var _this = this;
        return _async_to_generator$I(function*() {
            let jsonDict = yield _this.kvstore.getAll(_this.nodeCollection);
            let docs = {};
            for(let key in jsonDict){
                docs[key] = jsonToDoc(jsonDict[key]);
            }
            return docs;
        })();
    }
    addDocuments(docs, allowUpdate = true) {
        var _this = this;
        return _async_to_generator$I(function*() {
            for(var idx = 0; idx < docs.length; idx++){
                const doc = docs[idx];
                if (doc.id_ === null) {
                    throw new Error("doc_id not set");
                }
                if (!allowUpdate && (yield _this.documentExists(doc.id_))) {
                    throw new Error(`doc_id ${doc.id_} already exists. Set allow_update to True to overwrite.`);
                }
                let nodeKey = doc.id_;
                let data = docToJson(doc);
                yield _this.kvstore.put(nodeKey, data, _this.nodeCollection);
                let metadata = {
                    docHash: doc.hash
                };
                if (doc.getType() === exports.ObjectType.TEXT && doc.sourceNode !== undefined) {
                    let refDocInfo = (yield _this.getRefDocInfo(doc.sourceNode.nodeId)) || {
                        nodeIds: [],
                        extraInfo: {}
                    };
                    refDocInfo.nodeIds.push(doc.id_);
                    if (___namespace.default.isEmpty(refDocInfo.extraInfo)) {
                        refDocInfo.extraInfo = {};
                    }
                    yield _this.kvstore.put(doc.sourceNode.nodeId, refDocInfo, _this.refDocCollection);
                    metadata.refDocId = doc.sourceNode.nodeId;
                }
                _this.kvstore.put(nodeKey, metadata, _this.metadataCollection);
            }
        })();
    }
    getDocument(docId, raiseError = true) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let json = yield _this.kvstore.get(docId, _this.nodeCollection);
            if (___namespace.default.isNil(json)) {
                if (raiseError) {
                    throw new Error(`docId ${docId} not found.`);
                } else {
                    return;
                }
            }
            return jsonToDoc(json);
        })();
    }
    getRefDocInfo(refDocId) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let refDocInfo = yield _this.kvstore.get(refDocId, _this.refDocCollection);
            return refDocInfo ? ___namespace.default.clone(refDocInfo) : undefined;
        })();
    }
    getAllRefDocInfo() {
        var _this = this;
        return _async_to_generator$I(function*() {
            let refDocInfos = yield _this.kvstore.getAll(_this.refDocCollection);
            if (___namespace.default.isNil(refDocInfos)) {
                return;
            }
            return refDocInfos;
        })();
    }
    refDocExists(refDocId) {
        var _this = this;
        return _async_to_generator$I(function*() {
            return !___namespace.default.isNil((yield _this.getRefDocInfo(refDocId)));
        })();
    }
    documentExists(docId) {
        var _this = this;
        return _async_to_generator$I(function*() {
            return !___namespace.default.isNil((yield _this.kvstore.get(docId, _this.nodeCollection)));
        })();
    }
    removeRefDocNode(docId) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let metadata = yield _this.kvstore.get(docId, _this.metadataCollection);
            if (metadata === null) {
                return;
            }
            let refDocId = metadata.refDocId;
            if (___namespace.default.isNil(refDocId)) {
                return;
            }
            const refDocInfo = yield _this.kvstore.get(refDocId, _this.refDocCollection);
            if (!___namespace.default.isNil(refDocInfo)) {
                ___namespace.pull(refDocInfo.docIds, docId);
                if (refDocInfo.docIds.length > 0) {
                    _this.kvstore.put(refDocId, refDocInfo.toDict(), _this.refDocCollection);
                }
                _this.kvstore.delete(refDocId, _this.metadataCollection);
            }
        })();
    }
    deleteDocument(docId, raiseError = true, removeRefDocNode = true) {
        var _this = this;
        return _async_to_generator$I(function*() {
            if (removeRefDocNode) {
                yield _this.removeRefDocNode(docId);
            }
            let deleteSuccess = yield _this.kvstore.delete(docId, _this.nodeCollection);
            yield _this.kvstore.delete(docId, _this.metadataCollection);
            if (!deleteSuccess && raiseError) {
                throw new Error(`doc_id ${docId} not found.`);
            }
        })();
    }
    deleteRefDoc(refDocId, raiseError = true) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let refDocInfo = yield _this.getRefDocInfo(refDocId);
            if (___namespace.default.isNil(refDocInfo)) {
                if (raiseError) {
                    throw new Error(`ref_doc_id ${refDocId} not found.`);
                } else {
                    return;
                }
            }
            for (let docId of refDocInfo.nodeIds){
                yield _this.deleteDocument(docId, false, false);
            }
            yield _this.kvstore.delete(refDocId, _this.metadataCollection);
            yield _this.kvstore.delete(refDocId, _this.refDocCollection);
        })();
    }
    setDocumentHash(docId, docHash) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let metadata = {
                docHash: docHash
            };
            yield _this.kvstore.put(docId, metadata, _this.metadataCollection);
        })();
    }
    getDocumentHash(docId) {
        var _this = this;
        return _async_to_generator$I(function*() {
            let metadata = yield _this.kvstore.get(docId, _this.metadataCollection);
            return ___namespace.default.get(metadata, "docHash");
        })();
    }
    constructor(kvstore, namespace = DEFAULT_NAMESPACE){
        super();
        this.kvstore = kvstore;
        this.nodeCollection = `${namespace}/data`;
        this.refDocCollection = `${namespace}/ref_doc_info`;
        this.metadataCollection = `${namespace}/metadata`;
    }
}

function asyncGeneratorStep$H(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$H(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$H(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$H(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class SimpleDocumentStore extends KVDocumentStore {
    static fromPersistDir(persistDir = DEFAULT_PERSIST_DIR, namespace, fsModule) {
        return _async_to_generator$H(function*() {
            const persistPath = path__default$1.default.join(persistDir, DEFAULT_DOC_STORE_PERSIST_FILENAME);
            return yield SimpleDocumentStore.fromPersistPath(persistPath, namespace, fsModule);
        })();
    }
    static fromPersistPath(persistPath, namespace, fs) {
        return _async_to_generator$H(function*() {
            fs = fs || DEFAULT_FS;
            const simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs);
            return new SimpleDocumentStore(simpleKVStore, namespace);
        })();
    }
    persist(persistPath = path__default$1.default.join(DEFAULT_PERSIST_DIR, DEFAULT_DOC_STORE_PERSIST_FILENAME), fs) {
        var _this = this;
        return _async_to_generator$H(function*() {
            fs = fs || DEFAULT_FS;
            if (___namespace.default.isObject(_this.kvStore) && _this.kvStore instanceof BaseInMemoryKVStore) {
                yield _this.kvStore.persist(persistPath, fs);
            }
        })();
    }
    static fromDict(saveDict, namespace) {
        const simpleKVStore = SimpleKVStore.fromDict(saveDict);
        return new SimpleDocumentStore(simpleKVStore, namespace);
    }
    toDict() {
        if (___namespace.default.isObject(this.kvStore) && this.kvStore instanceof SimpleKVStore) {
            return this.kvStore.toDict();
        }
        // If the kvstore is not a SimpleKVStore, you might want to throw an error or return a default value.
        throw new Error("KVStore is not a SimpleKVStore");
    }
    constructor(kvStore, namespace){
        kvStore = kvStore || new SimpleKVStore();
        namespace = namespace || DEFAULT_NAMESPACE;
        super(kvStore, namespace);
        this.kvStore = kvStore;
    }
}

function asyncGeneratorStep$G(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$G(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$G(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$G(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _extends$8() {
    _extends$8 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$8.apply(this, arguments);
}
/**
 * The underlying structure of each index.
 */ class IndexStruct {
    toJson() {
        return {
            indexId: this.indexId,
            summary: this.summary
        };
    }
    getSummary() {
        if (this.summary === undefined) {
            throw new Error("summary field of the index dict is not set");
        }
        return this.summary;
    }
    constructor(indexId = node_crypto.randomUUID(), summary = undefined){
        this.indexId = indexId;
        this.summary = summary;
    }
}
exports.IndexStructType = void 0;
(function(IndexStructType) {
    IndexStructType["SIMPLE_DICT"] = "simple_dict";
    IndexStructType["LIST"] = "list";
    IndexStructType["KEYWORD_TABLE"] = "keyword_table";
})(exports.IndexStructType || (exports.IndexStructType = {}));
class IndexDict extends IndexStruct {
    getSummary() {
        if (this.summary === undefined) {
            throw new Error("summary field of the index dict is not set");
        }
        return this.summary;
    }
    addNode(node, textId) {
        const vectorId = textId != null ? textId : node.id_;
        this.nodesDict[vectorId] = node;
    }
    toJson() {
        return _extends$8({}, super.toJson(), {
            nodesDict: this.nodesDict,
            type: this.type
        });
    }
    delete(nodeId) {
        delete this.nodesDict[nodeId];
    }
    constructor(...args){
        super(...args);
        this.nodesDict = {};
        this.type = "simple_dict";
    }
}
function jsonToIndexStruct(json) {
    if (json.type === "list") {
        const indexList = new IndexList(json.indexId, json.summary);
        indexList.nodes = json.nodes;
        return indexList;
    } else if (json.type === "simple_dict") {
        const indexDict = new IndexDict(json.indexId, json.summary);
        indexDict.nodesDict = Object.entries(json.nodesDict).reduce((acc, [key, value])=>{
            acc[key] = jsonToNode(value);
            return acc;
        }, {});
        return indexDict;
    } else {
        throw new Error(`Unknown index struct type: ${json.type}`);
    }
}
class IndexList extends IndexStruct {
    addNode(node) {
        this.nodes.push(node.id_);
    }
    toJson() {
        return _extends$8({}, super.toJson(), {
            nodes: this.nodes,
            type: this.type
        });
    }
    constructor(...args){
        super(...args);
        this.nodes = [];
        this.type = "list";
    }
}
// A table of keywords mapping keywords to text chunks.
class KeywordTable extends IndexStruct {
    addNode(keywords, nodeId) {
        keywords.forEach((keyword)=>{
            if (!this.table.has(keyword)) {
                this.table.set(keyword, new Set());
            }
            this.table.get(keyword).add(nodeId);
        });
    }
    deleteNode(keywords, nodeId) {
        keywords.forEach((keyword)=>{
            if (this.table.has(keyword)) {
                this.table.get(keyword).delete(nodeId);
            }
        });
    }
    toJson() {
        return _extends$8({}, super.toJson(), {
            table: this.table,
            type: this.type
        });
    }
    constructor(...args){
        super(...args);
        this.table = new Map();
        this.type = "keyword_table";
    }
}
/**
 * Indexes are the data structure that we store our nodes and embeddings in so
 * they can be retrieved for our queries.
 */ class BaseIndex {
    /**
   * Insert a document into the index.
   * @param document
   */ insert(document) {
        var _this = this;
        return _async_to_generator$G(function*() {
            const nodes = _this.serviceContext.nodeParser.getNodesFromDocuments([
                document
            ]);
            yield _this.insertNodes(nodes);
            _this.docStore.setDocumentHash(document.id_, document.hash);
        })();
    }
    constructor(init){
        this.serviceContext = init.serviceContext;
        this.storageContext = init.storageContext;
        this.docStore = init.docStore;
        this.vectorStore = init.vectorStore;
        this.indexStore = init.indexStore;
        this.indexStruct = init.indexStruct;
    }
}

function asyncGeneratorStep$F(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$F(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$F(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$F(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const defaultPersistPath = `${DEFAULT_PERSIST_DIR}/${DEFAULT_INDEX_STORE_PERSIST_FILENAME}`;
class BaseIndexStore {
    persist(persistPath = defaultPersistPath, fs) {
        return _async_to_generator$F(function*() {
        // Persist the index store to disk.
        })();
    }
}

function asyncGeneratorStep$E(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$E(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$E(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$E(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class KVIndexStore extends BaseIndexStore {
    addIndexStruct(indexStruct) {
        var _this = this;
        return _async_to_generator$E(function*() {
            let key = indexStruct.indexId;
            let data = indexStruct.toJson();
            yield _this._kvStore.put(key, data, _this._collection);
        })();
    }
    deleteIndexStruct(key) {
        var _this = this;
        return _async_to_generator$E(function*() {
            yield _this._kvStore.delete(key, _this._collection);
        })();
    }
    getIndexStruct(structId) {
        var _this = this;
        return _async_to_generator$E(function*() {
            if (___namespace.default.isNil(structId)) {
                let structs = yield _this.getIndexStructs();
                if (structs.length !== 1) {
                    throw new Error("More than one index struct found");
                }
                return structs[0];
            } else {
                let json = yield _this._kvStore.get(structId, _this._collection);
                if (___namespace.default.isNil(json)) {
                    return;
                }
                return jsonToIndexStruct(json);
            }
        })();
    }
    getIndexStructs() {
        var _this = this;
        return _async_to_generator$E(function*() {
            let jsons = yield _this._kvStore.getAll(_this._collection);
            return ___namespace.default.values(jsons).map((json)=>jsonToIndexStruct(json));
        })();
    }
    constructor(kvStore, namespace = DEFAULT_NAMESPACE){
        super();
        this._kvStore = kvStore;
        this._collection = `${namespace}/data`;
    }
}

function asyncGeneratorStep$D(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$D(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$D(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$D(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class SimpleIndexStore extends KVIndexStore {
    static fromPersistDir(persistDir = DEFAULT_PERSIST_DIR, fs = DEFAULT_FS) {
        var _this = this;
        return _async_to_generator$D(function*() {
            const persistPath = path__default$1.default.join(persistDir, DEFAULT_INDEX_STORE_PERSIST_FILENAME);
            return _this.fromPersistPath(persistPath, fs);
        })();
    }
    static fromPersistPath(persistPath, fs = DEFAULT_FS) {
        return _async_to_generator$D(function*() {
            let simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs);
            return new SimpleIndexStore(simpleKVStore);
        })();
    }
    persist(persistPath = DEFAULT_PERSIST_DIR, fs = DEFAULT_FS) {
        var _this = this;
        return _async_to_generator$D(function*() {
            yield _this.kvStore.persist(persistPath, fs);
        })();
    }
    static fromDict(saveDict) {
        let simpleKVStore = SimpleKVStore.fromDict(saveDict);
        return new SimpleIndexStore(simpleKVStore);
    }
    toDict() {
        if (!(this.kvStore instanceof SimpleKVStore)) {
            throw new Error("KVStore is not a SimpleKVStore");
        }
        return this.kvStore.toDict();
    }
    constructor(kvStore){
        kvStore = kvStore || new SimpleKVStore();
        super(kvStore);
        this.kvStore = kvStore;
    }
}

exports.VectorStoreQueryMode = void 0;
(function(VectorStoreQueryMode) {
    VectorStoreQueryMode["DEFAULT"] = "default";
    VectorStoreQueryMode["SPARSE"] = "sparse";
    VectorStoreQueryMode["HYBRID"] = "hybrid";
    // fit learners
    VectorStoreQueryMode["SVM"] = "svm";
    VectorStoreQueryMode["LOGISTIC_REGRESSION"] = "logistic_regression";
    VectorStoreQueryMode["LINEAR_REGRESSION"] = "linear_regression";
    // maximum marginal relevance
    VectorStoreQueryMode["MMR"] = "mmr";
})(exports.VectorStoreQueryMode || (exports.VectorStoreQueryMode = {}));

function asyncGeneratorStep$C(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$C(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$C(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$C(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const LEARNER_MODES = new Set([
    exports.VectorStoreQueryMode.SVM,
    exports.VectorStoreQueryMode.LINEAR_REGRESSION,
    exports.VectorStoreQueryMode.LOGISTIC_REGRESSION
]);
const MMR_MODE = exports.VectorStoreQueryMode.MMR;
class SimpleVectorStoreData {
    constructor(){
        this.embeddingDict = {};
        this.textIdToRefDocId = {};
    }
}
class SimpleVectorStore {
    static fromPersistDir(persistDir = DEFAULT_PERSIST_DIR, fs = DEFAULT_FS) {
        return _async_to_generator$C(function*() {
            let persistPath = `${persistDir}/vector_store.json`;
            return yield SimpleVectorStore.fromPersistPath(persistPath, fs);
        })();
    }
    get client() {
        return null;
    }
    get(textId) {
        var _this = this;
        return _async_to_generator$C(function*() {
            return _this.data.embeddingDict[textId];
        })();
    }
    add(embeddingResults) {
        var _this = this;
        return _async_to_generator$C(function*() {
            for (let node of embeddingResults){
                var _node_sourceNode;
                _this.data.embeddingDict[node.id_] = node.getEmbedding();
                if (!node.sourceNode) {
                    console.error("Missing source node from TextNode.");
                    continue;
                }
                _this.data.textIdToRefDocId[node.id_] = (_node_sourceNode = node.sourceNode) == null ? void 0 : _node_sourceNode.nodeId;
            }
            if (_this.persistPath) {
                yield _this.persist(_this.persistPath, _this.fs);
            }
            return embeddingResults.map((result)=>result.id_);
        })();
    }
    delete(refDocId) {
        var _this = this;
        return _async_to_generator$C(function*() {
            let textIdsToDelete = Object.keys(_this.data.textIdToRefDocId).filter((textId)=>_this.data.textIdToRefDocId[textId] === refDocId);
            for (let textId of textIdsToDelete){
                delete _this.data.embeddingDict[textId];
                delete _this.data.textIdToRefDocId[textId];
            }
            return Promise.resolve();
        })();
    }
    query(query) {
        var _this = this;
        return _async_to_generator$C(function*() {
            if (!___namespace.default.isNil(query.filters)) {
                throw new Error("Metadata filters not implemented for SimpleVectorStore yet.");
            }
            let items = Object.entries(_this.data.embeddingDict);
            let nodeIds, embeddings;
            if (query.docIds) {
                let availableIds = new Set(query.docIds);
                const queriedItems = items.filter((item)=>availableIds.has(item[0]));
                nodeIds = queriedItems.map((item)=>item[0]);
                embeddings = queriedItems.map((item)=>item[1]);
            } else {
                // No docIds specified, so use all available items
                nodeIds = items.map((item)=>item[0]);
                embeddings = items.map((item)=>item[1]);
            }
            let queryEmbedding = query.queryEmbedding;
            let topSimilarities, topIds;
            if (LEARNER_MODES.has(query.mode)) {
                [topSimilarities, topIds] = getTopKEmbeddingsLearner();
            } else if (query.mode === MMR_MODE) {
                let mmrThreshold = query.mmrThreshold;
                [topSimilarities, topIds] = getTopKMMREmbeddings(queryEmbedding, embeddings, null, query.similarityTopK, nodeIds, mmrThreshold);
            } else if (query.mode === exports.VectorStoreQueryMode.DEFAULT) {
                [topSimilarities, topIds] = getTopKEmbeddings(queryEmbedding, embeddings, query.similarityTopK, nodeIds);
            } else {
                throw new Error(`Invalid query mode: ${query.mode}`);
            }
            return Promise.resolve({
                similarities: topSimilarities,
                ids: topIds
            });
        })();
    }
    persist(persistPath = `${DEFAULT_PERSIST_DIR}/vector_store.json`, fs) {
        var _this = this;
        return _async_to_generator$C(function*() {
            fs = fs || _this.fs;
            let dirPath = path__default$1.default.dirname(persistPath);
            if (!(yield exists(fs, dirPath))) {
                yield fs.mkdir(dirPath);
            }
            yield fs.writeFile(persistPath, JSON.stringify(_this.data));
        })();
    }
    static fromPersistPath(persistPath, fs) {
        return _async_to_generator$C(function*() {
            fs = fs || DEFAULT_FS;
            let dirPath = path__default$1.default.dirname(persistPath);
            if (!(yield exists(fs, dirPath))) {
                yield fs.mkdir(dirPath, {
                    recursive: true
                });
            }
            let dataDict = {};
            try {
                let fileData = yield fs.readFile(persistPath);
                dataDict = JSON.parse(fileData.toString());
            } catch (e) {
                console.error(`No valid data found at path: ${persistPath} starting new store.`);
            }
            let data = new SimpleVectorStoreData();
            var _dataDict_embeddingDict;
            data.embeddingDict = (_dataDict_embeddingDict = dataDict.embeddingDict) != null ? _dataDict_embeddingDict : {};
            var _dataDict_textIdToRefDocId;
            data.textIdToRefDocId = (_dataDict_textIdToRefDocId = dataDict.textIdToRefDocId) != null ? _dataDict_textIdToRefDocId : {};
            const store = new SimpleVectorStore(data);
            store.persistPath = persistPath;
            store.fs = fs;
            return store;
        })();
    }
    static fromDict(saveDict) {
        let data = new SimpleVectorStoreData();
        data.embeddingDict = saveDict.embeddingDict;
        data.textIdToRefDocId = saveDict.textIdToRefDocId;
        return new SimpleVectorStore(data);
    }
    toDict() {
        return {
            embeddingDict: this.data.embeddingDict,
            textIdToRefDocId: this.data.textIdToRefDocId
        };
    }
    constructor(data, fs){
        this.storesText = false;
        this.data = new SimpleVectorStoreData();
        this.fs = DEFAULT_FS;
        this.data = data || new SimpleVectorStoreData();
        this.fs = fs || DEFAULT_FS;
    }
}

function asyncGeneratorStep$B(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$B(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$B(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$B(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function storageContextFromDefaults(_) {
    return _storageContextFromDefaults.apply(this, arguments);
}
function _storageContextFromDefaults() {
    _storageContextFromDefaults = _async_to_generator$B(function*({ docStore, indexStore, vectorStore, imageVectorStore, storeImages, persistDir, fs }) {
        if (!persistDir) {
            docStore = docStore || new SimpleDocumentStore();
            indexStore = indexStore || new SimpleIndexStore();
            vectorStore = vectorStore || new SimpleVectorStore();
            imageVectorStore = storeImages ? new SimpleVectorStore() : imageVectorStore;
        } else {
            fs = fs || DEFAULT_FS;
            docStore = docStore || (yield SimpleDocumentStore.fromPersistDir(persistDir, DEFAULT_NAMESPACE, fs));
            indexStore = indexStore || (yield SimpleIndexStore.fromPersistDir(persistDir, fs));
            vectorStore = vectorStore || (yield SimpleVectorStore.fromPersistDir(persistDir, fs));
            imageVectorStore = storeImages ? yield SimpleVectorStore.fromPersistDir(path__default$1.default.join(persistDir, DEFAULT_IMAGE_VECTOR_NAMESPACE), fs) : imageVectorStore;
        }
        return {
            docStore,
            indexStore,
            vectorStore,
            imageVectorStore
        };
    });
    return _storageContextFromDefaults.apply(this, arguments);
}

function asyncGeneratorStep$A(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$A(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$A(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$A(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const MAX_INSERT_BATCH_SIZE = 20;
class AstraDBVectorStore {
    /**
   * Create a new collection in your Astra DB vector database.
   * You must still use connect() to connect to the collection.
   *
   * @param collection your new colletion's name
   * @param options: CreateCollectionOptions used to set the number of vector dimensions and similarity metric
   * @returns Promise that resolves if the creation did not throw an error.
   */ create(collection, options) {
        var _this = this;
        return _async_to_generator$A(function*() {
            yield _this.astraDBClient.createCollection(collection, options);
            console.debug("Created Astra DB collection");
            return;
        })();
    }
    /**
   * Connect to an existing collection in your Astra DB vector database.
   * You must call this before adding, deleting, or querying.
   *
   * @param collection your existing colletion's name
   * @returns Promise that resolves if the connection did not throw an error.
   */ connect(collection) {
        var _this = this;
        return _async_to_generator$A(function*() {
            _this.collection = yield _this.astraDBClient.collection(collection);
            console.debug("Connected to Astra DB collection");
            return;
        })();
    }
    /**
   * Get an instance of your Astra DB client.
   * @returns the AstraDB client
   */ client() {
        return this.astraDBClient;
    }
    /**
   * Add your document(s) to your Astra DB collection.
   *
   * @returns and array of node ids which were added
   */ add(nodes) {
        var _this = this;
        return _async_to_generator$A(function*() {
            if (!_this.collection) {
                throw new Error("Must connect to collection before adding.");
            }
            const collection = _this.collection;
            if (!nodes || nodes.length === 0) {
                return [];
            }
            const dataToInsert = nodes.map((node)=>{
                return {
                    _id: node.id_,
                    $vector: node.getEmbedding(),
                    content: node.getContent(exports.MetadataMode.ALL),
                    metadata: node.metadata
                };
            });
            console.debug(`Adding ${dataToInsert.length} rows to table`);
            // Perform inserts in steps of MAX_INSERT_BATCH_SIZE
            let batchData = [];
            for(let i = 0; i < dataToInsert.length; i += MAX_INSERT_BATCH_SIZE){
                batchData.push(dataToInsert.slice(i, i + MAX_INSERT_BATCH_SIZE));
            }
            for (const batch of batchData){
                console.debug(`Inserting batch of size ${batch.length}`);
                yield collection.insertMany(batch);
            }
            return dataToInsert.map((node)=>node._id);
        })();
    }
    /**
   * Delete a document from your Astra DB collection.
   *
   * @param refDocId the id of the document to delete
   * @param deleteOptions: any DeleteOneOptions to pass to the delete query
   * @returns Promise that resolves if the delete query did not throw an error.
   */ delete(refDocId, deleteOptions) {
        var _this = this;
        return _async_to_generator$A(function*() {
            if (!_this.collection) {
                throw new Error("Must connect to collection before deleting.");
            }
            const collection = _this.collection;
            console.debug(`Deleting row with id ${refDocId}`);
            yield collection.deleteOne({
                _id: refDocId
            }, deleteOptions);
        })();
    }
    /**
   * Query documents from your Astra DB collection to get the closest match to your embedding.
   *
   * @param query: VectorStoreQuery
   * @param options: Not used
   */ query(query, options) {
        var _this = this;
        return _async_to_generator$A(function*() {
            var _query_filters_filters, _query_filters;
            if (!_this.collection) {
                throw new Error("Must connect to collection before querying.");
            }
            const collection = _this.collection;
            const filters = {};
            (_query_filters = query.filters) == null ? void 0 : (_query_filters_filters = _query_filters.filters) == null ? void 0 : _query_filters_filters.forEach((f)=>{
                filters[f.key] = f.value;
            });
            const cursor = yield collection.find(filters, {
                sort: query.queryEmbedding ? {
                    $vector: query.queryEmbedding
                } : undefined,
                limit: query.similarityTopK,
                includeSimilarity: true
            });
            const nodes = [];
            const ids = [];
            const similarities = [];
            yield cursor.forEach(/*#__PURE__*/ _async_to_generator$A(function*(row) {
                const id = row[_this.idKey];
                const embedding = row.$vector;
                const similarity = row.$similarity;
                const metadata = row[_this.metadataKey];
                // Remove fields from content
                delete row[_this.idKey];
                delete row.$similarity;
                delete row.$vector;
                delete row[_this.metadataKey];
                const content = _this.contentKey ? row[_this.contentKey] : JSON.stringify(row);
                const node = new Document({
                    id_: id,
                    text: content,
                    metadata: metadata != null ? metadata : {},
                    embedding: embedding
                });
                ids.push(id);
                similarities.push(similarity);
                nodes.push(node);
            }));
            return {
                similarities,
                ids,
                nodes
            };
        })();
    }
    constructor(init){
        this.storesText = true;
        this.flatMetadata = true;
        if (init == null ? void 0 : init.astraDBClient) {
            this.astraDBClient = init.astraDBClient;
        } else {
            var _init_params, _init_params1;
            var _init_params_token;
            const token = (_init_params_token = init == null ? void 0 : (_init_params = init.params) == null ? void 0 : _init_params.token) != null ? _init_params_token : process.env.ASTRA_DB_APPLICATION_TOKEN;
            var _init_params_endpoint;
            const endpoint = (_init_params_endpoint = init == null ? void 0 : (_init_params1 = init.params) == null ? void 0 : _init_params1.endpoint) != null ? _init_params_endpoint : process.env.ASTRA_DB_ENDPOINT;
            if (!token) {
                throw new Error("Must specify ASTRA_DB_APPLICATION_TOKEN via env variable.");
            }
            if (!endpoint) {
                throw new Error("Must specify ASTRA_DB_ENDPOINT via env variable.");
            }
            this.astraDBClient = new astraDbTs.AstraDB(token, endpoint);
        }
        var _init_idKey;
        this.idKey = (_init_idKey = init == null ? void 0 : init.idKey) != null ? _init_idKey : "_id";
        this.contentKey = init == null ? void 0 : init.contentKey;
        var _init_metadataKey;
        this.metadataKey = (_init_metadataKey = init == null ? void 0 : init.metadataKey) != null ? _init_metadataKey : "metadata";
    }
}

function _object_without_properties_loose$1(source, excluded) {
    if (source == null) return {};
    var target = {};
    var sourceKeys = Object.keys(source);
    var key, i;
    for(i = 0; i < sourceKeys.length; i++){
        key = sourceKeys[i];
        if (excluded.indexOf(key) >= 0) continue;
        target[key] = source[key];
    }
    return target;
}
const DEFAULT_TEXT_KEY$1 = "text";
function validateIsFlat(obj) {
    for(let key in obj){
        if (typeof obj[key] === "object" && obj[key] !== null) {
            throw new Error(`Value for metadata ${key} must not be another object`);
        }
    }
}
function nodeToMetadata(node, removeText = false, textField = DEFAULT_TEXT_KEY$1, flatMetadata = false) {
    var _node_sourceNode, _node_sourceNode1, _node_sourceNode2;
    const _node_toMutableJSON = node.toMutableJSON(), { metadata, embedding } = _node_toMutableJSON, rest = _object_without_properties_loose$1(_node_toMutableJSON, [
        "metadata",
        "embedding"
    ]);
    if (flatMetadata) {
        validateIsFlat(metadata);
    }
    if (removeText) {
        rest[textField] = "";
    }
    metadata["_node_content"] = JSON.stringify(rest);
    metadata["_node_type"] = node.constructor.name.replace("_", ""); // remove leading underscore to be compatible with Python
    metadata["document_id"] = ((_node_sourceNode = node.sourceNode) == null ? void 0 : _node_sourceNode.nodeId) || "None";
    metadata["doc_id"] = ((_node_sourceNode1 = node.sourceNode) == null ? void 0 : _node_sourceNode1.nodeId) || "None";
    metadata["ref_doc_id"] = ((_node_sourceNode2 = node.sourceNode) == null ? void 0 : _node_sourceNode2.nodeId) || "None";
    return metadata;
}
function metadataDictToNode(metadata) {
    const { _node_content: nodeContent, _node_type: nodeType, document_id, doc_id, ref_doc_id } = metadata, rest = _object_without_properties_loose$1(metadata, [
        "_node_content",
        "_node_type",
        "document_id",
        "doc_id",
        "ref_doc_id"
    ]);
    if (!nodeContent) {
        throw new Error("Node content not found in metadata.");
    }
    const nodeObj = JSON.parse(nodeContent);
    nodeObj.metadata = rest;
    // Note: we're using the name of the class stored in `_node_type`
    // and not the type attribute to reconstruct
    // the node. This way we're compatible with LlamaIndex Python
    switch(nodeType){
        case "IndexNode":
            return jsonToNode(nodeObj, exports.ObjectType.INDEX);
        default:
            return jsonToNode(nodeObj, exports.ObjectType.TEXT);
    }
}

function asyncGeneratorStep$z(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$z(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$z(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$z(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const DEFAULT_TEXT_KEY = "text";
class ChromaVectorStore {
    client() {
        return this.chromaClient;
    }
    getCollection() {
        var _this = this;
        return _async_to_generator$z(function*() {
            if (!_this.collection) {
                const coll = yield _this.chromaClient.createCollection({
                    name: _this.collectionName
                });
                _this.collection = coll;
            }
            return _this.collection;
        })();
    }
    getDataToInsert(nodes) {
        const metadatas = nodes.map((node)=>nodeToMetadata(node, true, this.textKey, this.flatMetadata));
        return {
            embeddings: nodes.map((node)=>node.getEmbedding()),
            ids: nodes.map((node)=>node.id_),
            metadatas,
            documents: nodes.map((node)=>node.getContent(exports.MetadataMode.NONE))
        };
    }
    add(nodes) {
        var _this = this;
        return _async_to_generator$z(function*() {
            if (!nodes || nodes.length === 0) {
                return [];
            }
            const dataToInsert = _this.getDataToInsert(nodes);
            const collection = yield _this.getCollection();
            yield collection.add(dataToInsert);
            return nodes.map((node)=>node.id_);
        })();
    }
    delete(refDocId, deleteOptions) {
        var _this = this;
        return _async_to_generator$z(function*() {
            const collection = yield _this.getCollection();
            yield collection.delete({
                ids: [
                    refDocId
                ],
                where: deleteOptions == null ? void 0 : deleteOptions.where,
                whereDocument: deleteOptions == null ? void 0 : deleteOptions.whereDocument
            });
        })();
    }
    query(query, options) {
        var _this = this;
        return _async_to_generator$z(function*() {
            if (query.docIds) {
                throw new Error("ChromaDB does not support querying by docIDs");
            }
            if (query.mode != exports.VectorStoreQueryMode.DEFAULT) {
                throw new Error("ChromaDB does not support querying by mode");
            }
            const chromaWhere = {};
            if (query.filters) {
                query.filters.filters.map((filter)=>{
                    const filterKey = filter.key;
                    const filterValue = filter.value;
                    chromaWhere[filterKey] = filterValue;
                });
            }
            const collection = yield _this.getCollection();
            var _query_queryEmbedding, _query_queryStr;
            const queryResponse = yield collection.query({
                queryEmbeddings: (_query_queryEmbedding = query.queryEmbedding) != null ? _query_queryEmbedding : undefined,
                queryTexts: (_query_queryStr = query.queryStr) != null ? _query_queryStr : undefined,
                nResults: query.similarityTopK,
                where: Object.keys(chromaWhere).length ? chromaWhere : undefined,
                whereDocument: options == null ? void 0 : options.whereDocument,
                //ChromaDB doesn't return the result embeddings by default so we need to include them
                include: [
                    chromadb.IncludeEnum.Distances,
                    chromadb.IncludeEnum.Metadatas,
                    chromadb.IncludeEnum.Documents,
                    chromadb.IncludeEnum.Embeddings
                ]
            });
            const vectorStoreQueryResult = {
                nodes: queryResponse.ids[0].map((id, index)=>{
                    const text = queryResponse.documents[0][index];
                    var _queryResponse_metadatas__index;
                    const metaData = (_queryResponse_metadatas__index = queryResponse.metadatas[0][index]) != null ? _queryResponse_metadatas__index : {};
                    const node = metadataDictToNode(metaData);
                    node.setContent(text);
                    return node;
                }),
                similarities: queryResponse.distances[0].map((distance)=>1 - distance),
                ids: queryResponse.ids[0]
            };
            return vectorStoreQueryResult;
        })();
    }
    constructor(init){
        this.storesText = true;
        this.flatMetadata = true;
        this.collection = null;
        this.collectionName = init.collectionName;
        this.chromaClient = new chromadb.ChromaClient(init.chromaClientParams);
        var _init_textKey;
        this.textKey = (_init_textKey = init.textKey) != null ? _init_textKey : DEFAULT_TEXT_KEY;
    }
}

function _async_iterator$3(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$3(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$3(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$3 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$3.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$3(s);
}
function asyncGeneratorStep$y(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$y(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$y(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$y(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
// Utility function to convert metadata filters to MongoDB filter
function toMongoDBFilter(standardFilters) {
    const filters = {};
    for (const filter of standardFilters.filters){
        filters[filter.key] = filter.value;
    }
    return filters;
}
// MongoDB Atlas Vector Store class implementing VectorStore
class MongoDBAtlasVectorSearch {
    add(nodes) {
        var _this = this;
        return _async_to_generator$y(function*() {
            if (!nodes || nodes.length === 0) {
                return [];
            }
            const dataToInsert = nodes.map((node)=>{
                const metadata = nodeToMetadata(node, true, _this.textKey, _this.flatMetadata);
                return {
                    [_this.idKey]: node.id_,
                    [_this.embeddingKey]: node.getEmbedding(),
                    [_this.textKey]: node.getContent(exports.MetadataMode.NONE) || "",
                    [_this.metadataKey]: metadata
                };
            });
            console.debug("Inserting data into MongoDB: ", dataToInsert);
            const insertResult = yield _this.collection.insertMany(dataToInsert, _this.insertOptions);
            console.debug("Result of insert: ", insertResult);
            return nodes.map((node)=>node.id_);
        })();
    }
    delete(refDocId, deleteOptions) {
        var _this = this;
        return _async_to_generator$y(function*() {
            yield _this.collection.deleteOne({
                [`${_this.metadataKey}.ref_doc_id`]: refDocId
            }, deleteOptions);
        })();
    }
    get client() {
        return this.mongodbClient;
    }
    query(query, options) {
        var _this = this;
        return _async_to_generator$y(function*() {
            const params = {
                queryVector: query.queryEmbedding,
                path: _this.embeddingKey,
                numCandidates: query.similarityTopK * 10,
                limit: query.similarityTopK,
                index: _this.indexName
            };
            if (query.filters) {
                params.filter = toMongoDBFilter(query.filters);
            }
            const queryField = {
                $vectorSearch: params
            };
            const pipeline = [
                queryField,
                {
                    $project: {
                        score: {
                            $meta: "vectorSearchScore"
                        },
                        [_this.embeddingKey]: 0
                    }
                }
            ];
            console.debug("Running query pipeline: ", pipeline);
            const cursor = yield _this.collection.aggregate(pipeline);
            const nodes = [];
            const ids = [];
            const similarities = [];
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$3((yield cursor)), _step; _iteratorAbruptCompletion = !(_step = yield _iterator.next()).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const res = _value;
                        const text = res[_this.textKey];
                        const score = res.score;
                        const id = res[_this.idKey];
                        const metadata = res[_this.metadataKey];
                        const node = metadataDictToNode(metadata);
                        node.setContent(text);
                        ids.push(id);
                        nodes.push(node);
                        similarities.push(score);
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            const result = {
                nodes,
                similarities,
                ids
            };
            console.debug("Result of query (ids):", ids);
            return result;
        })();
    }
    constructor(init){
        this.storesText = true;
        this.flatMetadata = true;
        if (init.mongodbClient) {
            this.mongodbClient = init.mongodbClient;
        } else {
            const mongoUri = process.env.MONGODB_URI;
            if (!mongoUri) {
                throw new Error("Must specify MONGODB_URI via env variable if not directly passing in client.");
            }
            this.mongodbClient = new mongodb.MongoClient(mongoUri);
        }
        var _init_dbName, _init_collectionName;
        this.collection = this.mongodbClient.db((_init_dbName = init.dbName) != null ? _init_dbName : "default_db").collection((_init_collectionName = init.collectionName) != null ? _init_collectionName : "default_collection");
        var _init_indexName;
        this.indexName = (_init_indexName = init.indexName) != null ? _init_indexName : "default";
        var _init_embeddingKey;
        this.embeddingKey = (_init_embeddingKey = init.embeddingKey) != null ? _init_embeddingKey : "embedding";
        var _init_idKey;
        this.idKey = (_init_idKey = init.idKey) != null ? _init_idKey : "id";
        var _init_textKey;
        this.textKey = (_init_textKey = init.textKey) != null ? _init_textKey : "text";
        var _init_metadataKey;
        this.metadataKey = (_init_metadataKey = init.metadataKey) != null ? _init_metadataKey : "metadata";
        this.insertOptions = init.insertOptions;
    }
}

function asyncGeneratorStep$x(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$x(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$x(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$x(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
const PGVECTOR_SCHEMA = "public";
const PGVECTOR_TABLE = "llamaindex_embedding";
/**
 * Provides support for writing and querying vector data in Postgres.
 * Note: Can't be used with data created using the Python version of the vector store (https://docs.llamaindex.ai/en/stable/examples/vector_stores/postgres.html)
 */ class PGVectorStore {
    /**
   * Setter for the collection property.
   * Using a collection allows for simple segregation of vector data,
   * e.g. by user, source, or access-level.
   * Leave/set blank to ignore the collection value when querying.
   * @param coll Name for the collection.
   */ setCollection(coll) {
        this.collection = coll;
    }
    /**
   * Getter for the collection property.
   * Using a collection allows for simple segregation of vector data,
   * e.g. by user, source, or access-level.
   * Leave/set blank to ignore the collection value when querying.
   * @returns The currently-set collection value.  Default is empty string.
   */ getCollection() {
        return this.collection;
    }
    getDb() {
        var _this = this;
        return _async_to_generator$x(function*() {
            if (!_this.db) {
                try {
                    // Create DB connection
                    // Read connection params from env - see comment block above
                    const db = new pg__default.default.Client({
                        connectionString: _this.connectionString
                    });
                    yield db.connect();
                    // Check vector extension
                    db.query("CREATE EXTENSION IF NOT EXISTS vector");
                    yield pgvector__default.default.registerType(db);
                    // Check schema, table(s), index(es)
                    yield _this.checkSchema(db);
                    // All good?  Keep the connection reference
                    _this.db = db;
                } catch (err) {
                    console.error(err);
                    return Promise.reject(err);
                }
            }
            return Promise.resolve(_this.db);
        })();
    }
    checkSchema(db) {
        var _this = this;
        return _async_to_generator$x(function*() {
            yield db.query(`CREATE SCHEMA IF NOT EXISTS ${_this.schemaName}`);
            const tbl = `CREATE TABLE IF NOT EXISTS ${_this.schemaName}.${_this.tableName}(
      id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
      external_id VARCHAR,
      collection VARCHAR,
      document TEXT,
      metadata JSONB DEFAULT '{}',
      embeddings VECTOR(1536)
    )`;
            yield db.query(tbl);
            const idxs = `CREATE INDEX IF NOT EXISTS idx_${_this.tableName}_external_id ON ${_this.schemaName}.${_this.tableName} (external_id);
      CREATE INDEX IF NOT EXISTS idx_${_this.tableName}_collection ON ${_this.schemaName}.${_this.tableName} (collection);`;
            yield db.query(idxs);
            // TODO add IVFFlat or HNSW indexing?
            return db;
        })();
    }
    /**
   * Connects to the database specified in environment vars.
   * This method also checks and creates the vector extension,
   * the destination table and indexes if not found.
   * @returns A connection to the database, or the error encountered while connecting/setting up.
   */ client() {
        return this.getDb();
    }
    /**
   * Delete all vector records for the specified collection.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @returns The result of the delete query.
   */ clearCollection() {
        var _this = this;
        return _async_to_generator$x(function*() {
            const sql = `DELETE FROM ${_this.schemaName}.${_this.tableName} 
      WHERE collection = $1`;
            const db = yield _this.getDb();
            const ret = yield db.query(sql, [
                _this.collection
            ]);
            return ret;
        })();
    }
    getDataToInsert(embeddingResults) {
        const result = [];
        for(let index = 0; index < embeddingResults.length; index++){
            const row = embeddingResults[index];
            let id = row.id_.length ? row.id_ : null;
            let meta = row.metadata || {};
            meta.create_date = new Date();
            const params = [
                id,
                "",
                this.collection,
                row.getContent(exports.MetadataMode.EMBED),
                meta,
                "[" + row.getEmbedding().join(",") + "]"
            ];
            result.push(params);
        }
        return result;
    }
    /**
   * Adds vector record(s) to the table.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @param embeddingResults The Nodes to be inserted, optionally including metadata tuples.
   * @returns A list of zero or more id values for the created records.
   */ add(embeddingResults) {
        var _this = this;
        return _async_to_generator$x(function*() {
            if (embeddingResults.length == 0) {
                console.debug("Empty list sent to PGVectorStore::add");
                return Promise.resolve([]);
            }
            const sql = `INSERT INTO ${_this.schemaName}.${_this.tableName} 
      (id, external_id, collection, document, metadata, embeddings) 
      VALUES ($1, $2, $3, $4, $5, $6)`;
            const db = yield _this.getDb();
            const data = _this.getDataToInsert(embeddingResults);
            let ret = [];
            for(let index = 0; index < data.length; index++){
                const params = data[index];
                try {
                    const result = yield db.query(sql, params);
                    if (result.rows.length) {
                        const id = result.rows[0].id;
                        ret.push(id);
                    }
                } catch (err) {
                    const msg = `${err}`;
                    console.log(msg, err);
                }
            }
            return Promise.resolve(ret);
        })();
    }
    /**
   * Deletes a single record from the database by id.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @param refDocId Unique identifier for the record to delete.
   * @param deleteKwargs Required by VectorStore interface.  Currently ignored.
   * @returns Promise that resolves if the delete query did not throw an error.
   */ delete(refDocId, deleteKwargs) {
        var _this = this;
        return _async_to_generator$x(function*() {
            const collectionCriteria = _this.collection.length ? "AND collection = $2" : "";
            const sql = `DELETE FROM ${_this.schemaName}.${_this.tableName} 
      WHERE id = $1 ${collectionCriteria}`;
            const db = yield _this.getDb();
            const params = _this.collection.length ? [
                refDocId,
                _this.collection
            ] : [
                refDocId
            ];
            yield db.query(sql, params);
            return Promise.resolve();
        })();
    }
    /**
   * Query the vector store for the closest matching data to the query embeddings
   * @param query The VectorStoreQuery to be used
   * @param options Required by VectorStore interface.  Currently ignored.
   * @returns Zero or more Document instances with data from the vector store.
   */ query(query, options) {
        var _this = this;
        return _async_to_generator$x(function*() {
            var _query_queryEmbedding;
            // TODO QUERY TYPES:
            //    Distance:       SELECT embedding <-> $1 AS distance FROM items;
            //    Inner Product:  SELECT (embedding <#> $1) * -1 AS inner_product FROM items;
            //    Cosine Sim:     SELECT 1 - (embedding <=> $1) AS cosine_similarity FROM items;
            const embedding = "[" + ((_query_queryEmbedding = query.queryEmbedding) == null ? void 0 : _query_queryEmbedding.join(",")) + "]";
            var _query_similarityTopK;
            const max = (_query_similarityTopK = query.similarityTopK) != null ? _query_similarityTopK : 2;
            const where = _this.collection.length ? "WHERE collection = $2" : "";
            // TODO Add collection filter if set
            const sql = `SELECT 
        v.*, 
        embeddings <-> $1 s 
      FROM ${_this.schemaName}.${_this.tableName} v
      ${where}
      ORDER BY s 
      LIMIT ${max}
    `;
            const db = yield _this.getDb();
            const params = _this.collection.length ? [
                embedding,
                _this.collection
            ] : [
                embedding
            ];
            const results = yield db.query(sql, params);
            const nodes = results.rows.map((row)=>{
                return new Document({
                    id_: row.id,
                    text: row.document,
                    metadata: row.metadata,
                    embedding: row.embeddings
                });
            });
            const ret = {
                nodes: nodes,
                similarities: results.rows.map((row)=>row.s),
                ids: results.rows.map((row)=>row.id)
            };
            return Promise.resolve(ret);
        })();
    }
    /**
   * Required by VectorStore interface.  Currently ignored.
   * @param persistPath
   * @param fs
   * @returns Resolved Promise.
   */ persist(persistPath, fs) {
        return Promise.resolve();
    }
    /**
   * Constructs a new instance of the PGVectorStore
   *
   * If the `connectionString` is not provided the following env variables are
   * used to connect to the DB:
   * PGHOST=your database host
   * PGUSER=your database user
   * PGPASSWORD=your database password
   * PGDATABASE=your database name
   * PGPORT=your database port
   *
   * @param {object} config - The configuration settings for the instance.
   * @param {string} config.schemaName - The name of the schema (optional). Defaults to PGVECTOR_SCHEMA.
   * @param {string} config.tableName - The name of the table (optional). Defaults to PGVECTOR_TABLE.
   * @param {string} config.connectionString - The connection string (optional).
   */ constructor(config){
        this.storesText = true;
        this.collection = "";
        this.schemaName = PGVECTOR_SCHEMA;
        this.tableName = PGVECTOR_TABLE;
        this.connectionString = undefined;
        var _config_schemaName;
        this.schemaName = (_config_schemaName = config == null ? void 0 : config.schemaName) != null ? _config_schemaName : PGVECTOR_SCHEMA;
        var _config_tableName;
        this.tableName = (_config_tableName = config == null ? void 0 : config.tableName) != null ? _config_tableName : PGVECTOR_TABLE;
        this.connectionString = config == null ? void 0 : config.connectionString;
    }
}

function asyncGeneratorStep$w(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$w(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$w(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$w(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Provides support for writing and querying vector data in Postgres.
 */ class PineconeVectorStore {
    getDb() {
        var _this = this;
        return _async_to_generator$w(function*() {
            if (!_this.db) {
                _this.db = yield new pinecone.Pinecone();
            }
            return Promise.resolve(_this.db);
        })();
    }
    /**
   * Connects to the Pinecone account specified in environment vars.
   * This method also checks and creates the named index if not found.
   * @returns Pinecone client, or the error encountered while connecting/setting up.
   */ client() {
        return this.getDb();
    }
    index() {
        var _this = this;
        return _async_to_generator$w(function*() {
            const db = yield _this.getDb();
            return yield db.index(_this.indexName);
        })();
    }
    /**
   * Delete all records for the current index.
   * NOTE: This operation is not supported by Pinecone for "Starter" (free) indexes.
   * @returns The result of the delete query.
   */ clearIndex() {
        var _this = this;
        return _async_to_generator$w(function*() {
            const db = yield _this.getDb();
            return yield db.index(_this.indexName).deleteAll();
        })();
    }
    /**
   * Adds vector record(s) to the table.
   * @TODO Does not create or insert sparse vectors.
   * @param embeddingResults The Nodes to be inserted, optionally including metadata tuples.
   * @returns Due to limitations in the Pinecone client, does not return the upserted ID list, only a Promise resolve/reject.
   */ add(embeddingResults) {
        var _this = this;
        return _async_to_generator$w(function*() {
            if (embeddingResults.length == 0) {
                return Promise.resolve([]);
            }
            const idx = yield _this.index();
            const nodes = embeddingResults.map(_this.nodeToRecord);
            for(let i = 0; i < nodes.length; i += _this.chunkSize){
                const chunk = nodes.slice(i, i + _this.chunkSize);
                const result = yield _this.saveChunk(idx, chunk);
                if (!result) {
                    return Promise.reject();
                }
            }
            return Promise.resolve([]);
        })();
    }
    saveChunk(idx, chunk) {
        return _async_to_generator$w(function*() {
            try {
                yield idx.upsert(chunk);
                return true;
            } catch (err) {
                const msg = `${err}`;
                console.log(msg, err);
                return false;
            }
        })();
    }
    /**
   * Deletes a single record from the database by id.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @param refDocId Unique identifier for the record to delete.
   * @param deleteKwargs Required by VectorStore interface.  Currently ignored.
   * @returns Promise that resolves if the delete query did not throw an error.
   */ delete(refDocId, deleteKwargs) {
        var _this = this;
        return _async_to_generator$w(function*() {
            const idx = yield _this.index();
            return idx.deleteOne(refDocId);
        })();
    }
    /**
   * Query the vector store for the closest matching data to the query embeddings
   * @TODO QUERY TYPES
   * @param query The VectorStoreQuery to be used
   * @param options Required by VectorStore interface.  Currently ignored.
   * @returns Zero or more Document instances with data from the vector store.
   */ query(query, options) {
        var _this = this;
        return _async_to_generator$w(function*() {
            const filter = _this.toPineconeFilter(query.filters);
            var options = {
                vector: query.queryEmbedding,
                topK: query.similarityTopK,
                include_values: true,
                include_metadara: true,
                filter: filter
            };
            const idx = yield _this.index();
            const results = yield idx.query(options);
            const idList = results.matches.map((row)=>row.id);
            const records = yield idx.fetch(idList);
            const rows = Object.values(records.records);
            const nodes = rows.map((row)=>{
                return new Document({
                    id_: row.id,
                    text: _this.textFromResultRow(row),
                    metadata: _this.metaWithoutText(row.metadata),
                    embedding: row.values
                });
            });
            const ret = {
                nodes: nodes,
                similarities: results.matches.map((row)=>row.score || 999),
                ids: results.matches.map((row)=>row.id)
            };
            return Promise.resolve(ret);
        })();
    }
    /**
   * Required by VectorStore interface.  Currently ignored.
   * @param persistPath
   * @param fs
   * @returns Resolved Promise.
   */ persist(persistPath, fs) {
        return Promise.resolve();
    }
    toPineconeFilter(stdFilters) {
        var _stdFilters_filters;
        return stdFilters == null ? void 0 : (_stdFilters_filters = stdFilters.filters) == null ? void 0 : _stdFilters_filters.reduce((carry, item)=>{
            carry[item.key] = item.value;
            return carry;
        }, {});
    }
    textFromResultRow(row) {
        var _row_metadata;
        var _row_metadata_text;
        return (_row_metadata_text = (_row_metadata = row.metadata) == null ? void 0 : _row_metadata.text) != null ? _row_metadata_text : "";
    }
    metaWithoutText(meta) {
        return Object.keys(meta).filter((key)=>key != "text").reduce((acc, key)=>{
            acc[key] = meta[key];
            return acc;
        }, {});
    }
    nodeToRecord(node) {
        let id = node.id_.length ? node.id_ : null;
        let meta = node.metadata || {};
        meta.create_date = new Date();
        meta.text = node.getContent(exports.MetadataMode.EMBED);
        return {
            id: id,
            values: node.getEmbedding(),
            metadata: meta
        };
    }
    constructor(params){
        this.storesText = true;
        var _params_indexName, _ref;
        this.indexName = (_ref = (_params_indexName = params == null ? void 0 : params.indexName) != null ? _params_indexName : process.env.PINECONE_INDEX_NAME) != null ? _ref : "llama";
        var _process_env_PINECONE_CHUNK_SIZE, _params_chunkSize;
        this.chunkSize = (_params_chunkSize = params == null ? void 0 : params.chunkSize) != null ? _params_chunkSize : Number.parseInt((_process_env_PINECONE_CHUNK_SIZE = process.env.PINECONE_CHUNK_SIZE) != null ? _process_env_PINECONE_CHUNK_SIZE : "100");
    }
}

function asyncGeneratorStep$v(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$v(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$v(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$v(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * The similarity between two embeddings.
 * @param embedding1
 * @param embedding2
 * @param mode
 * @returns similarity score with higher numbers meaning the two embeddings are more similar
 */ function similarity(embedding1, embedding2, mode = exports.SimilarityType.DEFAULT) {
    if (embedding1.length !== embedding2.length) {
        throw new Error("Embedding length mismatch");
    }
    // NOTE I've taken enough Kahan to know that we should probably leave the
    // numeric programming to numeric programmers. The naive approach here
    // will probably cause some avoidable loss of floating point precision
    // ml-distance is worth watching although they currently also use the naive
    // formulas
    function norm(x) {
        let result = 0;
        for(let i = 0; i < x.length; i++){
            result += x[i] * x[i];
        }
        return Math.sqrt(result);
    }
    switch(mode){
        case exports.SimilarityType.EUCLIDEAN:
            {
                let difference = embedding1.map((x, i)=>x - embedding2[i]);
                return -norm(difference);
            }
        case exports.SimilarityType.DOT_PRODUCT:
            {
                let result = 0;
                for(let i = 0; i < embedding1.length; i++){
                    result += embedding1[i] * embedding2[i];
                }
                return result;
            }
        case exports.SimilarityType.DEFAULT:
            {
                return similarity(embedding1, embedding2, exports.SimilarityType.DOT_PRODUCT) / (norm(embedding1) * norm(embedding2));
            }
        default:
            throw new Error("Not implemented yet");
    }
}
/**
 * Get the top K embeddings from a list of embeddings ordered by similarity to the query.
 * @param queryEmbedding
 * @param embeddings list of embeddings to consider
 * @param similarityTopK max number of embeddings to return, default 2
 * @param embeddingIds ids of embeddings in the embeddings list
 * @param similarityCutoff minimum similarity score
 * @returns
 */ // eslint-disable-next-line max-params
function getTopKEmbeddings(queryEmbedding, embeddings, similarityTopK = DEFAULT_SIMILARITY_TOP_K, embeddingIds = null, similarityCutoff = null) {
    if (embeddingIds == null) {
        embeddingIds = Array(embeddings.length).map((_, i)=>i);
    }
    if (embeddingIds.length !== embeddings.length) {
        throw new Error("getTopKEmbeddings: embeddings and embeddingIds length mismatch");
    }
    let similarities = [];
    for(let i = 0; i < embeddings.length; i++){
        const sim = similarity(queryEmbedding, embeddings[i]);
        if (similarityCutoff == null || sim > similarityCutoff) {
            similarities.push({
                similarity: sim,
                id: embeddingIds[i]
            });
        }
    }
    similarities.sort((a, b)=>b.similarity - a.similarity); // Reverse sort
    let resultSimilarities = [];
    let resultIds = [];
    for(let i = 0; i < similarityTopK; i++){
        if (i >= similarities.length) {
            break;
        }
        resultSimilarities.push(similarities[i].similarity);
        resultIds.push(similarities[i].id);
    }
    return [
        resultSimilarities,
        resultIds
    ];
}
// eslint-disable-next-line max-params
function getTopKEmbeddingsLearner(queryEmbedding, embeddings, similarityTopK, embeddingsIds, queryMode = exports.VectorStoreQueryMode.SVM) {
    throw new Error("Not implemented yet");
// To support SVM properly we're probably going to have to use something like
// https://github.com/mljs/libsvm which itself hasn't been updated in a while
}
// eslint-disable-next-line max-params
function getTopKMMREmbeddings(queryEmbedding, embeddings, similarityFn = null, similarityTopK = null, embeddingIds = null, _similarityCutoff = null, mmrThreshold = null) {
    let threshold = mmrThreshold || 0.5;
    similarityFn = similarityFn || similarity;
    if (embeddingIds === null || embeddingIds.length === 0) {
        embeddingIds = Array.from({
            length: embeddings.length
        }, (_, i)=>i);
    }
    let fullEmbedMap = new Map(embeddingIds.map((value, i)=>[
            value,
            i
        ]));
    let embedMap = new Map(fullEmbedMap);
    let embedSimilarity = new Map();
    let score = Number.NEGATIVE_INFINITY;
    let highScoreId = null;
    for(let i = 0; i < embeddings.length; i++){
        let emb = embeddings[i];
        let similarity = similarityFn(queryEmbedding, emb);
        embedSimilarity.set(embeddingIds[i], similarity);
        if (similarity * threshold > score) {
            highScoreId = embeddingIds[i];
            score = similarity * threshold;
        }
    }
    let results = [];
    let embeddingLength = embeddings.length;
    let similarityTopKCount = similarityTopK || embeddingLength;
    while(results.length < Math.min(similarityTopKCount, embeddingLength)){
        results.push([
            score,
            highScoreId
        ]);
        embedMap.delete(highScoreId);
        let recentEmbeddingId = highScoreId;
        score = Number.NEGATIVE_INFINITY;
        for (let embedId of Array.from(embedMap.keys())){
            let overlapWithRecent = similarityFn(embeddings[embedMap.get(embedId)], embeddings[fullEmbedMap.get(recentEmbeddingId)]);
            if (threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent > score) {
                score = threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent;
                highScoreId = embedId;
            }
        }
    }
    let resultSimilarities = results.map(([s, _])=>s);
    let resultIds = results.map(([_, n])=>n);
    return [
        resultSimilarities,
        resultIds
    ];
}
function blobToDataUrl(input) {
    return _blobToDataUrl.apply(this, arguments);
}
function _blobToDataUrl() {
    _blobToDataUrl = _async_to_generator$v(function*(input) {
        const { fileTypeFromBuffer } = yield import('file-type');
        const buffer = Buffer.from((yield input.arrayBuffer()));
        const type = yield fileTypeFromBuffer(buffer);
        if (!type) {
            throw new Error("Unsupported image type");
        }
        return "data:" + type.mime + ";base64," + buffer.toString("base64");
    });
    return _blobToDataUrl.apply(this, arguments);
}
function readImage(input) {
    return _readImage.apply(this, arguments);
}
function _readImage() {
    _readImage = _async_to_generator$v(function*(input) {
        const { RawImage } = yield import('@xenova/transformers');
        if (input instanceof Blob) {
            return yield RawImage.fromBlob(input);
        } else if (___namespace.default.isString(input) || input instanceof URL) {
            return yield RawImage.fromURL(input);
        } else {
            throw new Error(`Unsupported input type: ${typeof input}`);
        }
    });
    return _readImage.apply(this, arguments);
}
function imageToString(input) {
    return _imageToString.apply(this, arguments);
}
function _imageToString() {
    _imageToString = _async_to_generator$v(function*(input) {
        if (input instanceof Blob) {
            // if the image is a Blob, convert it to a base64 data URL
            return yield blobToDataUrl(input);
        } else if (___namespace.default.isString(input)) {
            return input;
        } else if (input instanceof URL) {
            return input.toString();
        } else {
            throw new Error(`Unsupported input type: ${typeof input}`);
        }
    });
    return _imageToString.apply(this, arguments);
}
function stringToImage(input) {
    if (input.startsWith("data:")) {
        // if the input is a base64 data URL, convert it back to a Blob
        const base64Data = input.split(",")[1];
        const byteArray = Buffer.from(base64Data, "base64");
        return new Blob([
            byteArray
        ]);
    } else if (input.startsWith("http://") || input.startsWith("https://")) {
        return new URL(input);
    } else if (___namespace.default.isString(input)) {
        return input;
    } else {
        throw new Error(`Unsupported input type: ${typeof input}`);
    }
}
function imageToDataUrl(input) {
    return _imageToDataUrl.apply(this, arguments);
}
function _imageToDataUrl() {
    _imageToDataUrl = _async_to_generator$v(function*(input) {
        // first ensure, that the input is a Blob
        if (input instanceof URL && input.protocol === "file:" || ___namespace.default.isString(input)) {
            // string or file URL
            const fs = DEFAULT_FS;
            const dataBuffer = yield fs.readFile(input instanceof URL ? input.pathname : input);
            input = new Blob([
                dataBuffer
            ]);
        } else if (!(input instanceof Blob)) {
            if (input instanceof URL) {
                throw new Error(`Unsupported URL with protocol: ${input.protocol}`);
            } else {
                throw new Error(`Unsupported input type: ${typeof input}`);
            }
        }
        return yield blobToDataUrl(input);
    });
    return _imageToDataUrl.apply(this, arguments);
}

exports.SimilarityType = void 0;
(function(SimilarityType) {
    SimilarityType["DEFAULT"] = "cosine";
    SimilarityType["DOT_PRODUCT"] = "dot_product";
    SimilarityType["EUCLIDEAN"] = "euclidean";
})(exports.SimilarityType || (exports.SimilarityType = {}));
class BaseEmbedding {
    similarity(embedding1, embedding2, mode = "cosine") {
        return similarity(embedding1, embedding2, mode);
    }
}

function asyncGeneratorStep$u(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$u(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$u(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$u(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/*
 * Base class for Multi Modal embeddings.
 */ class MultiModalEmbedding extends BaseEmbedding {
    getImageEmbeddings(images) {
        var _this = this;
        return _async_to_generator$u(function*() {
            return Promise.all(images.map((imgFilePath)=>_this.getImageEmbedding(imgFilePath)));
        })();
    }
}

function asyncGeneratorStep$t(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$t(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$t(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$t(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
exports.ClipEmbeddingModelType = void 0;
(function(ClipEmbeddingModelType) {
    ClipEmbeddingModelType["XENOVA_CLIP_VIT_BASE_PATCH32"] = "Xenova/clip-vit-base-patch32";
    ClipEmbeddingModelType["XENOVA_CLIP_VIT_BASE_PATCH16"] = "Xenova/clip-vit-base-patch16";
})(exports.ClipEmbeddingModelType || (exports.ClipEmbeddingModelType = {}));
class ClipEmbedding extends MultiModalEmbedding {
    getTokenizer() {
        var _this = this;
        return _async_to_generator$t(function*() {
            if (!_this.tokenizer) {
                const { AutoTokenizer } = yield import('@xenova/transformers');
                _this.tokenizer = yield AutoTokenizer.from_pretrained(_this.modelType);
            }
            return _this.tokenizer;
        })();
    }
    getProcessor() {
        var _this = this;
        return _async_to_generator$t(function*() {
            if (!_this.processor) {
                const { AutoProcessor } = yield import('@xenova/transformers');
                _this.processor = yield AutoProcessor.from_pretrained(_this.modelType);
            }
            return _this.processor;
        })();
    }
    getVisionModel() {
        var _this = this;
        return _async_to_generator$t(function*() {
            if (!_this.visionModel) {
                const { CLIPVisionModelWithProjection } = yield import('@xenova/transformers');
                _this.visionModel = yield CLIPVisionModelWithProjection.from_pretrained(_this.modelType);
            }
            return _this.visionModel;
        })();
    }
    getTextModel() {
        var _this = this;
        return _async_to_generator$t(function*() {
            if (!_this.textModel) {
                const { CLIPTextModelWithProjection } = yield import('@xenova/transformers');
                _this.textModel = yield CLIPTextModelWithProjection.from_pretrained(_this.modelType);
            }
            return _this.textModel;
        })();
    }
    getImageEmbedding(image) {
        var _this = this;
        return _async_to_generator$t(function*() {
            const loadedImage = yield readImage(image);
            const imageInputs = yield (yield _this.getProcessor())(loadedImage);
            const { image_embeds } = yield (yield _this.getVisionModel())(imageInputs);
            return Array.from(image_embeds.data);
        })();
    }
    getTextEmbedding(text) {
        var _this = this;
        return _async_to_generator$t(function*() {
            const textInputs = yield (yield _this.getTokenizer())([
                text
            ], {
                padding: true,
                truncation: true
            });
            const { text_embeds } = yield (yield _this.getTextModel())(textInputs);
            return text_embeds.data;
        })();
    }
    getQueryEmbedding(query) {
        var _this = this;
        return _async_to_generator$t(function*() {
            return _this.getTextEmbedding(query);
        })();
    }
    constructor(...args){
        super(...args);
        this.modelType = "Xenova/clip-vit-base-patch16";
    }
}

function asyncGeneratorStep$s(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$s(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$s(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$s(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
exports.HuggingFaceEmbeddingModelType = void 0;
(function(HuggingFaceEmbeddingModelType) {
    HuggingFaceEmbeddingModelType["XENOVA_ALL_MINILM_L6_V2"] = "Xenova/all-MiniLM-L6-v2";
    HuggingFaceEmbeddingModelType["XENOVA_ALL_MPNET_BASE_V2"] = "Xenova/all-mpnet-base-v2";
})(exports.HuggingFaceEmbeddingModelType || (exports.HuggingFaceEmbeddingModelType = {}));
/**
 * Uses feature extraction from '@xenova/transformers' to generate embeddings.
 * Per default the model [XENOVA_ALL_MINILM_L6_V2](https://huggingface.co/Xenova/all-MiniLM-L6-v2) is used.
 *
 * Can be changed by setting the `modelType` parameter in the constructor, e.g.:
 * ```
 * new HuggingFaceEmbedding({
 *     modelType: HuggingFaceEmbeddingModelType.XENOVA_ALL_MPNET_BASE_V2,
 * });
 * ```
 *
 * @extends BaseEmbedding
 */ class HuggingFaceEmbedding extends BaseEmbedding {
    getExtractor() {
        var _this = this;
        return _async_to_generator$s(function*() {
            if (!_this.extractor) {
                const { pipeline } = yield import('@xenova/transformers');
                _this.extractor = yield pipeline("feature-extraction", _this.modelType);
            }
            return _this.extractor;
        })();
    }
    getTextEmbedding(text) {
        var _this = this;
        return _async_to_generator$s(function*() {
            const extractor = yield _this.getExtractor();
            const output = yield extractor(text, {
                pooling: "mean",
                normalize: true
            });
            return output.data;
        })();
    }
    getQueryEmbedding(query) {
        var _this = this;
        return _async_to_generator$s(function*() {
            return _this.getTextEmbedding(query);
        })();
    }
    constructor(init){
        super();
        this.modelType = "Xenova/all-MiniLM-L6-v2";
        Object.assign(this, init);
    }
}

function _async_generator$1(gen) {
    var front, back;
    function send(key, arg) {
        return new Promise(function(resolve, reject) {
            var request = {
                key: key,
                arg: arg,
                resolve: resolve,
                reject: reject,
                next: null
            };
            if (back) {
                back = back.next = request;
            } else {
                front = back = request;
                resume(key, arg);
            }
        });
    }
    function resume(key, arg) {
        try {
            var result = gen[key](arg);
            var value = result.value;
            var wrappedAwait = value instanceof _await_value$1;
            Promise.resolve(wrappedAwait ? value.wrapped : value).then(function(arg) {
                if (wrappedAwait) {
                    resume("next", arg);
                    return;
                }
                settle(result.done ? "return" : "normal", arg);
            }, function(err) {
                resume("throw", err);
            });
        } catch (err) {
            settle("throw", err);
        }
    }
    function settle(type, value) {
        switch(type){
            case "return":
                front.resolve({
                    value: value,
                    done: true
                });
                break;
            case "throw":
                front.reject(value);
                break;
            default:
                front.resolve({
                    value: value,
                    done: false
                });
                break;
        }
        front = front.next;
        if (front) {
            resume(front.key, front.arg);
        } else {
            back = null;
        }
    }
    this._invoke = send;
    if (typeof gen.return !== "function") {
        this.return = undefined;
    }
}
if (typeof Symbol === "function" && Symbol.asyncIterator) {
    _async_generator$1.prototype[Symbol.asyncIterator] = function() {
        return this;
    };
}
_async_generator$1.prototype.next = function(arg) {
    return this._invoke("next", arg);
};
_async_generator$1.prototype.throw = function(arg) {
    return this._invoke("throw", arg);
};
_async_generator$1.prototype.return = function(arg) {
    return this._invoke("return", arg);
};
function _async_iterator$2(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$2(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$2(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$2 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$2.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$2(s);
}
function asyncGeneratorStep$r(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$r(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$r(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$r(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _await_async_generator$1(value) {
    return new _await_value$1(value);
}
function _await_value$1(value) {
    this.wrapped = value;
}
function _wrap_async_generator$1(fn) {
    return function() {
        return new _async_generator$1(fn.apply(this, arguments));
    };
}
const ALL_AVAILABLE_MISTRAL_MODELS = {
    "mistral-tiny": {
        contextWindow: 32000
    },
    "mistral-small": {
        contextWindow: 32000
    },
    "mistral-medium": {
        contextWindow: 32000
    }
};
class MistralAISession {
    getClient() {
        var _this = this;
        return _async_to_generator$r(function*() {
            const { default: MistralClient } = yield import('@mistralai/mistralai');
            if (!_this.client) {
                _this.client = new MistralClient(_this.apiKey);
            }
            return _this.client;
        })();
    }
    constructor(init){
        if (init == null ? void 0 : init.apiKey) {
            this.apiKey = init == null ? void 0 : init.apiKey;
        } else {
            if (typeof process !== undefined) {
                this.apiKey = process.env.MISTRAL_API_KEY;
            }
        }
        if (!this.apiKey) {
            throw new Error("Set Mistral API key in MISTRAL_API_KEY env variable"); // Overriding MistralAI package's error message
        }
    }
}
/**
 * MistralAI LLM implementation
 */ class MistralAI extends BaseLLM {
    get metadata() {
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: this.maxTokens,
            contextWindow: ALL_AVAILABLE_MISTRAL_MODELS[this.model].contextWindow,
            tokenizer: undefined
        };
    }
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    buildParams(messages) {
        return {
            model: this.model,
            temperature: this.temperature,
            maxTokens: this.maxTokens,
            topP: this.topP,
            safeMode: this.safeMode,
            randomSeed: this.randomSeed,
            messages
        };
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$r(function*() {
            const { messages, stream } = params;
            // Streaming
            if (stream) {
                return _this.streamChat(params);
            }
            // Non-streaming
            const client = yield _this.session.getClient();
            const response = yield client.chat(_this.buildParams(messages));
            const message = response.choices[0].message;
            return {
                message
            };
        })();
    }
    streamChat({ messages, parentEvent }) {
        var _this = this;
        return _wrap_async_generator$1(function*() {
            var _this_callbackManager;
            //Now let's wrap our stream in a callback
            const onLLMStream = ((_this_callbackManager = _this.callbackManager) == null ? void 0 : _this_callbackManager.onLLMStream) ? _this.callbackManager.onLLMStream : ()=>{};
            const client = yield _await_async_generator$1(_this.session.getClient());
            const chunkStream = yield _await_async_generator$1(client.chatStream(_this.buildParams(messages)));
            const event = parentEvent ? parentEvent : {
                id: "unspecified",
                type: "llmPredict"
            };
            //Indices
            var idx_counter = 0;
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$2(chunkStream), _step; _iteratorAbruptCompletion = !(_step = yield _await_async_generator$1(_iterator.next())).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const part = _value;
                        if (!part.choices.length) continue;
                        part.choices[0].index = idx_counter;
                        const isDone = part.choices[0].finish_reason === "stop" ? true : false;
                        const stream_callback = {
                            event: event,
                            index: idx_counter,
                            isDone: isDone,
                            token: part
                        };
                        onLLMStream(stream_callback);
                        idx_counter++;
                        var _part_choices__delta_content;
                        yield {
                            delta: (_part_choices__delta_content = part.choices[0].delta.content) != null ? _part_choices__delta_content : ""
                        };
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            return;
        })();
    }
    constructor(init){
        super();
        var _init_model;
        this.model = (_init_model = init == null ? void 0 : init.model) != null ? _init_model : "mistral-small";
        var _init_temperature;
        this.temperature = (_init_temperature = init == null ? void 0 : init.temperature) != null ? _init_temperature : 0.1;
        var _init_topP;
        this.topP = (_init_topP = init == null ? void 0 : init.topP) != null ? _init_topP : 1;
        var _init_maxTokens;
        this.maxTokens = (_init_maxTokens = init == null ? void 0 : init.maxTokens) != null ? _init_maxTokens : undefined;
        this.callbackManager = init == null ? void 0 : init.callbackManager;
        var _init_safeMode;
        this.safeMode = (_init_safeMode = init == null ? void 0 : init.safeMode) != null ? _init_safeMode : false;
        var _init_randomSeed;
        this.randomSeed = (_init_randomSeed = init == null ? void 0 : init.randomSeed) != null ? _init_randomSeed : undefined;
        this.session = new MistralAISession(init);
    }
}

function asyncGeneratorStep$q(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$q(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$q(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$q(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
exports.MistralAIEmbeddingModelType = void 0;
(function(MistralAIEmbeddingModelType) {
    MistralAIEmbeddingModelType["MISTRAL_EMBED"] = "mistral-embed";
})(exports.MistralAIEmbeddingModelType || (exports.MistralAIEmbeddingModelType = {}));
class MistralAIEmbedding extends BaseEmbedding {
    getMistralAIEmbedding(input) {
        var _this = this;
        return _async_to_generator$q(function*() {
            const client = yield _this.session.getClient();
            const { data } = yield client.embeddings({
                model: _this.model,
                input: [
                    input
                ]
            });
            return data[0].embedding;
        })();
    }
    getTextEmbedding(text) {
        var _this = this;
        return _async_to_generator$q(function*() {
            return _this.getMistralAIEmbedding(text);
        })();
    }
    getQueryEmbedding(query) {
        var _this = this;
        return _async_to_generator$q(function*() {
            return _this.getMistralAIEmbedding(query);
        })();
    }
    constructor(init){
        super();
        this.model = "mistral-embed";
        this.session = new MistralAISession(init);
    }
}

function asyncGeneratorStep$p(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$p(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$p(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$p(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _extends$7() {
    _extends$7 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$7.apply(this, arguments);
}
exports.OpenAIEmbeddingModelType = void 0;
(function(OpenAIEmbeddingModelType) {
    OpenAIEmbeddingModelType["TEXT_EMBED_ADA_002"] = "text-embedding-ada-002";
})(exports.OpenAIEmbeddingModelType || (exports.OpenAIEmbeddingModelType = {}));
class OpenAIEmbedding extends BaseEmbedding {
    getOpenAIEmbedding(input) {
        var _this = this;
        return _async_to_generator$p(function*() {
            const { data } = yield _this.session.openai.embeddings.create({
                model: _this.model,
                input
            });
            return data[0].embedding;
        })();
    }
    getTextEmbedding(text) {
        var _this = this;
        return _async_to_generator$p(function*() {
            return _this.getOpenAIEmbedding(text);
        })();
    }
    getQueryEmbedding(query) {
        var _this = this;
        return _async_to_generator$p(function*() {
            return _this.getOpenAIEmbedding(query);
        })();
    }
    constructor(init){
        super();
        // OpenAI session params
        this.apiKey = undefined;
        this.model = "text-embedding-ada-002";
        var _init_maxRetries;
        this.maxRetries = (_init_maxRetries = init == null ? void 0 : init.maxRetries) != null ? _init_maxRetries : 10;
        var _init_timeout;
        this.timeout = (_init_timeout = init == null ? void 0 : init.timeout) != null ? _init_timeout : 60 * 1000; // Default is 60 seconds
        this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
        if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
            const azureConfig = getAzureConfigFromEnv(_extends$7({}, init == null ? void 0 : init.azure, {
                model: getAzureModel(this.model)
            }));
            if (!azureConfig.apiKey) {
                throw new Error("Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable.");
            }
            this.apiKey = azureConfig.apiKey;
            var _init_session;
            this.session = (_init_session = init == null ? void 0 : init.session) != null ? _init_session : getOpenAISession(_extends$7({
                azure: true,
                apiKey: this.apiKey,
                baseURL: getAzureBaseUrl(azureConfig),
                maxRetries: this.maxRetries,
                timeout: this.timeout,
                defaultQuery: {
                    "api-version": azureConfig.apiVersion
                }
            }, this.additionalSessionOptions));
        } else {
            var _init_apiKey;
            this.apiKey = (_init_apiKey = init == null ? void 0 : init.apiKey) != null ? _init_apiKey : undefined;
            var _init_session1;
            this.session = (_init_session1 = init == null ? void 0 : init.session) != null ? _init_session1 : getOpenAISession(_extends$7({
                apiKey: this.apiKey,
                maxRetries: this.maxRetries,
                timeout: this.timeout
            }, this.additionalSessionOptions));
        }
    }
}

function _extends$6() {
    _extends$6 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$6.apply(this, arguments);
}
class TogetherEmbedding extends OpenAIEmbedding {
    constructor(init){
        super(_extends$6({
            apiKey: process.env.TOGETHER_API_KEY
        }, init, {
            additionalSessionOptions: _extends$6({}, init == null ? void 0 : init.additionalSessionOptions, {
                baseURL: "https://api.together.xyz/v1"
            })
        }));
        var _init_model;
        this.model = (_init_model = init == null ? void 0 : init.model) != null ? _init_model : "togethercomputer/m2-bert-80M-32k-retrieval";
    }
}

function _async_generator(gen) {
    var front, back;
    function send(key, arg) {
        return new Promise(function(resolve, reject) {
            var request = {
                key: key,
                arg: arg,
                resolve: resolve,
                reject: reject,
                next: null
            };
            if (back) {
                back = back.next = request;
            } else {
                front = back = request;
                resume(key, arg);
            }
        });
    }
    function resume(key, arg) {
        try {
            var result = gen[key](arg);
            var value = result.value;
            var wrappedAwait = value instanceof _await_value;
            Promise.resolve(wrappedAwait ? value.wrapped : value).then(function(arg) {
                if (wrappedAwait) {
                    resume("next", arg);
                    return;
                }
                settle(result.done ? "return" : "normal", arg);
            }, function(err) {
                resume("throw", err);
            });
        } catch (err) {
            settle("throw", err);
        }
    }
    function settle(type, value) {
        switch(type){
            case "return":
                front.resolve({
                    value: value,
                    done: true
                });
                break;
            case "throw":
                front.reject(value);
                break;
            default:
                front.resolve({
                    value: value,
                    done: false
                });
                break;
        }
        front = front.next;
        if (front) {
            resume(front.key, front.arg);
        } else {
            back = null;
        }
    }
    this._invoke = send;
    if (typeof gen.return !== "function") {
        this.return = undefined;
    }
}
if (typeof Symbol === "function" && Symbol.asyncIterator) {
    _async_generator.prototype[Symbol.asyncIterator] = function() {
        return this;
    };
}
_async_generator.prototype.next = function(arg) {
    return this._invoke("next", arg);
};
_async_generator.prototype.throw = function(arg) {
    return this._invoke("throw", arg);
};
_async_generator.prototype.return = function(arg) {
    return this._invoke("return", arg);
};
function asyncGeneratorStep$o(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$o(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$o(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$o(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _await_async_generator(value) {
    return new _await_value(value);
}
function _await_value(value) {
    this.wrapped = value;
}
function _extends$5() {
    _extends$5 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$5.apply(this, arguments);
}
function _wrap_async_generator(fn) {
    return function() {
        return new _async_generator(fn.apply(this, arguments));
    };
}
const messageAccessor = (data)=>{
    return {
        delta: data.message.content
    };
};
const completionAccessor = (data)=>{
    return {
        text: data.response
    };
};
// https://github.com/jmorganca/ollama
class Ollama extends BaseEmbedding {
    get metadata() {
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: undefined,
            contextWindow: this.contextWindow,
            tokenizer: undefined
        };
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$o(function*() {
            const { messages, parentEvent, stream } = params;
            const payload = {
                model: _this.model,
                messages: messages.map((message)=>({
                        role: message.role,
                        content: message.content
                    })),
                stream: !!stream,
                options: _extends$5({
                    temperature: _this.temperature,
                    num_ctx: _this.contextWindow,
                    top_p: _this.topP
                }, _this.additionalChatOptions)
            };
            const response = yield fetch(`${_this.baseURL}/api/chat`, {
                body: JSON.stringify(payload),
                method: "POST",
                signal: AbortSignal.timeout(_this.requestTimeout),
                headers: {
                    "Content-Type": "application/json"
                }
            });
            if (!stream) {
                const raw = yield response.json();
                const { message } = raw;
                return {
                    message: {
                        role: "assistant",
                        content: message.content
                    },
                    raw
                };
            } else {
                const stream = response.body;
                node_assert.ok(stream, "stream is null");
                node_assert.ok(stream instanceof ReadableStream, "stream is not readable");
                return _this.streamChat(stream, messageAccessor, parentEvent);
            }
        })();
    }
    streamChat(stream, accessor, parentEvent) {
        return _wrap_async_generator(function*() {
            const reader = stream.getReader();
            while(true){
                const { done, value } = yield _await_async_generator(reader.read());
                if (done) {
                    return;
                }
                const lines = Buffer.from(value).toString("utf-8").split("\n").map((line)=>line.trim());
                for (const line of lines){
                    if (line === "") {
                        continue;
                    }
                    const json = JSON.parse(line);
                    if (json.error) {
                        throw new Error(json.error);
                    }
                    yield accessor(json);
                }
            }
        })();
    }
    complete(params) {
        var _this = this;
        return _async_to_generator$o(function*() {
            const { prompt, parentEvent, stream } = params;
            const payload = {
                model: _this.model,
                prompt: prompt,
                stream: !!stream,
                options: _extends$5({
                    temperature: _this.temperature,
                    num_ctx: _this.contextWindow,
                    top_p: _this.topP
                }, _this.additionalChatOptions)
            };
            const response = yield fetch(`${_this.baseURL}/api/generate`, {
                body: JSON.stringify(payload),
                method: "POST",
                signal: AbortSignal.timeout(_this.requestTimeout),
                headers: {
                    "Content-Type": "application/json"
                }
            });
            if (!stream) {
                const raw = yield response.json();
                return {
                    text: raw.response,
                    raw
                };
            } else {
                const stream = response.body;
                node_assert.ok(stream, "stream is null");
                node_assert.ok(stream instanceof ReadableStream, "stream is not readable");
                return _this.streamChat(stream, completionAccessor, parentEvent);
            }
        })();
    }
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    getEmbedding(prompt) {
        var _this = this;
        return _async_to_generator$o(function*() {
            const payload = {
                model: _this.model,
                prompt,
                options: _extends$5({
                    temperature: _this.temperature,
                    num_ctx: _this.contextWindow,
                    top_p: _this.topP
                }, _this.additionalChatOptions)
            };
            const response = yield fetch(`${_this.baseURL}/api/embeddings`, {
                body: JSON.stringify(payload),
                method: "POST",
                signal: AbortSignal.timeout(_this.requestTimeout),
                headers: {
                    "Content-Type": "application/json"
                }
            });
            const { embedding } = yield response.json();
            return embedding;
        })();
    }
    getTextEmbedding(text) {
        var _this = this;
        return _async_to_generator$o(function*() {
            return _this.getEmbedding(text);
        })();
    }
    getQueryEmbedding(query) {
        var _this = this;
        return _async_to_generator$o(function*() {
            return _this.getEmbedding(query);
        })();
    }
    constructor(init){
        super();
        this.hasStreaming = true;
        this.baseURL = "http://127.0.0.1:11434";
        this.temperature = 0.7;
        this.topP = 0.9;
        this.contextWindow = 4096;
        this.requestTimeout = 60 * 1000 // Default is 60 seconds
        ;
        this.model = init.model;
        Object.assign(this, init);
    }
}

function _extends$4() {
    _extends$4 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$4.apply(this, arguments);
}
class TogetherLLM extends OpenAI {
    constructor(init){
        super(_extends$4({}, init, {
            apiKey: process.env.TOGETHER_API_KEY,
            additionalSessionOptions: _extends$4({}, init == null ? void 0 : init.additionalSessionOptions, {
                baseURL: "https://api.together.xyz/v1"
            })
        }));
    }
}

/**
 * Splits the text of a document into smaller parts.
 * @param document - The document to split.
 * @param textSplitter - The text splitter to use.
 * @returns An array of text splits.
 */ function getTextSplitsFromDocument(document, textSplitter) {
    const text = document.getText();
    return textSplitter(text);
}
/**
 * Generates an array of nodes from a document.
 * @param doc
 * @param textSplitter - The text splitter to use.
 * @param includeMetadata - Whether to include metadata in the nodes.
 * @param includePrevNextRel - Whether to include previous and next relationships in the nodes.
 * @returns An array of nodes.
 */ function getNodesFromDocument(doc, textSplitter, includeMetadata = true, includePrevNextRel = true) {
    if (doc instanceof ImageDocument) {
        // TODO: use text splitter on text of image documents
        return [
            doc
        ];
    }
    if (!(doc instanceof Document)) {
        throw new Error("Expected either an Image Document or Document");
    }
    const document = doc;
    const nodes = [];
    const textSplits = getTextSplitsFromDocument(document, textSplitter);
    textSplits.forEach((textSplit)=>{
        const node = new TextNode({
            text: textSplit,
            metadata: includeMetadata ? ___namespace.default.cloneDeep(document.metadata) : {},
            excludedEmbedMetadataKeys: ___namespace.default.cloneDeep(document.excludedEmbedMetadataKeys),
            excludedLlmMetadataKeys: ___namespace.default.cloneDeep(document.excludedLlmMetadataKeys)
        });
        node.relationships[exports.NodeRelationship.SOURCE] = document.asRelatedNodeInfo();
        nodes.push(node);
    });
    if (includePrevNextRel) {
        nodes.forEach((node, index)=>{
            if (index > 0) {
                node.relationships[exports.NodeRelationship.PREVIOUS] = nodes[index - 1].asRelatedNodeInfo();
            }
            if (index < nodes.length - 1) {
                node.relationships[exports.NodeRelationship.NEXT] = nodes[index + 1].asRelatedNodeInfo();
            }
        });
    }
    return nodes;
}

const DEFAULT_WINDOW_SIZE = 3;
const DEFAULT_WINDOW_METADATA_KEY = "window";
const DEFAULT_OG_TEXT_METADATA_KEY = "original_text";
class SentenceWindowNodeParser {
    static fromDefaults(init) {
        return new SentenceWindowNodeParser(init);
    }
    getNodesFromDocuments(documents) {
        return documents.map((document)=>this.buildWindowNodesFromDocument(document)).flat();
    }
    buildWindowNodesFromDocument(doc) {
        const nodes = getNodesFromDocument(doc, this.textSplitter.getSentenceSplits.bind(this.textSplitter), this.includeMetadata, this.includePrevNextRel);
        for(let i = 0; i < nodes.length; i++){
            const node = nodes[i];
            const windowNodes = nodes.slice(Math.max(0, i - this.windowSize), Math.min(i + this.windowSize + 1, nodes.length));
            node.metadata[this.windowMetadataKey] = windowNodes.map((n)=>n.getText()).join(" ");
            node.metadata[this.originalTextMetadataKey] = node.getText();
            node.excludedEmbedMetadataKeys.push(this.windowMetadataKey, this.originalTextMetadataKey);
            node.excludedLlmMetadataKeys.push(this.windowMetadataKey, this.originalTextMetadataKey);
        }
        return nodes;
    }
    constructor(init){
        /**
   * The number of sentences on each side of a sentence to capture.
   */ this.windowSize = DEFAULT_WINDOW_SIZE;
        /**
   * The metadata key to store the sentence window under.
   */ this.windowMetadataKey = DEFAULT_WINDOW_METADATA_KEY;
        /**
   * The metadata key to store the original sentence in.
   */ this.originalTextMetadataKey = DEFAULT_OG_TEXT_METADATA_KEY;
        /**
   * Whether to include metadata in the nodes.
   */ this.includeMetadata = true;
        /**
   * Whether to include previous and next relationships in the nodes.
   */ this.includePrevNextRel = true;
        Object.assign(this, init);
        var _init_textSplitter;
        this.textSplitter = (_init_textSplitter = init == null ? void 0 : init.textSplitter) != null ? _init_textSplitter : new SentenceSplitter();
    }
}

/**
 * SimpleNodeParser is the default NodeParser. It splits documents into TextNodes using a splitter, by default SentenceSplitter
 */ class SimpleNodeParser {
    static fromDefaults(init) {
        return new SimpleNodeParser(init);
    }
    /**
   * Generate Node objects from documents
   * @param documents
   */ getNodesFromDocuments(documents) {
        return documents.map((document)=>getNodesFromDocument(document, this.textSplitter.splitText.bind(this.textSplitter), this.includeMetadata, this.includePrevNextRel)).flat();
    }
    constructor(init){
        var _init_chunkSize, _init_chunkOverlap, _init_textSplitter;
        this.textSplitter = (_init_textSplitter = init == null ? void 0 : init.textSplitter) != null ? _init_textSplitter : new SentenceSplitter({
            chunkSize: (_init_chunkSize = init == null ? void 0 : init.chunkSize) != null ? _init_chunkSize : DEFAULT_CHUNK_SIZE,
            chunkOverlap: (_init_chunkOverlap = init == null ? void 0 : init.chunkOverlap) != null ? _init_chunkOverlap : DEFAULT_CHUNK_OVERLAP
        });
        var _init_includeMetadata;
        this.includeMetadata = (_init_includeMetadata = init == null ? void 0 : init.includeMetadata) != null ? _init_includeMetadata : true;
        var _init_includePrevNextRel;
        this.includePrevNextRel = (_init_includePrevNextRel = init == null ? void 0 : init.includePrevNextRel) != null ? _init_includePrevNextRel : true;
    }
}

function _extends$3() {
    _extends$3 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$3.apply(this, arguments);
}
function serviceContextFromDefaults(options) {
    var _options_callbackManager;
    const callbackManager = (_options_callbackManager = options == null ? void 0 : options.callbackManager) != null ? _options_callbackManager : new CallbackManager();
    var _options_llm, _options_embedModel, _options_nodeParser, _options_promptHelper;
    const serviceContext = {
        llm: (_options_llm = options == null ? void 0 : options.llm) != null ? _options_llm : new OpenAI(),
        embedModel: (_options_embedModel = options == null ? void 0 : options.embedModel) != null ? _options_embedModel : new OpenAIEmbedding(),
        nodeParser: (_options_nodeParser = options == null ? void 0 : options.nodeParser) != null ? _options_nodeParser : new SimpleNodeParser({
            chunkSize: options == null ? void 0 : options.chunkSize,
            chunkOverlap: options == null ? void 0 : options.chunkOverlap
        }),
        promptHelper: (_options_promptHelper = options == null ? void 0 : options.promptHelper) != null ? _options_promptHelper : new PromptHelper(),
        callbackManager
    };
    return serviceContext;
}
function serviceContextFromServiceContext(serviceContext, options) {
    const newServiceContext = _extends$3({}, serviceContext);
    if (options.llm) {
        newServiceContext.llm = options.llm;
    }
    if (options.promptHelper) {
        newServiceContext.promptHelper = options.promptHelper;
    }
    if (options.embedModel) {
        newServiceContext.embedModel = options.embedModel;
    }
    if (options.nodeParser) {
        newServiceContext.nodeParser = options.nodeParser;
    }
    if (options.callbackManager) {
        newServiceContext.callbackManager = options.callbackManager;
    }
    return newServiceContext;
}

/**
 * Response is the output of a LLM
 */ class Response {
    getFormattedSources() {
        throw new Error("Not implemented yet");
    }
    toString() {
        var _this_response;
        return (_this_response = this.response) != null ? _this_response : "";
    }
    constructor(response, sourceNodes){
        this.response = response;
        this.sourceNodes = sourceNodes || [];
    }
}

function asyncGeneratorStep$n(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$n(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$n(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$n(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class MultiModalResponseSynthesizer {
    synthesize({ query, nodesWithScore, parentEvent, stream }) {
        var _this = this;
        return _async_to_generator$n(function*() {
            if (stream) {
                throw new Error("streaming not implemented");
            }
            const nodes = nodesWithScore.map(({ node })=>node);
            const { imageNodes, textNodes } = splitNodesByType(nodes);
            const textChunks = textNodes.map((node)=>node.getContent(_this.metadataMode));
            // TODO: use builders to generate context
            const context = textChunks.join("\n\n");
            const textPrompt = _this.textQATemplate({
                context,
                query
            });
            const images = yield Promise.all(imageNodes.map(/*#__PURE__*/ _async_to_generator$n(function*(node) {
                return {
                    type: "image_url",
                    image_url: {
                        url: yield imageToDataUrl(node.image)
                    }
                };
            })));
            const prompt = [
                {
                    type: "text",
                    text: textPrompt
                },
                ...images
            ];
            let response = yield _this.serviceContext.llm.complete({
                prompt,
                parentEvent
            });
            return new Response(response.text, nodes);
        })();
    }
    constructor({ serviceContext, textQATemplate, metadataMode } = {}){
        this.serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults();
        this.metadataMode = metadataMode != null ? metadataMode : exports.MetadataMode.NONE;
        this.textQATemplate = textQATemplate != null ? textQATemplate : defaultTextQaPrompt;
    }
}

function asyncGeneratorStep$m(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$m(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$m(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$m(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _extends$2() {
    _extends$2 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$2.apply(this, arguments);
}
var ResponseMode;
/**
 * Response modes of the response synthesizer
 */ (function(ResponseMode) {
    ResponseMode["REFINE"] = "refine";
    ResponseMode["COMPACT"] = "compact";
    ResponseMode["TREE_SUMMARIZE"] = "tree_summarize";
    ResponseMode["SIMPLE"] = "simple";
})(ResponseMode || (ResponseMode = {}));
/**
 * A response builder that just concatenates responses.
 */ class SimpleResponseBuilder {
    getResponse({ query, textChunks, parentEvent, stream }) {
        var _this = this;
        return _async_to_generator$m(function*() {
            const input = {
                query,
                context: textChunks.join("\n\n")
            };
            const prompt = _this.textQATemplate(input);
            if (stream) {
                const response = yield _this.llm.complete({
                    prompt,
                    parentEvent,
                    stream
                });
                return streamConverter(response, (chunk)=>chunk.text);
            } else {
                const response = yield _this.llm.complete({
                    prompt,
                    parentEvent,
                    stream
                });
                return response.text;
            }
        })();
    }
    constructor(serviceContext){
        this.llm = serviceContext.llm;
        this.textQATemplate = defaultTextQaPrompt;
    }
}
/**
 * A response builder that uses the query to ask the LLM generate a better response using multiple text chunks.
 */ class Refine {
    getResponse({ query, textChunks, parentEvent, prevResponse, stream }) {
        var _this = this;
        return _async_to_generator$m(function*() {
            let response = prevResponse;
            for(let i = 0; i < textChunks.length; i++){
                const chunk = textChunks[i];
                const lastChunk = i === textChunks.length - 1;
                if (!response) {
                    response = yield _this.giveResponseSingle(query, chunk, !!stream && lastChunk, parentEvent);
                } else {
                    response = yield _this.refineResponseSingle(response, query, chunk, !!stream && lastChunk, parentEvent);
                }
            }
            return response != null ? response : "Empty Response";
        })();
    }
    giveResponseSingle(queryStr, textChunk, stream, parentEvent) {
        var _this = this;
        return _async_to_generator$m(function*() {
            const textQATemplate = (input)=>_this.textQATemplate(_extends$2({}, input, {
                    query: queryStr
                }));
            const textChunks = _this.promptHelper.repack(textQATemplate, [
                textChunk
            ]);
            let response = undefined;
            for(let i = 0; i < textChunks.length; i++){
                const chunk = textChunks[i];
                const lastChunk = i === textChunks.length - 1;
                if (!response) {
                    response = yield _this.complete({
                        prompt: textQATemplate({
                            context: chunk
                        }),
                        parentEvent,
                        stream: stream && lastChunk
                    });
                } else {
                    response = yield _this.refineResponseSingle(response, queryStr, chunk, stream && lastChunk, parentEvent);
                }
            }
            return response;
        })();
    }
    // eslint-disable-next-line max-params
    refineResponseSingle(initialReponse, queryStr, textChunk, stream, parentEvent) {
        var _this = this;
        return _async_to_generator$m(function*() {
            const refineTemplate = (input)=>_this.refineTemplate(_extends$2({}, input, {
                    query: queryStr
                }));
            const textChunks = _this.promptHelper.repack(refineTemplate, [
                textChunk
            ]);
            let response = initialReponse;
            for(let i = 0; i < textChunks.length; i++){
                const chunk = textChunks[i];
                const lastChunk = i === textChunks.length - 1;
                response = yield _this.complete({
                    prompt: refineTemplate({
                        context: chunk,
                        existingAnswer: response
                    }),
                    parentEvent,
                    stream: stream && lastChunk
                });
            }
            return response;
        })();
    }
    complete(params) {
        var _this = this;
        return _async_to_generator$m(function*() {
            if (params.stream) {
                const response = yield _this.llm.complete(_extends$2({}, params, {
                    stream: true
                }));
                return streamConverter(response, (chunk)=>chunk.text);
            } else {
                const response = yield _this.llm.complete(_extends$2({}, params, {
                    stream: false
                }));
                return response.text;
            }
        })();
    }
    constructor(serviceContext, textQATemplate, refineTemplate){
        this.llm = serviceContext.llm;
        this.promptHelper = serviceContext.promptHelper;
        this.textQATemplate = textQATemplate != null ? textQATemplate : defaultTextQaPrompt;
        this.refineTemplate = refineTemplate != null ? refineTemplate : defaultRefinePrompt;
    }
}
/**
 * CompactAndRefine is a slight variation of Refine that first compacts the text chunks into the smallest possible number of chunks.
 */ class CompactAndRefine extends Refine {
    getResponse({ query, textChunks, parentEvent, prevResponse, stream }) {
        var _this = this, _superprop_get_getResponse = ()=>super.getResponse;
        return _async_to_generator$m(function*() {
            const textQATemplate = (input)=>_this.textQATemplate(_extends$2({}, input, {
                    query: query
                }));
            const refineTemplate = (input)=>_this.refineTemplate(_extends$2({}, input, {
                    query: query
                }));
            const maxPrompt = getBiggestPrompt([
                textQATemplate,
                refineTemplate
            ]);
            const newTexts = _this.promptHelper.repack(maxPrompt, textChunks);
            const params = {
                query,
                textChunks: newTexts,
                parentEvent,
                prevResponse
            };
            if (stream) {
                return _superprop_get_getResponse().call(_this, _extends$2({}, params, {
                    stream
                }));
            }
            return _superprop_get_getResponse().call(_this, params);
        })();
    }
}
/**
 * TreeSummarize repacks the text chunks into the smallest possible number of chunks and then summarizes them, then recursively does so until there's one chunk left.
 */ class TreeSummarize {
    getResponse({ query, textChunks, parentEvent, stream }) {
        var _this = this;
        return _async_to_generator$m(function*() {
            if (!textChunks || textChunks.length === 0) {
                throw new Error("Must have at least one text chunk");
            }
            // Should we send the query here too?
            const packedTextChunks = _this.promptHelper.repack(_this.summaryTemplate, textChunks);
            if (packedTextChunks.length === 1) {
                const params = {
                    prompt: _this.summaryTemplate({
                        context: packedTextChunks[0],
                        query
                    }),
                    parentEvent
                };
                if (stream) {
                    const response = yield _this.llm.complete(_extends$2({}, params, {
                        stream
                    }));
                    return streamConverter(response, (chunk)=>chunk.text);
                }
                return (yield _this.llm.complete(params)).text;
            } else {
                const summaries = yield Promise.all(packedTextChunks.map((chunk)=>_this.llm.complete({
                        prompt: _this.summaryTemplate({
                            context: chunk,
                            query
                        }),
                        parentEvent
                    })));
                const params = {
                    query,
                    textChunks: summaries.map((s)=>s.text)
                };
                if (stream) {
                    return _this.getResponse(_extends$2({}, params, {
                        stream
                    }));
                }
                return _this.getResponse(params);
            }
        })();
    }
    constructor(serviceContext, summaryTemplate){
        this.llm = serviceContext.llm;
        this.promptHelper = serviceContext.promptHelper;
        this.summaryTemplate = summaryTemplate != null ? summaryTemplate : defaultTreeSummarizePrompt;
    }
}
function getResponseBuilder(serviceContext, responseMode) {
    switch(responseMode){
        case "simple":
            return new SimpleResponseBuilder(serviceContext);
        case "refine":
            return new Refine(serviceContext);
        case "tree_summarize":
            return new TreeSummarize(serviceContext);
        default:
            return new CompactAndRefine(serviceContext);
    }
}

function asyncGeneratorStep$l(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$l(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$l(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$l(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * A ResponseSynthesizer is used to generate a response from a query and a list of nodes.
 */ class ResponseSynthesizer {
    synthesize({ query, nodesWithScore, parentEvent, stream }) {
        var _this = this;
        return _async_to_generator$l(function*() {
            const textChunks = nodesWithScore.map(({ node })=>node.getContent(_this.metadataMode));
            const nodes = nodesWithScore.map(({ node })=>node);
            if (stream) {
                const response = yield _this.responseBuilder.getResponse({
                    query,
                    textChunks,
                    parentEvent,
                    stream
                });
                return streamConverter(response, (chunk)=>new Response(chunk, nodes));
            }
            const response = yield _this.responseBuilder.getResponse({
                query,
                textChunks,
                parentEvent
            });
            return new Response(response, nodes);
        })();
    }
    constructor({ responseBuilder, serviceContext, metadataMode = exports.MetadataMode.NONE } = {}){
        this.serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults();
        this.responseBuilder = responseBuilder != null ? responseBuilder : getResponseBuilder(this.serviceContext);
        this.metadataMode = metadataMode;
    }
}

function asyncGeneratorStep$k(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$k(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$k(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$k(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * A query engine that uses a retriever to query an index and then synthesizes the response.
 */ class RetrieverQueryEngine {
    applyNodePostprocessors(nodes) {
        return this.nodePostprocessors.reduce((nodes, nodePostprocessor)=>nodePostprocessor.postprocessNodes(nodes), nodes);
    }
    retrieve(query, parentEvent) {
        var _this = this;
        return _async_to_generator$k(function*() {
            const nodes = yield _this.retriever.retrieve(query, parentEvent, _this.preFilters);
            return _this.applyNodePostprocessors(nodes);
        })();
    }
    query(params) {
        var _this = this;
        return _async_to_generator$k(function*() {
            const { query, stream } = params;
            const parentEvent = params.parentEvent || {
                id: node_crypto.randomUUID(),
                type: "wrapper",
                tags: [
                    "final"
                ]
            };
            const nodesWithScore = yield _this.retrieve(query, parentEvent);
            if (stream) {
                return _this.responseSynthesizer.synthesize({
                    query,
                    nodesWithScore,
                    parentEvent,
                    stream: true
                });
            }
            return _this.responseSynthesizer.synthesize({
                query,
                nodesWithScore,
                parentEvent
            });
        })();
    }
    constructor(retriever, responseSynthesizer, preFilters, nodePostprocessors){
        this.retriever = retriever;
        const serviceContext = this.retriever.getServiceContext();
        this.responseSynthesizer = responseSynthesizer || new ResponseSynthesizer({
            serviceContext
        });
        this.preFilters = preFilters;
        this.nodePostprocessors = nodePostprocessors || [];
    }
}
/**
 * SubQuestionQueryEngine decomposes a question into subquestions and then
 */ class SubQuestionQueryEngine {
    static fromDefaults(init) {
        var _init_serviceContext;
        const serviceContext = (_init_serviceContext = init.serviceContext) != null ? _init_serviceContext : serviceContextFromDefaults({});
        var _init_questionGen;
        const questionGen = (_init_questionGen = init.questionGen) != null ? _init_questionGen : new LLMQuestionGenerator();
        var _init_responseSynthesizer;
        const responseSynthesizer = (_init_responseSynthesizer = init.responseSynthesizer) != null ? _init_responseSynthesizer : new ResponseSynthesizer({
            responseBuilder: new CompactAndRefine(serviceContext),
            serviceContext
        });
        return new SubQuestionQueryEngine({
            questionGen,
            responseSynthesizer,
            queryEngineTools: init.queryEngineTools
        });
    }
    query(params) {
        var _this = this;
        return _async_to_generator$k(function*() {
            const { query, stream } = params;
            const subQuestions = yield _this.questionGen.generate(_this.metadatas, query);
            // groups final retrieval+synthesis operation
            const parentEvent = params.parentEvent || {
                id: node_crypto.randomUUID(),
                type: "wrapper",
                tags: [
                    "final"
                ]
            };
            // groups all sub-queries
            const subQueryParentEvent = {
                id: node_crypto.randomUUID(),
                parentId: parentEvent.id,
                type: "wrapper",
                tags: [
                    "intermediate"
                ]
            };
            const subQNodes = yield Promise.all(subQuestions.map((subQ)=>_this.querySubQ(subQ, subQueryParentEvent)));
            const nodesWithScore = subQNodes.filter((node)=>node !== null).map((node)=>node);
            if (stream) {
                return _this.responseSynthesizer.synthesize({
                    query,
                    nodesWithScore,
                    parentEvent,
                    stream: true
                });
            }
            return _this.responseSynthesizer.synthesize({
                query,
                nodesWithScore,
                parentEvent
            });
        })();
    }
    querySubQ(subQ, parentEvent) {
        var _this = this;
        return _async_to_generator$k(function*() {
            try {
                const question = subQ.subQuestion;
                const queryEngine = _this.queryEngines[subQ.toolName];
                const response = yield queryEngine.query({
                    query: question,
                    parentEvent
                });
                const responseText = response.response;
                const nodeText = `Sub question: ${question}\nResponse: ${responseText}`;
                const node = new TextNode({
                    text: nodeText
                });
                return {
                    node,
                    score: 0
                };
            } catch (error) {
                return null;
            }
        })();
    }
    constructor(init){
        this.questionGen = init.questionGen;
        var _init_responseSynthesizer;
        this.responseSynthesizer = (_init_responseSynthesizer = init.responseSynthesizer) != null ? _init_responseSynthesizer : new ResponseSynthesizer();
        this.queryEngines = init.queryEngineTools.reduce((acc, tool)=>{
            acc[tool.metadata.name] = tool.queryEngine;
            return acc;
        }, {});
        this.metadatas = init.queryEngineTools.map((tool)=>tool.metadata);
    }
}

function asyncGeneratorStep$j(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$j(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$j(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$j(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * CondenseQuestionChatEngine is used in conjunction with a Index (for example VectorStoreIndex).
 * It does two steps on taking a user's chat message: first, it condenses the chat message
 * with the previous chat history into a question with more context.
 * Then, it queries the underlying Index using the new question with context and returns
 * the response.
 * CondenseQuestionChatEngine performs well when the input is primarily questions about the
 * underlying data. It performs less well when the chat messages are not questions about the
 * data, or are very referential to previous context.
 */ class CondenseQuestionChatEngine {
    condenseQuestion(chatHistory, question) {
        var _this = this;
        return _async_to_generator$j(function*() {
            const chatHistoryStr = messagesToHistoryStr((yield chatHistory.requestMessages()));
            return _this.llm.complete({
                prompt: defaultCondenseQuestionPrompt({
                    question: question,
                    chatHistory: chatHistoryStr
                })
            });
        })();
    }
    chat(params) {
        var _this = this;
        return _async_to_generator$j(function*() {
            const { message, stream } = params;
            const chatHistory = params.chatHistory ? getHistory(params.chatHistory) : _this.chatHistory;
            const condensedQuestion = (yield _this.condenseQuestion(chatHistory, extractText(message))).text;
            chatHistory.addMessage({
                content: message,
                role: "user"
            });
            if (stream) {
                const stream = yield _this.queryEngine.query({
                    query: condensedQuestion,
                    stream: true
                });
                return streamReducer({
                    stream,
                    initialValue: "",
                    reducer: (accumulator, part)=>accumulator += part.response,
                    finished: (accumulator)=>{
                        chatHistory.addMessage({
                            content: accumulator,
                            role: "assistant"
                        });
                    }
                });
            }
            const response = yield _this.queryEngine.query({
                query: condensedQuestion
            });
            chatHistory.addMessage({
                content: response.response,
                role: "assistant"
            });
            return response;
        })();
    }
    reset() {
        this.chatHistory.reset();
    }
    constructor(init){
        var _init_serviceContext;
        this.queryEngine = init.queryEngine;
        this.chatHistory = getHistory(init == null ? void 0 : init.chatHistory);
        var _init_serviceContext_llm;
        this.llm = (_init_serviceContext_llm = init == null ? void 0 : (_init_serviceContext = init.serviceContext) == null ? void 0 : _init_serviceContext.llm) != null ? _init_serviceContext_llm : serviceContextFromDefaults().llm;
        var _init_condenseMessagePrompt;
        this.condenseMessagePrompt = (_init_condenseMessagePrompt = init == null ? void 0 : init.condenseMessagePrompt) != null ? _init_condenseMessagePrompt : defaultCondenseQuestionPrompt;
    }
}

function asyncGeneratorStep$i(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$i(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$i(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$i(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class DefaultContextGenerator {
    applyNodePostprocessors(nodes) {
        return this.nodePostprocessors.reduce((nodes, nodePostprocessor)=>nodePostprocessor.postprocessNodes(nodes), nodes);
    }
    generate(message, parentEvent) {
        var _this = this;
        return _async_to_generator$i(function*() {
            if (!parentEvent) {
                parentEvent = {
                    id: node_crypto.randomUUID(),
                    type: "wrapper",
                    tags: [
                        "final"
                    ]
                };
            }
            const sourceNodesWithScore = yield _this.retriever.retrieve(message, parentEvent);
            const nodes = _this.applyNodePostprocessors(sourceNodesWithScore);
            return {
                message: {
                    content: _this.contextSystemPrompt({
                        context: nodes.map((r)=>r.node.text).join("\n\n")
                    }),
                    role: "system"
                },
                nodes
            };
        })();
    }
    constructor(init){
        this.retriever = init.retriever;
        var _init_contextSystemPrompt;
        this.contextSystemPrompt = (_init_contextSystemPrompt = init == null ? void 0 : init.contextSystemPrompt) != null ? _init_contextSystemPrompt : defaultContextSystemPrompt;
        this.nodePostprocessors = init.nodePostprocessors || [];
    }
}

function asyncGeneratorStep$h(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$h(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$h(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$h(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * ContextChatEngine uses the Index to get the appropriate context for each query.
 * The context is stored in the system prompt, and the chat history is preserved,
 * ideally allowing the appropriate context to be surfaced for each query.
 */ class ContextChatEngine {
    chat(params) {
        var _this = this;
        return _async_to_generator$h(function*() {
            const { message, stream } = params;
            const chatHistory = params.chatHistory ? getHistory(params.chatHistory) : _this.chatHistory;
            const parentEvent = {
                id: node_crypto.randomUUID(),
                type: "wrapper",
                tags: [
                    "final"
                ]
            };
            const requestMessages = yield _this.prepareRequestMessages(message, chatHistory, parentEvent);
            if (stream) {
                const stream = yield _this.chatModel.chat({
                    messages: requestMessages.messages,
                    parentEvent,
                    stream: true
                });
                return streamConverter(streamReducer({
                    stream,
                    initialValue: "",
                    reducer: (accumulator, part)=>accumulator += part.delta,
                    finished: (accumulator)=>{
                        chatHistory.addMessage({
                            content: accumulator,
                            role: "assistant"
                        });
                    }
                }), (r)=>new Response(r.delta, requestMessages.nodes));
            }
            const response = yield _this.chatModel.chat({
                messages: requestMessages.messages,
                parentEvent
            });
            chatHistory.addMessage(response.message);
            return new Response(response.message.content, requestMessages.nodes);
        })();
    }
    reset() {
        this.chatHistory.reset();
    }
    prepareRequestMessages(message, chatHistory, parentEvent) {
        var _this = this;
        return _async_to_generator$h(function*() {
            chatHistory.addMessage({
                content: message,
                role: "user"
            });
            const textOnly = extractText(message);
            const context = yield _this.contextGenerator.generate(textOnly, parentEvent);
            const nodes = context.nodes.map((r)=>r.node);
            const messages = yield chatHistory.requestMessages(context ? [
                context.message
            ] : undefined);
            return {
                nodes,
                messages
            };
        })();
    }
    constructor(init){
        var _init_chatModel;
        this.chatModel = (_init_chatModel = init.chatModel) != null ? _init_chatModel : new OpenAI({
            model: "gpt-3.5-turbo-16k"
        });
        this.chatHistory = getHistory(init == null ? void 0 : init.chatHistory);
        this.contextGenerator = new DefaultContextGenerator({
            retriever: init.retriever,
            contextSystemPrompt: init == null ? void 0 : init.contextSystemPrompt,
            nodePostprocessors: init == null ? void 0 : init.nodePostprocessors
        });
    }
}

function asyncGeneratorStep$g(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$g(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$g(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$g(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * SimpleChatEngine is the simplest possible chat engine. Useful for using your own custom prompts.
 */ class SimpleChatEngine {
    chat(params) {
        var _this = this;
        return _async_to_generator$g(function*() {
            const { message, stream } = params;
            const chatHistory = params.chatHistory ? getHistory(params.chatHistory) : _this.chatHistory;
            chatHistory.addMessage({
                content: message,
                role: "user"
            });
            if (stream) {
                const stream = yield _this.llm.chat({
                    messages: yield chatHistory.requestMessages(),
                    stream: true
                });
                return streamConverter(streamReducer({
                    stream,
                    initialValue: "",
                    reducer: (accumulator, part)=>accumulator += part.delta,
                    finished: (accumulator)=>{
                        chatHistory.addMessage({
                            content: accumulator,
                            role: "assistant"
                        });
                    }
                }), (r)=>new Response(r.delta));
            }
            const response = yield _this.llm.chat({
                messages: yield chatHistory.requestMessages()
            });
            chatHistory.addMessage(response.message);
            return new Response(response.message.content);
        })();
    }
    reset() {
        this.chatHistory.reset();
    }
    constructor(init){
        this.chatHistory = getHistory(init == null ? void 0 : init.chatHistory);
        var _init_llm;
        this.llm = (_init_llm = init == null ? void 0 : init.llm) != null ? _init_llm : new OpenAI();
    }
}

// @ts-ignore
// Get subtokens from a list of tokens., filtering for stopwords.
function expandTokensWithSubtokens(tokens) {
    const results = new Set();
    const regex = /\w+/g;
    for (let token of tokens){
        results.add(token);
        const subTokens = token.match(regex);
        if (subTokens && subTokens.length > 1) {
            for (let w of subTokens){
                results.add(w);
            }
        }
    }
    return results;
}
function extractKeywordsGivenResponse(response, startToken = "", lowercase = true) {
    const results = [];
    response = response.trim();
    if (response.startsWith(startToken)) {
        response = response.substring(startToken.length);
    }
    const keywords = response.split(",");
    for (let k of keywords){
        let rk = k;
        if (lowercase) {
            rk = rk.toLowerCase();
        }
        results.push(rk.trim());
    }
    return expandTokensWithSubtokens(new Set(results));
}
function simpleExtractKeywords(textChunk, maxKeywords) {
    const regex = /\w+/g;
    let tokens = [
        ...textChunk.matchAll(regex)
    ].map((token)=>token[0].toLowerCase().trim());
    // Creating a frequency map
    const valueCounts = {};
    for (let token of tokens){
        valueCounts[token] = (valueCounts[token] || 0) + 1;
    }
    // Sorting tokens by frequency
    const sortedTokens = Object.keys(valueCounts).sort((a, b)=>valueCounts[b] - valueCounts[a]);
    const keywords = maxKeywords ? sortedTokens.slice(0, maxKeywords) : sortedTokens;
    return new Set(keywords);
}
function rakeExtractKeywords(textChunk, maxKeywords) {
    const keywords = Object.keys(rake__default.default(textChunk));
    const limitedKeywords = maxKeywords ? keywords.slice(0, maxKeywords) : keywords;
    return new Set(limitedKeywords);
}

function asyncGeneratorStep$f(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$f(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$f(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$f(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
// Base Keyword Table Retriever
class BaseKeywordTableRetriever {
    retrieve(query) {
        var _this = this;
        return _async_to_generator$f(function*() {
            const keywords = yield _this.getKeywords(query);
            const chunkIndicesCount = {};
            const filteredKeywords = keywords.filter((keyword)=>_this.indexStruct.table.has(keyword));
            for (let keyword of filteredKeywords){
                for (let nodeId of _this.indexStruct.table.get(keyword) || []){
                    var _chunkIndicesCount_nodeId;
                    chunkIndicesCount[nodeId] = ((_chunkIndicesCount_nodeId = chunkIndicesCount[nodeId]) != null ? _chunkIndicesCount_nodeId : 0) + 1;
                }
            }
            const sortedChunkIndices = Object.keys(chunkIndicesCount).sort((a, b)=>chunkIndicesCount[b] - chunkIndicesCount[a]).slice(0, _this.numChunksPerQuery);
            const sortedNodes = yield _this.docstore.getNodes(sortedChunkIndices);
            return sortedNodes.map((node)=>({
                    node
                }));
        })();
    }
    getServiceContext() {
        return this.index.serviceContext;
    }
    constructor({ index, keywordExtractTemplate, queryKeywordExtractTemplate, maxKeywordsPerQuery = 10, numChunksPerQuery = 10 }){
        this.index = index;
        this.indexStruct = index.indexStruct;
        this.docstore = index.docStore;
        this.serviceContext = index.serviceContext;
        this.maxKeywordsPerQuery = maxKeywordsPerQuery;
        this.numChunksPerQuery = numChunksPerQuery;
        this.keywordExtractTemplate = keywordExtractTemplate || defaultKeywordExtractPrompt;
        this.queryKeywordExtractTemplate = queryKeywordExtractTemplate || defaultQueryKeywordExtractPrompt;
    }
}
// Extracts keywords using LLMs.
class KeywordTableLLMRetriever extends BaseKeywordTableRetriever {
    getKeywords(query) {
        var _this = this;
        return _async_to_generator$f(function*() {
            const response = yield _this.serviceContext.llm.complete({
                prompt: _this.queryKeywordExtractTemplate({
                    question: query,
                    maxKeywords: _this.maxKeywordsPerQuery
                })
            });
            const keywords = extractKeywordsGivenResponse(response.text, "KEYWORDS:");
            return [
                ...keywords
            ];
        })();
    }
}
// Extracts keywords using simple regex-based keyword extractor.
class KeywordTableSimpleRetriever extends BaseKeywordTableRetriever {
    getKeywords(query) {
        return Promise.resolve([
            ...simpleExtractKeywords(query, this.maxKeywordsPerQuery)
        ]);
    }
}
// Extracts keywords using RAKE keyword extractor
class KeywordTableRAKERetriever extends BaseKeywordTableRetriever {
    getKeywords(query) {
        return Promise.resolve([
            ...rakeExtractKeywords(query, this.maxKeywordsPerQuery)
        ]);
    }
}

function asyncGeneratorStep$e(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$e(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$e(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$e(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _extends$1() {
    _extends$1 = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends$1.apply(this, arguments);
}
function _object_without_properties_loose(source, excluded) {
    if (source == null) return {};
    var target = {};
    var sourceKeys = Object.keys(source);
    var key, i;
    for(i = 0; i < sourceKeys.length; i++){
        key = sourceKeys[i];
        if (excluded.indexOf(key) >= 0) continue;
        target[key] = source[key];
    }
    return target;
}
exports.KeywordTableRetrieverMode = void 0;
(function(KeywordTableRetrieverMode) {
    KeywordTableRetrieverMode["DEFAULT"] = "DEFAULT";
    KeywordTableRetrieverMode["SIMPLE"] = "SIMPLE";
    KeywordTableRetrieverMode["RAKE"] = "RAKE";
})(exports.KeywordTableRetrieverMode || (exports.KeywordTableRetrieverMode = {}));
const KeywordTableRetrieverMap = {
    ["DEFAULT"]: KeywordTableLLMRetriever,
    ["SIMPLE"]: KeywordTableSimpleRetriever,
    ["RAKE"]: KeywordTableRAKERetriever
};
/**
 * The KeywordTableIndex, an index that extracts keywords from each Node and builds a mapping from each keyword to the corresponding Nodes of that keyword.
 */ class KeywordTableIndex extends BaseIndex {
    static init(options) {
        return _async_to_generator$e(function*() {
            var _options_storageContext;
            const storageContext = (_options_storageContext = options.storageContext) != null ? _options_storageContext : yield storageContextFromDefaults({});
            var _options_serviceContext;
            const serviceContext = (_options_serviceContext = options.serviceContext) != null ? _options_serviceContext : serviceContextFromDefaults({});
            const { docStore, indexStore } = storageContext;
            // Setup IndexStruct from storage
            let indexStructs = yield indexStore.getIndexStructs();
            let indexStruct;
            if (options.indexStruct && indexStructs.length > 0) {
                throw new Error("Cannot initialize index with both indexStruct and indexStore");
            }
            if (options.indexStruct) {
                indexStruct = options.indexStruct;
            } else if (indexStructs.length == 1) {
                indexStruct = indexStructs[0];
            } else if (indexStructs.length > 1 && options.indexId) {
                indexStruct = yield indexStore.getIndexStruct(options.indexId);
            } else {
                indexStruct = null;
            }
            // check indexStruct type
            if (indexStruct && indexStruct.type !== exports.IndexStructType.KEYWORD_TABLE) {
                throw new Error("Attempting to initialize KeywordTableIndex with non-keyword table indexStruct");
            }
            if (indexStruct) {
                if (options.nodes) {
                    throw new Error("Cannot initialize KeywordTableIndex with both nodes and indexStruct");
                }
            } else {
                if (!options.nodes) {
                    throw new Error("Cannot initialize KeywordTableIndex without nodes or indexStruct");
                }
                indexStruct = yield KeywordTableIndex.buildIndexFromNodes(options.nodes, storageContext.docStore, serviceContext);
                yield indexStore.addIndexStruct(indexStruct);
            }
            return new KeywordTableIndex({
                storageContext,
                serviceContext,
                docStore,
                indexStore,
                indexStruct
            });
        })();
    }
    asRetriever(options) {
        const _ref = options != null ? options : {}, { mode = "DEFAULT" } = _ref, otherOptions = _object_without_properties_loose(_ref, [
            "mode"
        ]);
        const KeywordTableRetriever = KeywordTableRetrieverMap[mode];
        if (KeywordTableRetriever) {
            return new KeywordTableRetriever(_extends$1({
                index: this
            }, otherOptions));
        }
        throw new Error(`Unknown retriever mode: ${mode}`);
    }
    asQueryEngine(options) {
        const { retriever, responseSynthesizer } = options != null ? options : {};
        return new RetrieverQueryEngine(retriever != null ? retriever : this.asRetriever(), responseSynthesizer, options == null ? void 0 : options.preFilters, options == null ? void 0 : options.nodePostprocessors);
    }
    static extractKeywords(text, serviceContext) {
        return _async_to_generator$e(function*() {
            const response = yield serviceContext.llm.complete({
                prompt: defaultKeywordExtractPrompt({
                    context: text
                })
            });
            return extractKeywordsGivenResponse(response.text, "KEYWORDS:");
        })();
    }
    /**
   * High level API: split documents, get keywords, and build index.
   * @param documents
   * @param storageContext
   * @param serviceContext
   * @returns
   */ static fromDocuments(documents, args = {}) {
        return _async_to_generator$e(function*() {
            let { storageContext, serviceContext } = args;
            storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
            serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
            const docStore = storageContext.docStore;
            docStore.addDocuments(documents, true);
            for (const doc of documents){
                docStore.setDocumentHash(doc.id_, doc.hash);
            }
            const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
            const index = yield KeywordTableIndex.init({
                nodes,
                storageContext,
                serviceContext
            });
            return index;
        })();
    }
    /**
   * Get keywords for nodes and place them into the index.
   * @param nodes
   * @param serviceContext
   * @param vectorStore
   * @returns
   */ static buildIndexFromNodes(nodes, docStore, serviceContext) {
        return _async_to_generator$e(function*() {
            const indexStruct = new KeywordTable();
            yield docStore.addDocuments(nodes, true);
            for (const node of nodes){
                const keywords = yield KeywordTableIndex.extractKeywords(node.getContent(exports.MetadataMode.LLM), serviceContext);
                indexStruct.addNode([
                    ...keywords
                ], node.id_);
            }
            return indexStruct;
        })();
    }
    insertNodes(nodes) {
        var _this = this;
        return _async_to_generator$e(function*() {
            for (let node of nodes){
                const keywords = yield KeywordTableIndex.extractKeywords(node.getContent(exports.MetadataMode.LLM), _this.serviceContext);
                _this.indexStruct.addNode([
                    ...keywords
                ], node.id_);
            }
        })();
    }
    deleteNode(nodeId) {
        const keywordsToDelete = new Set();
        for (const [keyword, existingNodeIds] of Object.entries(this.indexStruct.table)){
            const index = existingNodeIds.indexOf(nodeId);
            if (index !== -1) {
                existingNodeIds.splice(index, 1);
                // Delete keywords that have zero nodes
                if (existingNodeIds.length === 0) {
                    keywordsToDelete.add(keyword);
                }
            }
        }
        this.indexStruct.deleteNode([
            ...keywordsToDelete
        ], nodeId);
    }
    deleteNodes(nodeIds, deleteFromDocStore) {
        var _this = this;
        return _async_to_generator$e(function*() {
            nodeIds.forEach((nodeId)=>{
                _this.deleteNode(nodeId);
            });
            if (deleteFromDocStore) {
                for (const nodeId of nodeIds){
                    yield _this.docStore.deleteDocument(nodeId, false);
                }
            }
            yield _this.storageContext.indexStore.addIndexStruct(_this.indexStruct);
        })();
    }
    deleteRefDoc(refDocId, deleteFromDocStore) {
        var _this = this;
        return _async_to_generator$e(function*() {
            const refDocInfo = yield _this.docStore.getRefDocInfo(refDocId);
            if (!refDocInfo) {
                return;
            }
            yield _this.deleteNodes(refDocInfo.nodeIds, false);
            if (deleteFromDocStore) {
                yield _this.docStore.deleteRefDoc(refDocId, false);
            }
            return;
        })();
    }
    constructor(init){
        super(init);
    }
}

const defaultFormatNodeBatchFn = (summaryNodes)=>{
    return summaryNodes.map((node, idx)=>{
        return `
Document ${idx + 1}:
${node.getContent(exports.MetadataMode.LLM)}
        `.trim();
    }).join("\n\n");
};
const defaultParseChoiceSelectAnswerFn = (answer, numChoices, raiseErr = false)=>{
    // split the line into the answer number and relevance score portions
    const lineTokens = answer.split("\n").map((line)=>{
        let lineTokens = line.split(",");
        if (lineTokens.length !== 2) {
            if (raiseErr) {
                throw new Error(`Invalid answer line: ${line}. Answer line must be of the form: answer_num: <int>, answer_relevance: <float>`);
            } else {
                return null;
            }
        }
        return lineTokens;
    }).filter((lineTokens)=>!___namespace.default.isNil(lineTokens));
    // parse the answer number and relevance score
    return lineTokens.reduce((parseResult, lineToken)=>{
        try {
            let docNum = parseInt(lineToken[0].split(":")[1].trim());
            let answerRelevance = parseFloat(lineToken[1].split(":")[1].trim());
            if (docNum < 1 || docNum > numChoices) {
                if (raiseErr) {
                    throw new Error(`Invalid answer number: ${docNum}. Answer number must be between 1 and ${numChoices}`);
                }
            } else {
                parseResult[docNum] = answerRelevance;
            }
        } catch (e) {
            if (raiseErr) {
                throw e;
            }
        }
        return parseResult;
    }, {});
};

function asyncGeneratorStep$d(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$d(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$d(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$d(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Simple retriever for SummaryIndex that returns all nodes
 */ class SummaryIndexRetriever {
    retrieve(query, parentEvent) {
        var _this = this;
        return _async_to_generator$d(function*() {
            const nodeIds = _this.index.indexStruct.nodes;
            const nodes = yield _this.index.docStore.getNodes(nodeIds);
            const result = nodes.map((node)=>({
                    node: node,
                    score: 1
                }));
            if (_this.index.serviceContext.callbackManager.onRetrieve) {
                _this.index.serviceContext.callbackManager.onRetrieve({
                    query,
                    nodes: result,
                    event: globalsHelper.createEvent({
                        parentEvent,
                        type: "retrieve"
                    })
                });
            }
            return result;
        })();
    }
    getServiceContext() {
        return this.index.serviceContext;
    }
    constructor(index){
        this.index = index;
    }
}
/**
 * LLM retriever for SummaryIndex which lets you select the most relevant chunks.
 */ class SummaryIndexLLMRetriever {
    retrieve(query, parentEvent) {
        var _this = this;
        return _async_to_generator$d(function*() {
            const nodeIds = _this.index.indexStruct.nodes;
            const results = [];
            for(let idx = 0; idx < nodeIds.length; idx += _this.choiceBatchSize){
                const nodeIdsBatch = nodeIds.slice(idx, idx + _this.choiceBatchSize);
                const nodesBatch = yield _this.index.docStore.getNodes(nodeIdsBatch);
                const fmtBatchStr = _this.formatNodeBatchFn(nodesBatch);
                const input = {
                    context: fmtBatchStr,
                    query: query
                };
                const rawResponse = (yield _this.serviceContext.llm.complete({
                    prompt: _this.choiceSelectPrompt(input)
                })).text;
                // parseResult is a map from doc number to relevance score
                const parseResult = _this.parseChoiceSelectAnswerFn(rawResponse, nodesBatch.length);
                const choiceNodeIds = nodeIdsBatch.filter((nodeId, idx)=>{
                    return `${idx}` in parseResult;
                });
                const choiceNodes = yield _this.index.docStore.getNodes(choiceNodeIds);
                const nodeWithScores = choiceNodes.map((node, i)=>({
                        node: node,
                        score: ___namespace.default.get(parseResult, `${i + 1}`, 1)
                    }));
                results.push(...nodeWithScores);
            }
            if (_this.serviceContext.callbackManager.onRetrieve) {
                _this.serviceContext.callbackManager.onRetrieve({
                    query,
                    nodes: results,
                    event: globalsHelper.createEvent({
                        parentEvent,
                        type: "retrieve"
                    })
                });
            }
            return results;
        })();
    }
    getServiceContext() {
        return this.serviceContext;
    }
    // eslint-disable-next-line max-params
    constructor(index, choiceSelectPrompt, choiceBatchSize = 10, formatNodeBatchFn, parseChoiceSelectAnswerFn, serviceContext){
        this.index = index;
        this.choiceSelectPrompt = choiceSelectPrompt || defaultChoiceSelectPrompt;
        this.choiceBatchSize = choiceBatchSize;
        this.formatNodeBatchFn = formatNodeBatchFn || defaultFormatNodeBatchFn;
        this.parseChoiceSelectAnswerFn = parseChoiceSelectAnswerFn || defaultParseChoiceSelectAnswerFn;
        this.serviceContext = serviceContext || index.serviceContext;
    }
}

function asyncGeneratorStep$c(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$c(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$c(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$c(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
exports.SummaryRetrieverMode = void 0;
(function(SummaryRetrieverMode) {
    SummaryRetrieverMode["DEFAULT"] = "default";
    // EMBEDDING = "embedding",
    SummaryRetrieverMode["LLM"] = "llm";
})(exports.SummaryRetrieverMode || (exports.SummaryRetrieverMode = {}));
/**
 * A SummaryIndex keeps nodes in a sequential order for use with summarization.
 */ class SummaryIndex extends BaseIndex {
    static init(options) {
        return _async_to_generator$c(function*() {
            var _options_storageContext;
            const storageContext = (_options_storageContext = options.storageContext) != null ? _options_storageContext : yield storageContextFromDefaults({});
            var _options_serviceContext;
            const serviceContext = (_options_serviceContext = options.serviceContext) != null ? _options_serviceContext : serviceContextFromDefaults({});
            const { docStore, indexStore } = storageContext;
            // Setup IndexStruct from storage
            let indexStructs = yield indexStore.getIndexStructs();
            let indexStruct;
            if (options.indexStruct && indexStructs.length > 0) {
                throw new Error("Cannot initialize index with both indexStruct and indexStore");
            }
            if (options.indexStruct) {
                indexStruct = options.indexStruct;
            } else if (indexStructs.length == 1) {
                indexStruct = indexStructs[0];
            } else if (indexStructs.length > 1 && options.indexId) {
                indexStruct = yield indexStore.getIndexStruct(options.indexId);
            } else {
                indexStruct = null;
            }
            // check indexStruct type
            if (indexStruct && indexStruct.type !== exports.IndexStructType.LIST) {
                throw new Error("Attempting to initialize SummaryIndex with non-list indexStruct");
            }
            if (indexStruct) {
                if (options.nodes) {
                    throw new Error("Cannot initialize SummaryIndex with both nodes and indexStruct");
                }
            } else {
                if (!options.nodes) {
                    throw new Error("Cannot initialize SummaryIndex without nodes or indexStruct");
                }
                indexStruct = yield SummaryIndex.buildIndexFromNodes(options.nodes, storageContext.docStore);
                yield indexStore.addIndexStruct(indexStruct);
            }
            return new SummaryIndex({
                storageContext,
                serviceContext,
                docStore,
                indexStore,
                indexStruct
            });
        })();
    }
    static fromDocuments(documents, args = {}) {
        return _async_to_generator$c(function*() {
            let { storageContext, serviceContext } = args;
            storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
            serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
            const docStore = storageContext.docStore;
            docStore.addDocuments(documents, true);
            for (const doc of documents){
                docStore.setDocumentHash(doc.id_, doc.hash);
            }
            const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
            const index = yield SummaryIndex.init({
                nodes,
                storageContext,
                serviceContext
            });
            return index;
        })();
    }
    asRetriever(options) {
        const { mode = "default" } = options != null ? options : {};
        switch(mode){
            case "default":
                return new SummaryIndexRetriever(this);
            case "llm":
                return new SummaryIndexLLMRetriever(this);
            default:
                throw new Error(`Unknown retriever mode: ${mode}`);
        }
    }
    asQueryEngine(options) {
        let { retriever, responseSynthesizer } = options != null ? options : {};
        if (!retriever) {
            retriever = this.asRetriever();
        }
        if (!responseSynthesizer) {
            let responseBuilder = new CompactAndRefine(this.serviceContext);
            responseSynthesizer = new ResponseSynthesizer({
                serviceContext: this.serviceContext,
                responseBuilder
            });
        }
        return new RetrieverQueryEngine(retriever, responseSynthesizer, options == null ? void 0 : options.preFilters, options == null ? void 0 : options.nodePostprocessors);
    }
    static buildIndexFromNodes(nodes, docStore, indexStruct) {
        return _async_to_generator$c(function*() {
            indexStruct = indexStruct || new IndexList();
            yield docStore.addDocuments(nodes, true);
            for (const node of nodes){
                indexStruct.addNode(node);
            }
            return indexStruct;
        })();
    }
    insertNodes(nodes) {
        var _this = this;
        return _async_to_generator$c(function*() {
            for (const node of nodes){
                _this.indexStruct.addNode(node);
            }
        })();
    }
    deleteRefDoc(refDocId, deleteFromDocStore) {
        var _this = this;
        return _async_to_generator$c(function*() {
            const refDocInfo = yield _this.docStore.getRefDocInfo(refDocId);
            if (!refDocInfo) {
                return;
            }
            yield _this.deleteNodes(refDocInfo.nodeIds, false);
            if (deleteFromDocStore) {
                yield _this.docStore.deleteRefDoc(refDocId, false);
            }
            return;
        })();
    }
    deleteNodes(nodeIds, deleteFromDocStore) {
        var _this = this;
        return _async_to_generator$c(function*() {
            _this.indexStruct.nodes = _this.indexStruct.nodes.filter((existingNodeId)=>!nodeIds.includes(existingNodeId));
            if (deleteFromDocStore) {
                for (const nodeId of nodeIds){
                    yield _this.docStore.deleteDocument(nodeId, false);
                }
            }
            yield _this.storageContext.indexStore.addIndexStruct(_this.indexStruct);
        })();
    }
    getRefDocInfo() {
        var _this = this;
        return _async_to_generator$c(function*() {
            const nodeDocIds = _this.indexStruct.nodes;
            const nodes = yield _this.docStore.getNodes(nodeDocIds);
            const refDocInfoMap = {};
            for (const node of nodes){
                const refNode = node.sourceNode;
                if (___namespace.default.isNil(refNode)) {
                    continue;
                }
                const refDocInfo = yield _this.docStore.getRefDocInfo(refNode.nodeId);
                if (___namespace.default.isNil(refDocInfo)) {
                    continue;
                }
                refDocInfoMap[refNode.nodeId] = refDocInfo;
            }
            return refDocInfoMap;
        })();
    }
    constructor(init){
        super(init);
    }
}

function asyncGeneratorStep$b(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$b(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$b(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$b(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * VectorIndexRetriever retrieves nodes from a VectorIndex.
 */ class VectorIndexRetriever {
    retrieve(query, parentEvent, preFilters) {
        var _this = this;
        return _async_to_generator$b(function*() {
            let nodesWithScores = yield _this.textRetrieve(query, preFilters);
            nodesWithScores = nodesWithScores.concat((yield _this.textToImageRetrieve(query, preFilters)));
            _this.sendEvent(query, nodesWithScores, parentEvent);
            return nodesWithScores;
        })();
    }
    textRetrieve(query, preFilters) {
        var _this = this;
        return _async_to_generator$b(function*() {
            const q = yield _this.buildVectorStoreQuery(_this.index.embedModel, query, _this.similarityTopK);
            const result = yield _this.index.vectorStore.query(q, preFilters);
            return _this.buildNodeListFromQueryResult(result);
        })();
    }
    textToImageRetrieve(query, preFilters) {
        var _this = this;
        return _async_to_generator$b(function*() {
            if (!_this.index.imageEmbedModel || !_this.index.imageVectorStore) {
                // no-op if image embedding and vector store are not set
                return [];
            }
            const q = yield _this.buildVectorStoreQuery(_this.index.imageEmbedModel, query, _this.imageSimilarityTopK);
            const result = yield _this.index.imageVectorStore.query(q, preFilters);
            return _this.buildNodeListFromQueryResult(result);
        })();
    }
    sendEvent(query, nodesWithScores, parentEvent) {
        if (this.serviceContext.callbackManager.onRetrieve) {
            this.serviceContext.callbackManager.onRetrieve({
                query,
                nodes: nodesWithScores,
                event: globalsHelper.createEvent({
                    parentEvent,
                    type: "retrieve"
                })
            });
        }
    }
    buildVectorStoreQuery(embedModel, query, similarityTopK) {
        return _async_to_generator$b(function*() {
            const queryEmbedding = yield embedModel.getQueryEmbedding(query);
            return {
                queryEmbedding: queryEmbedding,
                mode: exports.VectorStoreQueryMode.DEFAULT,
                similarityTopK: similarityTopK
            };
        })();
    }
    buildNodeListFromQueryResult(result) {
        let nodesWithScores = [];
        for(let i = 0; i < result.ids.length; i++){
            var _result_nodes;
            const nodeFromResult = (_result_nodes = result.nodes) == null ? void 0 : _result_nodes[i];
            if (!this.index.indexStruct.nodesDict[result.ids[i]] && nodeFromResult) {
                this.index.indexStruct.nodesDict[result.ids[i]] = nodeFromResult;
            }
            const node = this.index.indexStruct.nodesDict[result.ids[i]];
            // XXX: Hack, if it's an image node, we reconstruct the image from the URL
            // Alternative: Store image in doc store and retrieve it here
            if (node instanceof ImageNode) {
                node.image = node.getUrl();
            }
            nodesWithScores.push({
                node: node,
                score: result.similarities[i]
            });
        }
        return nodesWithScores;
    }
    getServiceContext() {
        return this.serviceContext;
    }
    constructor({ index, similarityTopK, imageSimilarityTopK }){
        this.index = index;
        this.serviceContext = this.index.serviceContext;
        this.similarityTopK = similarityTopK != null ? similarityTopK : DEFAULT_SIMILARITY_TOP_K;
        this.imageSimilarityTopK = imageSimilarityTopK != null ? imageSimilarityTopK : DEFAULT_SIMILARITY_TOP_K;
    }
}

function asyncGeneratorStep$a(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$a(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$a(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$a(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
function _extends() {
    _extends = Object.assign || function(target) {
        for(var i = 1; i < arguments.length; i++){
            var source = arguments[i];
            for(var key in source){
                if (Object.prototype.hasOwnProperty.call(source, key)) {
                    target[key] = source[key];
                }
            }
        }
        return target;
    };
    return _extends.apply(this, arguments);
}
/**
 * The VectorStoreIndex, an index that stores the nodes only according to their vector embedings.
 */ class VectorStoreIndex extends BaseIndex {
    /**
   * The async init function creates a new VectorStoreIndex.
   * @param options
   * @returns
   */ static init(options) {
        var _this = this;
        return _async_to_generator$a(function*() {
            var _options_storageContext;
            const storageContext = (_options_storageContext = options.storageContext) != null ? _options_storageContext : yield storageContextFromDefaults({});
            var _options_serviceContext;
            const serviceContext = (_options_serviceContext = options.serviceContext) != null ? _options_serviceContext : serviceContextFromDefaults({});
            const indexStore = storageContext.indexStore;
            const docStore = storageContext.docStore;
            let indexStruct = yield VectorStoreIndex.setupIndexStructFromStorage(indexStore, options);
            if (!options.nodes && !indexStruct) {
                throw new Error("Cannot initialize VectorStoreIndex without nodes or indexStruct");
            }
            indexStruct = indexStruct != null ? indexStruct : new IndexDict();
            const index = new _this({
                storageContext,
                serviceContext,
                docStore,
                indexStruct,
                indexStore,
                vectorStore: options.vectorStore,
                imageVectorStore: options.imageVectorStore
            });
            if (options.nodes) {
                // If nodes are passed in, then we need to update the index
                yield index.buildIndexFromNodes(options.nodes, {
                    logProgress: options.logProgress
                });
            }
            return index;
        })();
    }
    static setupIndexStructFromStorage(indexStore, options) {
        return _async_to_generator$a(function*() {
            let indexStructs = yield indexStore.getIndexStructs();
            let indexStruct;
            if (options.indexStruct && indexStructs.length > 0) {
                throw new Error("Cannot initialize index with both indexStruct and indexStore");
            }
            if (options.indexStruct) {
                indexStruct = options.indexStruct;
            } else if (indexStructs.length == 1) {
                indexStruct = indexStructs[0];
            } else if (indexStructs.length > 1 && options.indexId) {
                indexStruct = yield indexStore.getIndexStruct(options.indexId);
            }
            // Check indexStruct type
            if (indexStruct && indexStruct.type !== exports.IndexStructType.SIMPLE_DICT) {
                throw new Error("Attempting to initialize VectorStoreIndex with non-vector indexStruct");
            }
            return indexStruct;
        })();
    }
    /**
   * Calculates the embeddings for the given nodes.
   *
   * @param nodes - An array of BaseNode objects representing the nodes for which embeddings are to be calculated.
   * @param {Object} [options] - An optional object containing additional parameters.
   *   @param {boolean} [options.logProgress] - A boolean indicating whether to log progress to the console (useful for debugging).
   */ getNodeEmbeddingResults(nodes, options) {
        var _this = this;
        return _async_to_generator$a(function*() {
            const nodesWithEmbeddings = [];
            for(let i = 0; i < nodes.length; ++i){
                const node = nodes[i];
                if (options == null ? void 0 : options.logProgress) {
                    console.log(`Getting embedding for node ${i + 1}/${nodes.length}`);
                }
                node.embedding = yield _this.embedModel.getTextEmbedding(node.getContent(exports.MetadataMode.EMBED));
                nodesWithEmbeddings.push(node);
            }
            return nodesWithEmbeddings;
        })();
    }
    /**
   * Get embeddings for nodes and place them into the index.
   * @param nodes
   * @returns
   */ buildIndexFromNodes(nodes, options) {
        var _this = this;
        return _async_to_generator$a(function*() {
            // Check if the index already has nodes with the same hash
            const newNodes = nodes.filter((node)=>Object.entries(_this.indexStruct.nodesDict).reduce((acc, [key, value])=>{
                    if (value.hash === node.hash) {
                        acc = false;
                    }
                    return acc;
                }, true));
            yield _this.insertNodes(newNodes, options);
        })();
    }
    /**
   * High level API: split documents, get embeddings, and build index.
   * @param documents
   * @param args
   * @returns
   */ static fromDocuments(documents, args = {}) {
        var _this = this;
        return _async_to_generator$a(function*() {
            var _args_storageContext;
            args.storageContext = (_args_storageContext = args.storageContext) != null ? _args_storageContext : yield storageContextFromDefaults({});
            var _args_serviceContext;
            args.serviceContext = (_args_serviceContext = args.serviceContext) != null ? _args_serviceContext : serviceContextFromDefaults({});
            const docStore = args.storageContext.docStore;
            for (const doc of documents){
                docStore.setDocumentHash(doc.id_, doc.hash);
            }
            if (args.logProgress) {
                console.log("Using node parser on documents...");
            }
            args.nodes = args.serviceContext.nodeParser.getNodesFromDocuments(documents);
            if (args.logProgress) {
                console.log("Finished parsing documents.");
            }
            return yield _this.init(args);
        })();
    }
    static fromVectorStore(vectorStore, serviceContext, imageVectorStore) {
        var _this = this;
        return _async_to_generator$a(function*() {
            if (!vectorStore.storesText) {
                throw new Error("Cannot initialize from a vector store that does not store text");
            }
            const storageContext = yield storageContextFromDefaults({
                vectorStore,
                imageVectorStore
            });
            const index = yield _this.init({
                nodes: [],
                storageContext,
                serviceContext
            });
            return index;
        })();
    }
    asRetriever(options) {
        return new VectorIndexRetriever(_extends({
            index: this
        }, options));
    }
    asQueryEngine(options) {
        const { retriever, responseSynthesizer } = options != null ? options : {};
        return new RetrieverQueryEngine(retriever != null ? retriever : this.asRetriever(), responseSynthesizer, options == null ? void 0 : options.preFilters, options == null ? void 0 : options.nodePostprocessors);
    }
    insertNodesToStore(vectorStore, nodes) {
        var _this = this;
        return _async_to_generator$a(function*() {
            const newIds = yield vectorStore.add(nodes);
            // NOTE: if the vector store doesn't store text,
            // we need to add the nodes to the index struct and document store
            // NOTE: if the vector store keeps text,
            // we only need to add image and index nodes
            for(let i = 0; i < nodes.length; ++i){
                const type = nodes[i].getType();
                if (!vectorStore.storesText || type === exports.ObjectType.INDEX || type === exports.ObjectType.IMAGE) {
                    const nodeWithoutEmbedding = nodes[i].clone();
                    nodeWithoutEmbedding.embedding = undefined;
                    _this.indexStruct.addNode(nodeWithoutEmbedding, newIds[i]);
                    yield _this.docStore.addDocuments([
                        nodeWithoutEmbedding
                    ], true);
                }
            }
        })();
    }
    insertNodes(nodes, options) {
        var _this = this;
        return _async_to_generator$a(function*() {
            if (!nodes || nodes.length === 0) {
                return;
            }
            const { imageNodes, textNodes } = splitNodesByType(nodes);
            if (imageNodes.length > 0) {
                if (!_this.imageVectorStore) {
                    throw new Error("Cannot insert image nodes without image vector store");
                }
                const imageNodesWithEmbedding = yield _this.getImageNodeEmbeddingResults(imageNodes, options);
                yield _this.insertNodesToStore(_this.imageVectorStore, imageNodesWithEmbedding);
            }
            const embeddingResults = yield _this.getNodeEmbeddingResults(textNodes, options);
            yield _this.insertNodesToStore(_this.vectorStore, embeddingResults);
            yield _this.indexStore.addIndexStruct(_this.indexStruct);
        })();
    }
    deleteRefDoc(refDocId, deleteFromDocStore = true) {
        var _this = this;
        return _async_to_generator$a(function*() {
            yield _this.deleteRefDocFromStore(_this.vectorStore, refDocId);
            if (_this.imageVectorStore) {
                yield _this.deleteRefDocFromStore(_this.imageVectorStore, refDocId);
            }
            if (deleteFromDocStore) {
                yield _this.docStore.deleteDocument(refDocId, false);
            }
        })();
    }
    deleteRefDocFromStore(vectorStore, refDocId) {
        var _this = this;
        return _async_to_generator$a(function*() {
            vectorStore.delete(refDocId);
            if (!vectorStore.storesText) {
                const refDocInfo = yield _this.docStore.getRefDocInfo(refDocId);
                if (refDocInfo) {
                    for (const nodeId of refDocInfo.nodeIds){
                        _this.indexStruct.delete(nodeId);
                        vectorStore.delete(nodeId);
                    }
                }
                yield _this.indexStore.addIndexStruct(_this.indexStruct);
            }
        })();
    }
    /**
   * Calculates the embeddings for the given image nodes.
   *
   * @param nodes - An array of ImageNode objects representing the nodes for which embeddings are to be calculated.
   * @param {Object} [options] - An optional object containing additional parameters.
   *   @param {boolean} [options.logProgress] - A boolean indicating whether to log progress to the console (useful for debugging).
   */ getImageNodeEmbeddingResults(nodes, options) {
        var _this = this;
        return _async_to_generator$a(function*() {
            if (!_this.imageEmbedModel) {
                return [];
            }
            const nodesWithEmbeddings = [];
            for(let i = 0; i < nodes.length; ++i){
                const node = nodes[i];
                if (options == null ? void 0 : options.logProgress) {
                    console.log(`Getting embedding for node ${i + 1}/${nodes.length}`);
                }
                node.embedding = yield _this.imageEmbedModel.getImageEmbedding(node.image);
                nodesWithEmbeddings.push(node);
            }
            return nodesWithEmbeddings;
        })();
    }
    constructor(init){
        super(init);
        this.indexStore = init.indexStore;
        var _init_vectorStore;
        this.vectorStore = (_init_vectorStore = init.vectorStore) != null ? _init_vectorStore : init.storageContext.vectorStore;
        this.embedModel = init.serviceContext.embedModel;
        var _init_imageVectorStore;
        this.imageVectorStore = (_init_imageVectorStore = init.imageVectorStore) != null ? _init_imageVectorStore : init.storageContext.imageVectorStore;
        if (this.imageVectorStore) {
            this.imageEmbedModel = new ClipEmbedding();
        }
    }
}

class MetadataReplacementPostProcessor {
    postprocessNodes(nodes) {
        for (let n of nodes){
            var _n_node_metadata_this_targetMetadataKey;
            n.node.setContent((_n_node_metadata_this_targetMetadataKey = n.node.metadata[this.targetMetadataKey]) != null ? _n_node_metadata_this_targetMetadataKey : n.node.getContent(exports.MetadataMode.NONE));
        }
        return nodes;
    }
    constructor(targetMetadataKey){
        this.targetMetadataKey = targetMetadataKey;
    }
}

class SimilarityPostprocessor {
    postprocessNodes(nodes) {
        if (this.similarityCutoff === undefined) return nodes;
        const cutoff = this.similarityCutoff || 0;
        return nodes.filter((node)=>node.score && node.score >= cutoff);
    }
    constructor(options){
        this.similarityCutoff = options == null ? void 0 : options.similarityCutoff;
    }
}

function asyncGeneratorStep$9(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$9(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$9(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$9(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Base class for AssemblyAI Readers.
 */ class AssemblyAIReader {
    transcribeOrGetTranscript(params) {
        var _this = this;
        return _async_to_generator$9(function*() {
            if (typeof params === "string") {
                return yield _this.client.transcripts.get(params);
            } else {
                return yield _this.client.transcripts.transcribe(params);
            }
        })();
    }
    getTranscriptId(params) {
        var _this = this;
        return _async_to_generator$9(function*() {
            if (typeof params === "string") {
                return params;
            } else {
                return (yield _this.client.transcripts.transcribe(params)).id;
            }
        })();
    }
    /**
   * Creates a new AssemblyAI Reader.
   * @param assemblyAIOptions The options to configure the AssemblyAI Reader.
   * Configure the `assemblyAIOptions.apiKey` with your AssemblyAI API key, or configure it as the `ASSEMBLYAI_API_KEY` environment variable.
   */ constructor(assemblyAIOptions){
        let options = assemblyAIOptions;
        if (!options) {
            options = {};
        }
        if (!options.apiKey) {
            options.apiKey = process.env.ASSEMBLYAI_API_KEY;
        }
        if (!options.apiKey) {
            throw new Error("No AssemblyAI API key provided. Pass an `apiKey` option, or configure the `ASSEMBLYAI_API_KEY` environment variable.");
        }
        this.client = new assemblyai.AssemblyAI(options);
    }
}
/**
 * Transcribe audio and read the transcript as a document using AssemblyAI.
 */ class AudioTranscriptReader extends AssemblyAIReader {
    /**
   * Transcribe audio or get a transcript and load the transcript as a document using AssemblyAI.
   * @param params Parameters to transcribe an audio file or get an existing transcript.
   * @returns A promise that resolves to a single document containing the transcript text.
   */ loadData(params) {
        var _this = this;
        return _async_to_generator$9(function*() {
            const transcript = yield _this.transcribeOrGetTranscript(params);
            return [
                new Document({
                    text: transcript.text || undefined
                })
            ];
        })();
    }
}
/**
 * Transcribe audio and return a document for each paragraph.
 */ class AudioTranscriptParagraphsReader extends AssemblyAIReader {
    /**
   * Transcribe audio or get a transcript, and returns a document for each paragraph.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @returns A promise that resolves to an array of documents, each containing a paragraph of the transcript.
   */ loadData(params) {
        var _this = this;
        return _async_to_generator$9(function*() {
            let transcriptId = yield _this.getTranscriptId(params);
            const paragraphsResponse = yield _this.client.transcripts.paragraphs(transcriptId);
            return paragraphsResponse.paragraphs.map((p)=>new Document({
                    text: p.text
                }));
        })();
    }
}
/**
 * Transcribe audio and return a document for each sentence.
 */ class AudioTranscriptSentencesReader extends AssemblyAIReader {
    /**
   * Transcribe audio or get a transcript, and returns a document for each sentence.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @returns A promise that resolves to an array of documents, each containing a sentence of the transcript.
   */ loadData(params) {
        var _this = this;
        return _async_to_generator$9(function*() {
            let transcriptId = yield _this.getTranscriptId(params);
            const sentencesResponse = yield _this.client.transcripts.sentences(transcriptId);
            return sentencesResponse.sentences.map((p)=>new Document({
                    text: p.text
                }));
        })();
    }
}
/**
 * Transcribe audio a transcript and read subtitles for the transcript as `srt` or `vtt` format.
 */ class AudioSubtitlesReader extends AssemblyAIReader {
    /**
   * Transcribe audio or get a transcript and reads subtitles for the transcript as `srt` or `vtt` format.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @param subtitleFormat The format of the subtitles, either `srt` or `vtt`.
   * @returns A promise that resolves a document containing the subtitles as the page content.
   */ loadData(params, subtitleFormat = "srt") {
        var _this = this;
        return _async_to_generator$9(function*() {
            let transcriptId = yield _this.getTranscriptId(params);
            const subtitles = yield _this.client.transcripts.subtitles(transcriptId, subtitleFormat);
            return [
                new Document({
                    text: subtitles
                })
            ];
        })();
    }
}

function asyncGeneratorStep$8(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$8(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$8(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$8(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * papaparse-based csv parser
 * @class CSVReader
 * @implements BaseReader
 */ class PapaCSVReader {
    /**
   * Loads data from csv files
   * @param {string} file - The path to the file to load.
   * @param {GenericFileSystem} [fs=DEFAULT_FS] - The file system to use for reading the file.
   * @returns {Promise<Document[]>}
   */ loadData(file, fs = DEFAULT_FS) {
        var _this = this;
        return _async_to_generator$8(function*() {
            const fileContent = yield fs.readFile(file, "utf-8");
            const result = Papa__default.default.parse(fileContent, _this.papaConfig);
            const textList = result.data.map((row)=>{
                // Compatible with header row mode
                const rowValues = Object.values(row).map((value)=>String(value));
                return rowValues.join(_this.colJoiner);
            });
            if (_this.concatRows) {
                return [
                    new Document({
                        text: textList.join(_this.rowJoiner)
                    })
                ];
            } else {
                return textList.map((text)=>new Document({
                        text
                    }));
            }
        })();
    }
    /**
   * Constructs a new instance of the class.
   * @param {boolean} [concatRows=true] - whether to concatenate all rows into one document.If set to False, a Document will be created for each row.True by default.
   * @param {string} [colJoiner=', '] - Separator to use for joining cols per row. Set to ", " by default.
   * @param {string} [rowJoiner='\n'] - Separator to use for joining each row.Only used when `concat_rows=True`.Set to "\n" by default.
   */ constructor(concatRows = true, colJoiner = ", ", rowJoiner = "\n", papaConfig){
        this.concatRows = concatRows;
        this.colJoiner = colJoiner;
        this.rowJoiner = rowJoiner;
        this.papaConfig = papaConfig;
    }
}

function asyncGeneratorStep$7(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$7(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$7(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$7(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
class DocxReader {
    /** DocxParser */ loadData(file, fs = DEFAULT_FS) {
        return _async_to_generator$7(function*() {
            const dataBuffer = yield fs.readFile(file);
            const { value } = yield mammoth__default.default.extractRawText({
                buffer: dataBuffer
            });
            return [
                new Document({
                    text: value,
                    id_: file
                })
            ];
        })();
    }
}

function asyncGeneratorStep$6(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$6(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$6(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$6(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Extract the significant text from an arbitrary HTML document.
 * The contents of any head, script, style, and xml tags are removed completely.
 * The URLs for a[href] tags are extracted, along with the inner text of the tag.
 * All other tags are removed, and the inner text is kept intact.
 * Html entities (e.g., &amp;) are not decoded.
 */ class HTMLReader {
    /**
   * Public method for this reader.
   * Required by BaseReader interface.
   * @param file Path/name of the file to be loaded.
   * @param fs fs wrapper interface for getting the file content.
   * @returns Promise<Document[]> A Promise object, eventually yielding zero or one Document parsed from the HTML content of the specified file.
   */ loadData(file, fs = DEFAULT_FS) {
        var _this = this;
        return _async_to_generator$6(function*() {
            const dataBuffer = yield fs.readFile(file, "utf-8");
            const htmlOptions = _this.getOptions();
            const content = yield _this.parseContent(dataBuffer, htmlOptions);
            return [
                new Document({
                    text: content,
                    id_: file
                })
            ];
        })();
    }
    /**
   * Wrapper for string-strip-html usage.
   * @param html Raw HTML content to be parsed.
   * @param options An object of options for the underlying library
   * @see getOptions
   * @returns The HTML content, stripped of unwanted tags and attributes
   */ parseContent(html, options = {}) {
        return _async_to_generator$6(function*() {
            const { stripHtml } = yield import('string-strip-html'); // ESM only
            return stripHtml(html).result;
        })();
    }
    /**
   * Wrapper for our configuration options passed to string-strip-html library
   * @see https://codsen.com/os/string-strip-html/examples
   * @returns An object of options for the underlying library
   */ getOptions() {
        return {
            skipHtmlDecoding: true,
            stripTogetherWithTheirContents: [
                "script",
                "style",
                "xml",
                "head"
            ]
        };
    }
}

function asyncGeneratorStep$5(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$5(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$5(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$5(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Extract text from markdown files.
 * Returns dictionary with keys as headers and values as the text between headers.
 */ class MarkdownReader {
    /**
   * Convert a markdown file to a dictionary.
   * The keys are the headers and the values are the text under each header.
   * @param {string} markdownText - The markdown text to convert.
   * @returns {Array<MarkdownTuple>} - An array of tuples, where each tuple contains a header (or null) and its corresponding text.
   */ markdownToTups(markdownText) {
        const markdownTups = [];
        const lines = markdownText.split("\n");
        let currentHeader = null;
        let currentText = "";
        for (const line of lines){
            const headerMatch = line.match(/^#+\s/);
            if (headerMatch) {
                if (currentHeader) {
                    if (!currentText) {
                        currentHeader += line + "\n";
                        continue;
                    }
                    markdownTups.push([
                        currentHeader,
                        currentText
                    ]);
                }
                currentHeader = line;
                currentText = "";
            } else {
                currentText += line + "\n";
            }
        }
        markdownTups.push([
            currentHeader,
            currentText
        ]);
        if (currentHeader) {
            // pass linting, assert keys are defined
            markdownTups.map((tuple)=>{
                var _tuple_;
                return [
                    ((_tuple_ = tuple[0]) == null ? void 0 : _tuple_.replace(/#/g, "").trim()) || null,
                    tuple[1].replace(/<.*?>/g, "")
                ];
            });
        } else {
            markdownTups.map((tuple)=>[
                    tuple[0],
                    tuple[1].replace(/<.*?>/g, "")
                ]);
        }
        return markdownTups;
    }
    removeImages(content) {
        const pattern = /!{1}\[\[(.*)\]\]/g;
        return content.replace(pattern, "");
    }
    removeHyperlinks(content) {
        const pattern = /\[(.*?)\]\((.*?)\)/g;
        return content.replace(pattern, "$1");
    }
    parseTups(content) {
        let modifiedContent = content;
        if (this._removeHyperlinks) {
            modifiedContent = this.removeHyperlinks(modifiedContent);
        }
        if (this._removeImages) {
            modifiedContent = this.removeImages(modifiedContent);
        }
        return this.markdownToTups(modifiedContent);
    }
    loadData(file, fs = DEFAULT_FS) {
        var _this = this;
        return _async_to_generator$5(function*() {
            const content = yield fs.readFile(file, {
                encoding: "utf-8"
            });
            const tups = _this.parseTups(content);
            const results = [];
            for (const [header, value] of tups){
                if (header) {
                    results.push(new Document({
                        text: `\n\n${header}\n${value}`
                    }));
                } else {
                    results.push(new Document({
                        text: value
                    }));
                }
            }
            return results;
        })();
    }
    /**
   * @param {boolean} [removeHyperlinks=true] - Indicates whether hyperlinks should be removed.
   * @param {boolean} [removeImages=true] - Indicates whether images should be removed.
   */ constructor(removeHyperlinks = true, removeImages = true){
        this._removeHyperlinks = removeHyperlinks;
        this._removeImages = removeImages;
    }
}

function asyncGeneratorStep$4(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$4(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$4(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$4(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Notion pages are retrieved recursively and converted to Document objects.
 * Notion Database can also be loaded, and [the serialization method can be customized](https://github.com/TomPenguin/notion-md-crawler/tree/main).
 *
 * [Note] To use this reader, must be created the Notion integration must be created in advance
 * Please refer to [this document](https://www.notion.so/help/create-integrations-with-the-notion-api) for details.
 */ class NotionReader {
    /**
   * Converts Pages to an array of Document objects
   * @param {Pages} pages - The Notion pages to convert (Return value of `loadPages`)
   * @returns {Document[]} An array of Document objects
   */ toDocuments(pages) {
        return Object.values(pages).map((page)=>{
            const text = notionMdCrawler.pageToString(page);
            return new Document({
                text,
                metadata: page.metadata
            });
        });
    }
    /**
   * Loads recursively the Notion page with the specified root page ID.
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Pages>} A Promise that resolves to a Pages object(Convertible with the `toDocuments` method)
   */ loadPages(rootPageId) {
        var _this = this;
        return _async_to_generator$4(function*() {
            return _this.crawl(rootPageId);
        })();
    }
    /**
   * Loads recursively Notion pages and converts them to an array of Document objects
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Document[]>} A Promise that resolves to an array of Document objects
   */ loadData(rootPageId) {
        var _this = this;
        return _async_to_generator$4(function*() {
            const pages = yield _this.loadPages(rootPageId);
            return _this.toDocuments(pages);
        })();
    }
    /**
   * Constructor for the NotionReader class
   * @param {NotionReaderOptions} options - Configuration options for the reader
   */ constructor({ client, serializers }){
        this.crawl = notionMdCrawler.crawler({
            client,
            serializers
        });
    }
}

function asyncGeneratorStep$3(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$3(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$3(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$3(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Read the text of a PDF
 */ class PDFReader {
    loadData(file, fs = DEFAULT_FS) {
        return _async_to_generator$3(function*() {
            const content = yield fs.readFile(file);
            if (!(content instanceof Buffer)) {
                console.warn(`PDF File ${file} can only be loaded using the Node FS`);
                return [];
            }
            const data = new Uint8Array(content.buffer, content.byteOffset, content.byteLength);
            const pdf = yield readPDF(data);
            return [
                new Document({
                    text: pdf.text,
                    id_: file
                })
            ];
        })();
    }
}
function readPage(pageData) {
    return _readPage.apply(this, arguments);
}
function _readPage() {
    _readPage = // NOTE: the following code is taken from https://www.npmjs.com/package/pdf-parse and modified
    _async_to_generator$3(function*(pageData) {
        //check documents https://mozilla.github.io/pdf.js/
        const textContent = yield pageData.getTextContent({
            includeMarkedContent: false
        });
        let lastY = null, text = "";
        //https://github.com/mozilla/pdf.js/issues/8963
        //https://github.com/mozilla/pdf.js/issues/2140
        //https://gist.github.com/hubgit/600ec0c224481e910d2a0f883a7b98e3
        //https://gist.github.com/hubgit/600ec0c224481e910d2a0f883a7b98e3
        for (const item of textContent.items){
            if (lastY == item.transform[5] || !lastY) {
                text += item.str;
            } else {
                text += "\n" + item.str;
            }
            lastY = item.transform[5];
        }
        return text;
    });
    return _readPage.apply(this, arguments);
}
const PDF_DEFAULT_OPTIONS = {
    max: 0
};
function readPDF(data) {
    return _readPDF.apply(this, arguments);
}
function _readPDF() {
    _readPDF = _async_to_generator$3(function*(data, options = PDF_DEFAULT_OPTIONS) {
        const { getDocument, version } = yield import('pdfjs-dist');
        const doc = yield getDocument({
            data
        }).promise;
        const metaData = yield doc.getMetadata().catch(()=>null);
        const counter = options.max === 0 ? doc.numPages : Math.max(options.max, doc.numPages);
        let text = "";
        for(let i = 1; i <= counter; i++){
            try {
                const pageData = yield doc.getPage(i);
                const pageText = yield readPage(pageData);
                text += `\n\n${pageText}`;
            } catch (err) {
                console.log(err);
            }
        }
        yield doc.destroy();
        return {
            numpages: doc.numPages,
            numrender: counter,
            info: metaData == null ? void 0 : metaData.info,
            metadata: metaData == null ? void 0 : metaData.metadata,
            text,
            version
        };
    });
    return _readPDF.apply(this, arguments);
}

function asyncGeneratorStep$2(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$2(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$2(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$2(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Reads the content of an image file into a Document object (which stores the image file as a Blob).
 */ class ImageReader {
    /**
   * Public method for this reader.
   * Required by BaseReader interface.
   * @param file Path/name of the file to be loaded.
   * @param fs fs wrapper interface for getting the file content.
   * @returns Promise<Document[]> A Promise object, eventually yielding zero or one ImageDocument of the specified file.
   */ loadData(file, fs = DEFAULT_FS) {
        return _async_to_generator$2(function*() {
            const dataBuffer = yield fs.readFile(file);
            const blob = new Blob([
                dataBuffer
            ]);
            return [
                new ImageDocument({
                    image: blob,
                    id_: file
                })
            ];
        })();
    }
}

function _async_iterator$1(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator$1(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator$1(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator$1 = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator$1.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator$1(s);
}
function asyncGeneratorStep$1(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator$1(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep$1(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep$1(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
var ReaderStatus;
(function(ReaderStatus) {
    ReaderStatus[ReaderStatus["STARTED"] = 0] = "STARTED";
    ReaderStatus[ReaderStatus["COMPLETE"] = 1] = "COMPLETE";
    ReaderStatus[ReaderStatus["ERROR"] = 2] = "ERROR";
})(ReaderStatus || (ReaderStatus = {}));
/**
 * Read a .txt file
 */ class TextFileReader {
    loadData(file, fs = DEFAULT_FS) {
        return _async_to_generator$1(function*() {
            const dataBuffer = yield fs.readFile(file, "utf-8");
            return [
                new Document({
                    text: dataBuffer,
                    id_: file
                })
            ];
        })();
    }
}
const FILE_EXT_TO_READER = {
    txt: new TextFileReader(),
    pdf: new PDFReader(),
    csv: new PapaCSVReader(),
    md: new MarkdownReader(),
    docx: new DocxReader(),
    htm: new HTMLReader(),
    html: new HTMLReader(),
    jpg: new ImageReader(),
    jpeg: new ImageReader(),
    png: new ImageReader(),
    gif: new ImageReader()
};
/**
 * Read all of the documents in a directory.
 * By default, supports the list of file types
 * in the FILE_EXT_TO_READER map.
 */ class SimpleDirectoryReader {
    loadData({ directoryPath, fs = DEFAULT_FS, defaultReader = new TextFileReader(), fileExtToReader = FILE_EXT_TO_READER }) {
        var _this = this;
        return _async_to_generator$1(function*() {
            // Observer can decide to skip the directory
            if (!_this.doObserverCheck("directory", directoryPath, 0)) {
                return [];
            }
            let docs = [];
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator$1(walk(fs, directoryPath)), _step; _iteratorAbruptCompletion = !(_step = yield _iterator.next()).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const filePath = _value;
                        try {
                            const fileExt = ___namespace.default.last(filePath.split(".")) || "";
                            // Observer can decide to skip each file
                            if (!_this.doObserverCheck("file", filePath, 0)) {
                                continue;
                            }
                            let reader = null;
                            if (fileExt in fileExtToReader) {
                                reader = fileExtToReader[fileExt];
                            } else if (!___namespace.default.isNil(defaultReader)) {
                                reader = defaultReader;
                            } else {
                                const msg = `No reader for file extension of ${filePath}`;
                                console.warn(msg);
                                // In an error condition, observer's false cancels the whole process.
                                if (!_this.doObserverCheck("file", filePath, 2, msg)) {
                                    return [];
                                }
                                continue;
                            }
                            const fileDocs = yield reader.loadData(filePath, fs);
                            // Observer can still cancel addition of the resulting docs from this file
                            if (_this.doObserverCheck("file", filePath, 1)) {
                                docs.push(...fileDocs);
                            }
                        } catch (e) {
                            const msg = `Error reading file ${filePath}: ${e}`;
                            console.error(msg);
                            // In an error condition, observer's false cancels the whole process.
                            if (!_this.doObserverCheck("file", filePath, 2, msg)) {
                                return [];
                            }
                        }
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            // After successful import of all files, directory completion
            // is only a notification for observer, cannot be cancelled.
            _this.doObserverCheck("directory", directoryPath, 1);
            return docs;
        })();
    }
    doObserverCheck(category, name, status, message) {
        if (this.observer) {
            return this.observer(category, name, status, message);
        }
        return true;
    }
    constructor(observer){
        this.observer = observer;
    }
}

function _async_iterator(iterable) {
    var method, async, sync, retry = 2;
    for("undefined" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;){
        if (async && null != (method = iterable[async])) return method.call(iterable);
        if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator(method.call(iterable));
        async = "@@asyncIterator", sync = "@@iterator";
    }
    throw new TypeError("Object is not async iterable");
}
function AsyncFromSyncIterator(s) {
    function AsyncFromSyncIteratorContinuation(r) {
        if (Object(r) !== r) return Promise.reject(new TypeError(r + " is not an object."));
        var done = r.done;
        return Promise.resolve(r.value).then(function(value) {
            return {
                value: value,
                done: done
            };
        });
    }
    return AsyncFromSyncIterator = function(s) {
        this.s = s, this.n = s.next;
    }, AsyncFromSyncIterator.prototype = {
        s: null,
        n: null,
        next: function() {
            return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));
        },
        return: function(value) {
            var ret = this.s.return;
            return void 0 === ret ? Promise.resolve({
                value: value,
                done: !0
            }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments));
        },
        throw: function(value) {
            var thr = this.s.return;
            return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments));
        }
    }, new AsyncFromSyncIterator(s);
}
function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {
    try {
        var info = gen[key](arg);
        var value = info.value;
    } catch (error) {
        reject(error);
        return;
    }
    if (info.done) {
        resolve(value);
    } else {
        Promise.resolve(value).then(_next, _throw);
    }
}
function _async_to_generator(fn) {
    return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
            var gen = fn.apply(self, args);
            function _next(value) {
                asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value);
            }
            function _throw(err) {
                asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err);
            }
            _next(undefined);
        });
    };
}
/**
 * Read in from MongoDB
 */ class SimpleMongoReader {
    /**
   * Flattens an array of strings or string arrays into a single-dimensional array of strings.
   * @param texts - The array of strings or string arrays to flatten.
   * @returns The flattened array of strings.
   */ flatten(texts) {
        return texts.reduce((result, text)=>result.concat(text instanceof Array ? text : [
                text
            ]), []);
    }
    /**
   * Loads data from MongoDB collection
   * @param {string} dbName - The name of the database to load.
   * @param {string} collectionName - The name of the collection to load.
   * @param {string[]} fieldNames - An array of field names to retrieve from each document. Defaults to ["text"].
   * @param {string} separator - The separator to join multiple field values. Defaults to an empty string.
   * @param {Record<string, any>} filterQuery - Specific query, as specified by MongoDB NodeJS documentation.
   * @param {Number} maxDocs - The maximum number of documents to retrieve. Defaults to 0 (retrieve all documents).
   * @param {string[]} metadataNames - An optional array of metadata field names. If specified extracts this information as metadata.
   * @returns {Promise<Document[]>}
   * @throws If a field specified in fieldNames or metadataNames is not found in a MongoDB document.
   */ // eslint-disable-next-line max-params
    loadData(dbName, collectionName, fieldNames = [
        "text"
    ], separator = "", filterQuery = {}, maxDocs = 0, metadataNames) {
        var _this = this;
        return _async_to_generator(function*() {
            const db = _this.client.db(dbName);
            // Get items from collection
            const cursor = db.collection(collectionName).find(filterQuery).limit(maxDocs);
            const documents = [];
            {
                var _iteratorAbruptCompletion = false, _didIteratorError = false, _iteratorError;
                try {
                    for(var _iterator = _async_iterator(cursor), _step; _iteratorAbruptCompletion = !(_step = yield _iterator.next()).done; _iteratorAbruptCompletion = false){
                        let _value = _step.value;
                        const item = _value;
                        try {
                            const texts = fieldNames.map((name)=>item[name]);
                            const flattenedTexts = _this.flatten(texts);
                            const text = flattenedTexts.join(separator);
                            let metadata = {};
                            if (metadataNames) {
                                // extract metadata if fields are specified
                                metadata = Object.fromEntries(metadataNames.map((name)=>[
                                        name,
                                        item[name]
                                    ]));
                            }
                            documents.push(new Document({
                                text,
                                metadata
                            }));
                        } catch (err) {
                            throw new Error(`Field not found in Mongo document: ${err.message}`);
                        }
                    }
                } catch (err) {
                    _didIteratorError = true;
                    _iteratorError = err;
                } finally{
                    try {
                        if (_iteratorAbruptCompletion && _iterator.return != null) {
                            yield _iterator.return();
                        }
                    } finally{
                        if (_didIteratorError) {
                            throw _iteratorError;
                        }
                    }
                }
            }
            return documents;
        })();
    }
    constructor(client){
        this.client = client;
    }
}

exports.ALL_AVAILABLE_ANTHROPIC_MODELS = ALL_AVAILABLE_ANTHROPIC_MODELS;
exports.ALL_AVAILABLE_LLAMADEUCE_MODELS = ALL_AVAILABLE_LLAMADEUCE_MODELS;
exports.ALL_AVAILABLE_MISTRAL_MODELS = ALL_AVAILABLE_MISTRAL_MODELS;
exports.ALL_AVAILABLE_OPENAI_MODELS = ALL_AVAILABLE_OPENAI_MODELS;
exports.Anthropic = Anthropic;
exports.AstraDBVectorStore = AstraDBVectorStore;
exports.AudioSubtitlesReader = AudioSubtitlesReader;
exports.AudioTranscriptParagraphsReader = AudioTranscriptParagraphsReader;
exports.AudioTranscriptReader = AudioTranscriptReader;
exports.AudioTranscriptSentencesReader = AudioTranscriptSentencesReader;
exports.BaseDocumentStore = BaseDocumentStore;
exports.BaseEmbedding = BaseEmbedding;
exports.BaseInMemoryKVStore = BaseInMemoryKVStore;
exports.BaseIndex = BaseIndex;
exports.BaseIndexStore = BaseIndexStore;
exports.BaseKVStore = BaseKVStore;
exports.BaseNode = BaseNode;
exports.CallbackManager = CallbackManager;
exports.ChatHistory = ChatHistory;
exports.ChromaVectorStore = ChromaVectorStore;
exports.ClipEmbedding = ClipEmbedding;
exports.CompactAndRefine = CompactAndRefine;
exports.CondenseQuestionChatEngine = CondenseQuestionChatEngine;
exports.ContextChatEngine = ContextChatEngine;
exports.DEFAULT_CHUNK_OVERLAP = DEFAULT_CHUNK_OVERLAP;
exports.DEFAULT_CHUNK_OVERLAP_RATIO = DEFAULT_CHUNK_OVERLAP_RATIO;
exports.DEFAULT_CHUNK_SIZE = DEFAULT_CHUNK_SIZE;
exports.DEFAULT_COLLECTION = DEFAULT_COLLECTION;
exports.DEFAULT_CONTEXT_WINDOW = DEFAULT_CONTEXT_WINDOW;
exports.DEFAULT_DOC_STORE_PERSIST_FILENAME = DEFAULT_DOC_STORE_PERSIST_FILENAME;
exports.DEFAULT_EMBEDDING_DIM = DEFAULT_EMBEDDING_DIM;
exports.DEFAULT_FS = DEFAULT_FS;
exports.DEFAULT_GRAPH_STORE_PERSIST_FILENAME = DEFAULT_GRAPH_STORE_PERSIST_FILENAME;
exports.DEFAULT_IMAGE_VECTOR_NAMESPACE = DEFAULT_IMAGE_VECTOR_NAMESPACE;
exports.DEFAULT_INDEX_STORE_PERSIST_FILENAME = DEFAULT_INDEX_STORE_PERSIST_FILENAME;
exports.DEFAULT_NAMESPACE = DEFAULT_NAMESPACE;
exports.DEFAULT_NUM_OUTPUTS = DEFAULT_NUM_OUTPUTS;
exports.DEFAULT_OG_TEXT_METADATA_KEY = DEFAULT_OG_TEXT_METADATA_KEY;
exports.DEFAULT_PADDING = DEFAULT_PADDING;
exports.DEFAULT_PERSIST_DIR = DEFAULT_PERSIST_DIR;
exports.DEFAULT_SIMILARITY_TOP_K = DEFAULT_SIMILARITY_TOP_K;
exports.DEFAULT_VECTOR_STORE_PERSIST_FILENAME = DEFAULT_VECTOR_STORE_PERSIST_FILENAME;
exports.DEFAULT_WINDOW_METADATA_KEY = DEFAULT_WINDOW_METADATA_KEY;
exports.DEFAULT_WINDOW_SIZE = DEFAULT_WINDOW_SIZE;
exports.Document = Document;
exports.DocxReader = DocxReader;
exports.FILE_EXT_TO_READER = FILE_EXT_TO_READER;
exports.GPT35_MODELS = GPT35_MODELS;
exports.GPT4_MODELS = GPT4_MODELS;
exports.HTMLReader = HTMLReader;
exports.HuggingFaceEmbedding = HuggingFaceEmbedding;
exports.ImageDocument = ImageDocument;
exports.ImageNode = ImageNode;
exports.InMemoryFileSystem = InMemoryFileSystem;
exports.IndexDict = IndexDict;
exports.IndexList = IndexList;
exports.IndexNode = IndexNode;
exports.IndexStruct = IndexStruct;
exports.KeywordTable = KeywordTable;
exports.KeywordTableIndex = KeywordTableIndex;
exports.KeywordTableLLMRetriever = KeywordTableLLMRetriever;
exports.KeywordTableRAKERetriever = KeywordTableRAKERetriever;
exports.KeywordTableSimpleRetriever = KeywordTableSimpleRetriever;
exports.LLMQuestionGenerator = LLMQuestionGenerator;
exports.LlamaDeuce = LlamaDeuce;
exports.MarkdownReader = MarkdownReader;
exports.MetadataReplacementPostProcessor = MetadataReplacementPostProcessor;
exports.MistralAI = MistralAI;
exports.MistralAIEmbedding = MistralAIEmbedding;
exports.MistralAISession = MistralAISession;
exports.MongoDBAtlasVectorSearch = MongoDBAtlasVectorSearch;
exports.MultiModalEmbedding = MultiModalEmbedding;
exports.MultiModalResponseSynthesizer = MultiModalResponseSynthesizer;
exports.NotionReader = NotionReader;
exports.Ollama = Ollama;
exports.OpenAI = OpenAI;
exports.OpenAIEmbedding = OpenAIEmbedding;
exports.PDFReader = PDFReader;
exports.PGVectorStore = PGVectorStore;
exports.PapaCSVReader = PapaCSVReader;
exports.PineconeVectorStore = PineconeVectorStore;
exports.Portkey = Portkey;
exports.PromptHelper = PromptHelper;
exports.Refine = Refine;
exports.Response = Response;
exports.ResponseSynthesizer = ResponseSynthesizer;
exports.RetrieverQueryEngine = RetrieverQueryEngine;
exports.SentenceSplitter = SentenceSplitter;
exports.SentenceWindowNodeParser = SentenceWindowNodeParser;
exports.SimilarityPostprocessor = SimilarityPostprocessor;
exports.SimpleChatEngine = SimpleChatEngine;
exports.SimpleChatHistory = SimpleChatHistory;
exports.SimpleDirectoryReader = SimpleDirectoryReader;
exports.SimpleDocumentStore = SimpleDocumentStore;
exports.SimpleIndexStore = SimpleIndexStore;
exports.SimpleKVStore = SimpleKVStore;
exports.SimpleMongoReader = SimpleMongoReader;
exports.SimpleNodeParser = SimpleNodeParser;
exports.SimpleResponseBuilder = SimpleResponseBuilder;
exports.SimpleVectorStore = SimpleVectorStore;
exports.SubQuestionOutputParser = SubQuestionOutputParser;
exports.SubQuestionQueryEngine = SubQuestionQueryEngine;
exports.SummaryChatHistory = SummaryChatHistory;
exports.SummaryIndex = SummaryIndex;
exports.SummaryIndexLLMRetriever = SummaryIndexLLMRetriever;
exports.SummaryIndexRetriever = SummaryIndexRetriever;
exports.TextFileReader = TextFileReader;
exports.TextNode = TextNode;
exports.TogetherEmbedding = TogetherEmbedding;
exports.TogetherLLM = TogetherLLM;
exports.TreeSummarize = TreeSummarize;
exports.VectorIndexRetriever = VectorIndexRetriever;
exports.VectorStoreIndex = VectorStoreIndex;
exports.anthropicTextQaPrompt = anthropicTextQaPrompt;
exports.buildToolsText = buildToolsText;
exports.cjkSentenceTokenizer = cjkSentenceTokenizer;
exports.defaultChoiceSelectPrompt = defaultChoiceSelectPrompt;
exports.defaultCondenseQuestionPrompt = defaultCondenseQuestionPrompt;
exports.defaultContextSystemPrompt = defaultContextSystemPrompt;
exports.defaultKeywordExtractPrompt = defaultKeywordExtractPrompt;
exports.defaultParagraphSeparator = defaultParagraphSeparator;
exports.defaultQueryKeywordExtractPrompt = defaultQueryKeywordExtractPrompt;
exports.defaultRefinePrompt = defaultRefinePrompt;
exports.defaultSentenceTokenizer = defaultSentenceTokenizer;
exports.defaultSubQuestionPrompt = defaultSubQuestionPrompt;
exports.defaultSummaryPrompt = defaultSummaryPrompt;
exports.defaultTextQaPrompt = defaultTextQaPrompt;
exports.defaultTreeSummarizePrompt = defaultTreeSummarizePrompt;
exports.exists = exists;
exports.getBiggestPrompt = getBiggestPrompt;
exports.getEmptyPromptTxt = getEmptyPromptTxt;
exports.getHistory = getHistory;
exports.getNodeFS = getNodeFS;
exports.getResponseBuilder = getResponseBuilder;
exports.getTopKEmbeddings = getTopKEmbeddings;
exports.getTopKEmbeddingsLearner = getTopKEmbeddingsLearner;
exports.getTopKMMREmbeddings = getTopKMMREmbeddings;
exports.globalsHelper = globalsHelper;
exports.imageToDataUrl = imageToDataUrl;
exports.imageToString = imageToString;
exports.jsonToIndexStruct = jsonToIndexStruct;
exports.jsonToNode = jsonToNode;
exports.messagesToHistoryStr = messagesToHistoryStr;
exports.parseJsonMarkdown = parseJsonMarkdown;
exports.readImage = readImage;
exports.serviceContextFromDefaults = serviceContextFromDefaults;
exports.serviceContextFromServiceContext = serviceContextFromServiceContext;
exports.similarity = similarity;
exports.splitNodesByType = splitNodesByType;
exports.storageContextFromDefaults = storageContextFromDefaults;
exports.stringToImage = stringToImage;
exports.walk = walk;
