import { Anthropic } from "@anthropic-ai/sdk";
import { AIMessage, AIMessageChunk, } from "@langchain/core/messages";
import { ChatGenerationChunk } from "@langchain/core/outputs";
import { getEnvironmentVariable } from "@langchain/core/utils/env";
import { BaseChatModel, } from "@langchain/core/language_models/chat_models";
/**
 * Wrapper around Anthropic large language models.
 *
 * To use you should have the `@anthropic-ai/sdk` package installed, with the
 * `ANTHROPIC_API_KEY` environment variable set.
 *
 * @remarks
 * Any parameters that are valid to be passed to {@link
 * https://console.anthropic.com/docs/api/reference |
 * `anthropic.beta.messages`} can be passed through {@link invocationKwargs},
 * even if not explicitly available on this class.
 * @example
 * ```typescript
 * const model = new ChatAnthropic({
 *   temperature: 0.9,
 *   anthropicApiKey: 'YOUR-API-KEY',
 * });
 * const res = await model.invoke({ input: 'Hello!' });
 * console.log(res);
 * ```
 */
export class ChatAnthropicMessages extends BaseChatModel {
    static lc_name() {
        return "ChatAnthropic";
    }
    get lc_secrets() {
        return {
            anthropicApiKey: "ANTHROPIC_API_KEY",
        };
    }
    get lc_aliases() {
        return {
            modelName: "model",
        };
    }
    constructor(fields) {
        super(fields ?? {});
        Object.defineProperty(this, "lc_serializable", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        Object.defineProperty(this, "anthropicApiKey", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "apiUrl", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "temperature", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: 1
        });
        Object.defineProperty(this, "topK", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: -1
        });
        Object.defineProperty(this, "topP", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: -1
        });
        Object.defineProperty(this, "maxTokens", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: 2048
        });
        Object.defineProperty(this, "modelName", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "claude-2.1"
        });
        Object.defineProperty(this, "invocationKwargs", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "stopSequences", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "streaming", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "clientOptions", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // Used for non-streaming requests
        Object.defineProperty(this, "batchClient", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // Used for streaming requests
        Object.defineProperty(this, "streamingClient", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.anthropicApiKey =
            fields?.anthropicApiKey ?? getEnvironmentVariable("ANTHROPIC_API_KEY");
        if (!this.anthropicApiKey) {
            throw new Error("Anthropic API key not found");
        }
        // Support overriding the default API URL (i.e., https://api.anthropic.com)
        this.apiUrl = fields?.anthropicApiUrl;
        this.modelName = fields?.modelName ?? this.modelName;
        this.invocationKwargs = fields?.invocationKwargs ?? {};
        this.temperature = fields?.temperature ?? this.temperature;
        this.topK = fields?.topK ?? this.topK;
        this.topP = fields?.topP ?? this.topP;
        this.maxTokens =
            fields?.maxTokensToSample ?? fields?.maxTokens ?? this.maxTokens;
        this.stopSequences = fields?.stopSequences ?? this.stopSequences;
        this.streaming = fields?.streaming ?? false;
        this.clientOptions = fields?.clientOptions ?? {};
    }
    /**
     * Get the parameters used to invoke the model
     */
    invocationParams(options) {
        return {
            model: this.modelName,
            temperature: this.temperature,
            top_k: this.topK,
            top_p: this.topP,
            stop_sequences: options?.stop ?? this.stopSequences,
            stream: this.streaming,
            max_tokens: this.maxTokens,
            ...this.invocationKwargs,
        };
    }
    /** @ignore */
    _identifyingParams() {
        return {
            model_name: this.modelName,
            ...this.invocationParams(),
        };
    }
    /**
     * Get the identifying parameters for the model
     */
    identifyingParams() {
        return {
            model_name: this.modelName,
            ...this.invocationParams(),
        };
    }
    async *_streamResponseChunks(messages, options, runManager) {
        const params = this.invocationParams(options);
        const stream = await this.createStreamWithRetry({
            ...params,
            ...this.formatMessagesForAnthropic(messages),
            stream: true,
        });
        for await (const data of stream) {
            if (options.signal?.aborted) {
                stream.controller.abort();
                throw new Error("AbortError: User aborted the request.");
            }
            if (data.type === "message_start") {
                // eslint-disable-next-line @typescript-eslint/no-unused-vars
                const { content, ...additionalKwargs } = data.message;
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                const filteredAdditionalKwargs = {};
                for (const [key, value] of Object.entries(additionalKwargs)) {
                    if (value !== undefined && value !== null) {
                        filteredAdditionalKwargs[key] = value;
                    }
                }
                yield new ChatGenerationChunk({
                    message: new AIMessageChunk({
                        content: "",
                        additional_kwargs: filteredAdditionalKwargs,
                    }),
                    text: "",
                });
            }
            else if (data.type === "message_delta") {
                yield new ChatGenerationChunk({
                    message: new AIMessageChunk({
                        content: "",
                        additional_kwargs: { ...data.delta },
                    }),
                    text: "",
                });
            }
            else if (data.type === "content_block_delta") {
                const content = data.delta?.text;
                if (content !== undefined) {
                    yield new ChatGenerationChunk({
                        message: new AIMessageChunk({
                            content,
                            additional_kwargs: {},
                        }),
                        text: content,
                    });
                    await runManager?.handleLLMNewToken(content);
                }
            }
        }
    }
    /**
     * Formats messages as a prompt for the model.
     * @param messages The base messages to format as a prompt.
     * @returns The formatted prompt.
     */
    formatMessagesForAnthropic(messages) {
        let system;
        if (messages.length > 0 && messages[0]._getType() === "system") {
            if (typeof messages[0].content !== "string") {
                throw new Error("Currently only string content messages are supported.");
            }
            system = messages[0].content;
        }
        const conversationMessages = system !== undefined ? messages.slice(1) : messages;
        const formattedMessages = conversationMessages.map((message) => {
            let role;
            if (typeof message.content !== "string") {
                throw new Error("Currently only string content messages are supported.");
            }
            if (message._getType() === "human") {
                role = "user";
            }
            else if (message._getType() === "ai") {
                role = "assistant";
            }
            else if (message._getType() === "system") {
                throw new Error("System messages are only permitted as the first passed message.");
            }
            else {
                throw new Error(`Message type "${message._getType()}" is not supported.`);
            }
            return {
                role,
                content: message.content,
            };
        });
        return {
            messages: formattedMessages,
            system,
        };
    }
    /** @ignore */
    async _generate(messages, options, runManager) {
        if (this.stopSequences && options.stop) {
            throw new Error(`"stopSequence" parameter found in input and default params`);
        }
        const params = this.invocationParams(options);
        if (params.stream) {
            let finalChunk;
            const stream = await this._streamResponseChunks(messages, options, runManager);
            for await (const chunk of stream) {
                if (finalChunk === undefined) {
                    finalChunk = chunk;
                }
                else {
                    finalChunk = finalChunk.concat(chunk);
                }
            }
            if (finalChunk === undefined) {
                throw new Error("No chunks returned from Anthropic API.");
            }
            return {
                generations: [
                    {
                        text: finalChunk.text,
                        message: finalChunk.message,
                    },
                ],
            };
        }
        else {
            const response = await this.completionWithRetry({
                ...params,
                stream: false,
                ...this.formatMessagesForAnthropic(messages),
            }, { signal: options.signal });
            const { content, ...additionalKwargs } = response;
            if (!Array.isArray(content) || content.length !== 1) {
                console.log(content);
                throw new Error("Received multiple content parts in Anthropic response. Only single part messages are currently supported.");
            }
            return {
                generations: [
                    {
                        text: content[0].text,
                        message: new AIMessage({
                            content: content[0].text,
                            additional_kwargs: additionalKwargs,
                        }),
                    },
                ],
            };
        }
    }
    /**
     * Creates a streaming request with retry.
     * @param request The parameters for creating a completion.
     * @returns A streaming request.
     */
    async createStreamWithRetry(request) {
        if (!this.streamingClient) {
            const options = this.apiUrl ? { baseURL: this.apiUrl } : undefined;
            this.streamingClient = new Anthropic({
                ...this.clientOptions,
                ...options,
                apiKey: this.anthropicApiKey,
                // Prefer LangChain built-in retries
                maxRetries: 0,
            });
        }
        const makeCompletionRequest = async () => this.streamingClient.beta.messages.create(
        // TODO: Fix typing once underlying SDK is fixed to not require unnecessary "anthropic-beta" param
        {
            ...request,
            ...this.invocationKwargs,
            stream: true,
        });
        return this.caller.call(makeCompletionRequest);
    }
    /** @ignore */
    async completionWithRetry(request, options) {
        if (!this.anthropicApiKey) {
            throw new Error("Missing Anthropic API key.");
        }
        if (!this.batchClient) {
            const options = this.apiUrl ? { baseURL: this.apiUrl } : undefined;
            this.batchClient = new Anthropic({
                ...this.clientOptions,
                ...options,
                apiKey: this.anthropicApiKey,
                maxRetries: 0,
            });
        }
        const makeCompletionRequest = async () => this.batchClient.beta.messages.create(
        // TODO: Fix typing once underlying SDK is fixed to not require unnecessary "anthropic-beta" param
        {
            ...request,
            ...this.invocationKwargs,
        });
        return this.caller.callWithOptions({ signal: options.signal }, makeCompletionRequest);
    }
    _llmType() {
        return "anthropic";
    }
    /** @ignore */
    _combineLLMOutput() {
        return [];
    }
}
export class ChatAnthropic extends ChatAnthropicMessages {
}
